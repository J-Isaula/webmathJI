{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Arquitectura de Redes Neuronales\"\n",
        "subtitle: \"\"\n",
        "author: \"Juan Isaula\"\n",
        "date: \"2024-01-24\"\n",
        "categories: [RNN, GRU, LSTM, PyTorch]\n",
        "image: \"arq_rn.jpeg\"\n",
        "editor: \n",
        "  markdown: \n",
        "    wrap: 72\n",
        "---\n",
        "\n",
        "\n",
        "Las arquitecturas de redes neuronales se refieren a los diseños\n",
        "estructurales y organizativos de redes neuronales artificiales (RNA).\n",
        "Estas arquitecturas determinan cómo se organiza la red, incluida la\n",
        "cantidad de capas, la cantidad de neuronas en cada capa, las conexiones\n",
        "entre neuoronas y las funciones de activación utilizadas. Se forman\n",
        "diferentes arquitecturas de redes neuronales alterando estos componentes\n",
        "estructurales para adaptarse a tareas o desafíos específicos. Si desea\n",
        "conocer los tipos de arquitectura de redes neuronales que debe conocer,\n",
        "este artículo es para usted. En este artículo, le explicaré los tipos de\n",
        "arquitecturas de redes neuronales en `Machine Learning` y cuándo\n",
        "elegirlas.\n",
        "\n",
        "## Fundamentos previos a la comprensión de Redes Neuronales\n",
        "\n",
        "### Función de Activación\n",
        "\n",
        "Una función de activación es una función que se agrega a una red\n",
        "neuronal para ayudar a la red a aprender dependencias no lineales\n",
        "complejas. Una función de activación típica debe ser diferenciable y\n",
        "continua en todas partes. A continuación proporcionaré algunos ejemplos\n",
        "de funciones de activación utilizando la biblioteca\n",
        "[PyTorch](https://pytorch.org/).\n",
        "\n",
        "#### Función ReLU\n",
        "\n",
        "`ReLU` o la función ReLU realiza una operación simple:\n",
        "$y = \\max (0, x)$. Aquí te proporcionó un ejemplo de uso de la función\n",
        "ReLU utilizando `PyTorch.`\n"
      ],
      "id": "2947db29"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x = torch.linspace(-10, 10,steps=100)\n",
        "\n",
        "relu = torch.nn.ReLU()\n",
        "\n",
        "y = relu(x)\n",
        "plt.title(\"ReLU\")\n",
        "plt.plot(x.tolist(), y.tolist())\n",
        "plt.show()"
      ],
      "id": "315af98b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Función Sigmoidea\n",
        "\n",
        "Es una de las funciones de activación no lineal más comunes. La función\n",
        "sigmoidea se representa matemáticamente como:\n",
        "\n",
        "$$\n",
        "\\sigma(x) = \\frac{1}{1 + e^x} \n",
        "$$\n",
        "\n",
        "Al igual que `ReLU`, la función $\\sigma$ se puede construir simplemente\n",
        "usando `PyTorch`.\n"
      ],
      "id": "507f51d2"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x = torch.linspace(-10, 10,steps=100)\n",
        "\n",
        "sigmoid = torch.nn.Sigmoid()\n",
        "\n",
        "y = sigmoid(x)\n",
        "plt.title(\"Sigmoidea\")\n",
        "plt.plot(x.tolist(), y.tolist())\n",
        "plt.show()"
      ],
      "id": "fdea3de8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Función Tanh\n",
        "\n",
        "La función tangente hiperbólica es similar a la función sigmoidea, pero\n",
        "devuelve valores en el rango $(-1,1)$. El beneficio de `Tanh` sobre\n",
        "$\\sigma$ es que las entradas negativas se asignarán estrictamente a\n",
        "negativa, y las entradas positivas se asignarán estrictamente a\n",
        "positivas:\n",
        "\n",
        "$$\n",
        "\\tanh(x) = \\frac{e^x - e^{-x}}{e^x + e^{-x}}\n",
        "$$\n"
      ],
      "id": "85ab5b6c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x=torch.linspace(-10,10, steps = 100)\n",
        "tanh = torch.nn.Tanh()\n",
        "y = tanh(x)\n",
        "\n",
        "plt.title('Tanh')\n",
        "plt.plot(x.tolist(),y.tolist())\n",
        "plt.show()"
      ],
      "id": "c9ad15f4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Las funciones de activación no lineales, como la $\\sigma$ y $\\tanh$\n",
        "sufren de un gran problema computacional llamado problema de ***fuga de\n",
        "gradiente.***\n",
        "\n",
        "La ***fuga de gradiente*** hace que sea muy difícil entrenar y ajustar\n",
        "los parámetros de las capas iniciales en la red. Este problema empeora a\n",
        "medida que aumenta el número de capas en la red.\n",
        "\n",
        "La fuga de gradiente es la causa principal que hace que las activaciones\n",
        "sigmoideas o Tanh no sean adecuadas para los modelos de Deep Learning\n",
        "(aprendizaje profundo). La función de activación `ReLU` no sufre de\n",
        "gradiente de fuga porque la derivada siempre es 1 para entradas\n",
        "positivas. Así que siempre considere usar `ReLU` como la función de\n",
        "activación en los primeros borradores del diseño de su modelo.\\\n",
        "\\\n",
        "La creación de una arquitectura de red neuronal que se adapte más a un\n",
        "problema en particular es un arte. Existe una dirección de estudio\n",
        "separada en el aprendizaje profundo llamado\n",
        "*`Búsqueda de arquitectura neural`*, que automatiza la ingeniería de\n",
        "arquitectura de red:\n",
        "<https://lilianweng.github.io/lil-log/2020/08/06/neural-architecture-search.html.>\n",
        "Pero incluso estos motores de búsqueda no pueden competir con las\n",
        "habilidades heurísticas humanas en el diseño todavía. Existen algunas\n",
        "técnicas que aumentan la probabilidad de mejorar el rendimiento de la\n",
        "red neuronal. Por supuesto, estas técnicas no garantizan la mejora en\n",
        "todos los casos. A veces incluso pueden empeorar el rendimiento de la\n",
        "red neuronal. Pero es probable que desarrolle una arquitectura de modelo\n",
        "robusta siguiendo estos enfoques.\n",
        "\n",
        "### Funciones de Pérdida y Optimización\n",
        "\n",
        "#### Funciones de Pérdida\n",
        "\n",
        "La función de pérdida calculará un error de red en cada iteración,\n",
        "mientras que la función de optimización determina *\"cómo y en qué\n",
        "dirección cambiar los parámetros de peso\".*\n",
        "\n",
        "Hay una cantidad diversa de funciones de pérdida, cada una de ellas está\n",
        "destinada a una tarea en particular. Para el análisis de series de\n",
        "tiempo, hay tres funciones de pérdida principales:\n",
        "\n",
        "-   ***Pérdida absoluta (L1):*** La pérdida absoluta es la métrica más\n",
        "    simple de la distancia entre dos vectores:\n",
        "\n",
        "    $$\n",
        "    absolute loss = \\frac{\\sum |y_{actual} - y_{predicción}|}{n}\n",
        "    $$\n",
        "\n",
        "    En `PyTorch`, la función de pérdida absoluta se implementa de la\n",
        "    siguiente manera:\n"
      ],
      "id": "542c4593"
    },
    {
      "cell_type": "code",
      "metadata": {
        "md-indent": "    "
      },
      "source": [
        "a = torch.tensor([1,2]).float()\n",
        "b = torch.tensor([1, 5]).float()\n",
        "abs_loss = torch.nn.L1Loss()\n",
        "abs_error = abs_loss(a,b)\n",
        "print(f'abs: {abs_error.item()}')"
      ],
      "id": "85062dcc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   ***Error cuadrático medio (MSE)*** ***(L2):*** Es la función de\n",
        "    pérdida más utilizada para los problemas de predicción de series de\n",
        "    tiempo:\n",
        "\n",
        "    $$\n",
        "    mean\\_squared\\_error =  \\frac{\\sum(y_{actual} - y_{predicted})^2}{n}\n",
        "    $$\n",
        "\n",
        "-   ***Pérdida suave (L1):*** es algo intermedio entre las funciones de\n",
        "    pérdida absoluta y MSE. La pérdida absoluto (L1) es menos sensible a\n",
        "    los valores atípicos que MSE:\n",
        "\n",
        "    $$\n",
        "    smooth\\_loss(y^{\\prime},y) = \\frac{1}{n}\\sum z_i \n",
        "    $$\n",
        "\n",
        "    donde $y$ es valor real, $y$ se predice, $z_i$ se define como:\n",
        "\n",
        "    $$ z = \n",
        "    \\begin{equation} \n",
        "     \\begin{matrix}\n",
        "      \\frac{0.5(y_{i}^{\\prime} - y_i)^2}{\\beta}, & |y_{i}^{\\prime} - y_i| < \\beta\\\\  \n",
        "    |y_{i}^{\\prime} - y_i| - 0.5\\beta, & otro\\_caso\n",
        "      \\end{matrix}\n",
        "    \\end{equation}\n",
        "    $$\n",
        "\n",
        "La función de pérdida de L1 suave tiene un parámetro $\\beta$, es igual a\n",
        "1 por defecto.\n",
        "\n",
        "#### Optimizador\n",
        "\n",
        "El objetivo principal de un optimizador es cambiar los parámetros de\n",
        "pesos del modelo para minimizar la función de pérdida. La selección de\n",
        "un optimizador adecuado depende completamente de la arquitectura de la\n",
        "red neuronal y los datos sobre los que ocurre el entrenamiento.\n",
        "\n",
        "-   `Adagrad:` es un algoritmo de optimización basado en gradiente que\n",
        "    adapta la tasa de aprendizaje a los parámetros. Realiza\n",
        "    actualizaciones más pequeñas para los parámetros asociados con\n",
        "    características frecuentes y actualizaciones más grandes para\n",
        "    parámetros asociados con características raras.\n",
        "\n",
        "-   `Adadelta` es la versión avanzada del algoritmo de Adagrad. Adadelta\n",
        "    busca minimizar su tasa de aprendizaje agresiva y monotónica que\n",
        "    disminuye. En lugar de acumular todos los gradientes pasados.\n",
        "\n",
        "-   `Adam` es otro método de optimización que calcula las tasas de\n",
        "    aprendizaje adaptativo para cada parámetro. Además de guardar un\n",
        "    promedio exponencialmente en descomposición de gradientes cuadrados\n",
        "    anteriores como Adadelta, Adam también mantiene un promedio\n",
        "    exponencialmente de disminución de gradientes anteriores.\n",
        "\n",
        "## Tipos de Redes Neuronales\n",
        "\n",
        "Comenzaremos explorando algunas de las arquitecturas de redes neuronales\n",
        "más eficientes para el pronóstico de series de tiempo. Nos centraremos\n",
        "en la implementación de redes neuronales recurrentes (RNN), unidad\n",
        "recurrentes cerradas (GRU), redes de memoria a largo plazo (LSTM).\n",
        "Comprender los principios básicos de las RNN será una buena base para su\n",
        "aplicación directa y dominar otras arquitecturas similares. Trataremos\n",
        "de cubrir la lógica y el núcleo de cada arquitectura, su aplicación\n",
        "práctica y pros y contras.\n",
        "\n",
        "Discutiremos los siguientes temas:\n",
        "\n",
        "-   Recurrent neural network (RNN)\n",
        "\n",
        "-   Gated recurrent unit network (GRU)\n",
        "\n",
        "-   Long short-term memory network (LSTM)\n",
        "\n",
        "### Recurrent Neural Network (RNN)\n",
        "\n",
        "RNN *(Red Neuronal Recurrente Estándar)* tiene un concepto de un estado\n",
        "oculto. Un estado oculto puede tratarse como memoria interna. El estado\n",
        "oculto no intenta recordar todos los valores pasados de la secuencia\n",
        "sino solo su efecto. Debido a la memoria interna, las RNN pueden\n",
        "recordar cosas importantes sobre su entrada, lo que les permite ser muy\n",
        "preciosos para predecir valores futuros.\n",
        "\n",
        "Estudiemos la teoría de RNN de una manera más formal. En RNN, la\n",
        "secuencia de entrada se representa a traves de un bucle. Cuando toma una\n",
        "decisión, considera la entrada actual y también lo que ha aprendido de\n",
        "las entradas que recibio anteriormente. Veamos el gráfico computacional\n",
        "de RNN para comprender esta lógica:\n",
        "\n",
        "![Gráfico Computacional de RNN](Figure%204.3.png)\n",
        "\n",
        "donde,\n",
        "\n",
        "-   $x_1, x_2, . . . , x_n$ son la secuencia de entrada.\n",
        "\n",
        "-   $h_i$ es el estado oculto. $h_i$ es un vector de longitud $h$.\n",
        "\n",
        "-   `RNN Cell` representa la capa de red neuronal que calcula la\n",
        "    siguiente función:\n",
        "    $h_t = \\tanh(W_{ih}x_t + b_{ih} + W_{hh}h_{(t-1)} + b_{hh})$\n",
        "\n",
        "Podemos ver a detalle la RNN Cell:\n",
        "\n",
        "![Gráfico computacional de RNN Cell](Figure%204.4.png)\n",
        "\n",
        "La RNN Cell combina información sobre el valor actual de la secuencia\n",
        "$x_i$ y el estado previamente oculto $h_{i-1}$. La RNN Cell, devuelve un\n",
        "estado oculto actualizado $h_i$ después de aplicar la función de\n",
        "activación.\n",
        "\n",
        "La RNN tiene los siguientes parámetros, que se ajustan durante el\n",
        "entrenamiento:\n",
        "\n",
        "-   $W_{ih}$ pesos ocultos de entrada\n",
        "\n",
        "-   $b_{ih}$ sesgos oculto de entrada\n",
        "\n",
        "-   $W_{hh}$ pesos ocultos - ocultos\n",
        "\n",
        "-   $B_{hh}$ sesgos oculto - oculto\n",
        "\n",
        "***Nota:*** *Un error común ocurre cuando los subíndices en los\n",
        "parámetros RNN* $(W_{ih}, b_{ih}, W_{hh}, b_{hh})$ *se interpretan como\n",
        "una dimensión de índice o tensor. No, son solo la abreviatura de\n",
        "entrada-oculto* $(h_í)$ *y oculto-oculto* $(h)$*. El mismo principio\n",
        "aplica a los parámetros de otros modelos: `GRU` y `LSTM`.*\n",
        "\n",
        "En ocasiones, los cientificos de datos utilizan la siguiente\n",
        "representación de las RNN:\n",
        "\n",
        "![Visualización alternativa de RNN](Figure%204.5.png)\n",
        "\n",
        "El gráfico que se muestra puede dar lugar a algunos malentendidos, y\n",
        "estoy tratando de evitar esto. Pero si este tipo de gráfico se adapta a\n",
        "tu intuición, entonces úsalo sin ninguna duda.\\\n",
        "\n",
        "Ahora estamos listos para examinar una implementación de RNN utilizando\n",
        "[PyTorch](https://pytorch.org/)\n"
      ],
      "id": "df55c56d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class RNN(nn.Module):\n",
        "\n",
        "    def __init__(self,\n",
        "                 hidden_size,\n",
        "                 in_size = 1,\n",
        "                 out_size = 1):\n",
        "        super(RNN, self).__init__()\n",
        "        self.rnn = nn.RNN(\n",
        "            input_size = in_size,\n",
        "            hidden_size = hidden_size,\n",
        "            batch_first = True)\n",
        "        self.fc = nn.Linear(hidden_size, out_size)\n",
        "\n",
        "    def forward(self, x, h = None):\n",
        "        out, _ = self.rnn(x, h)\n",
        "        last_hidden_states = out[:, -1]\n",
        "        out = self.fc(last_hidden_states)\n",
        "        return out, last_hidden_states"
      ],
      "id": "716e1ebf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note que nuestro modelo devuelve dos salidas: predicción y estado\n",
        "oculto. Es crucial reutilizar los estados ocultos durante la evaluación\n",
        "RNN. Utilizaremos conjuntos de datos de consumo de energía por hora (\n",
        "<https://www.kaggle.com/robikscube/Hourly-energy-Consumed>) para la\n",
        "implementación de RNN.\n"
      ],
      "id": "b08f12aa"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "df = pd.read_csv('AEP_hourly.csv')\n",
        "ts = df['AEP_MW'].astype(int).values.reshape(-1, 1)[-3000:]\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.title('AEP Hourly')\n",
        "plt.plot(ts[:500])\n",
        "plt.show()"
      ],
      "id": "d2640c29",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Podemos ver en que esta es una serie de tiempo realmente complicada.\n",
        "Tiene varios factores de estacionalidad con picos apenas predecibles.\n",
        "\n",
        "A continuación, voy a mostrarte como se desempeña RNN en la serie de\n",
        "tiempo AEP Hourly:\n"
      ],
      "id": "cd1bcc27"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import copy\n",
        "import random\n",
        "import sys\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "random.seed(1)\n",
        "torch.manual_seed(1)\n",
        "\n",
        "# Parametros globales\n",
        "\n",
        "\n",
        "features = 240\n",
        "# Longitud del conjunto de datos de prueba\n",
        "test_ts_len = 300\n",
        "# tamaño del estado oculto\n",
        "rnn_hidden_size = 24\n",
        "# tasa de aprendizaje de optimizador\n",
        "learning_rate = 0.02\n",
        "\n",
        "training_epochs = 500\n",
        "\n",
        "def sliding_window(ts, features):\n",
        "    X = []\n",
        "    Y = []\n",
        "\n",
        "    for i in range(features + 1, len(ts) + 1):\n",
        "        X.append(ts[i - (features + 1):i - 1])\n",
        "        Y.append([ts[i - 1]])\n",
        "\n",
        "    return X, Y\n",
        "\n",
        "def get_training_datasets(ts, features, test_len):\n",
        "    X, Y = sliding_window(ts, features)\n",
        "\n",
        "    X_train, Y_train, X_test, Y_test = X[0:-test_len],\\\n",
        "                                       Y[0:-test_len],\\\n",
        "                                       X[-test_len:],\\\n",
        "                                       Y[-test_len:]\n",
        "\n",
        "    train_len = round(len(ts) * 0.7)\n",
        "\n",
        "    X_train, X_val, Y_train, Y_val = X_train[0:train_len],\\\n",
        "                                     X_train[train_len:],\\\n",
        "                                     Y_train[0:train_len],\\\n",
        "                                     Y_train[train_len:]\n",
        "\n",
        "    x_train = torch.tensor(data = X_train).float()\n",
        "    y_train = torch.tensor(data = Y_train).float()\n",
        "\n",
        "    x_val = torch.tensor(data = X_val).float()\n",
        "    y_val = torch.tensor(data = Y_val).float()\n",
        "\n",
        "    x_test = torch.tensor(data = X_test).float()\n",
        "    y_test = torch.tensor(data = Y_test).float()\n",
        "\n",
        "    return x_train, x_val, x_test,\\\n",
        "           y_train.squeeze(1), y_val.squeeze(1), y_test.squeeze(1)\n",
        "           \n",
        "\n",
        "# Preparando datos para entrenamiento\n",
        "scaler = MinMaxScaler()\n",
        "scaled_ts = scaler.fit_transform(ts)\n",
        "x_train, x_val, x_test, y_train, y_val, y_test =\\\n",
        "    get_training_datasets(scaled_ts, features, test_ts_len)\n",
        "    \n",
        "\n",
        "# Inicialización del modelo \n",
        "model = RNN(hidden_size = rnn_hidden_size)\n",
        "model.train()\n"
      ],
      "id": "93b07f7f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Entrenamiento\n",
        "optimizer = torch.optim.Adam(params = model.parameters(), lr = learning_rate)\n",
        "mse_loss = torch.nn.MSELoss()\n",
        "\n",
        "best_model = None\n",
        "min_val_loss = sys.maxsize\n",
        "\n",
        "training_loss = []\n",
        "validation_loss = []\n",
        "\n",
        "for t in range(training_epochs):\n",
        "\n",
        "    prediction, _ = model(x_train)\n",
        "    loss = mse_loss(prediction, y_train)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    val_prediction, _ = model(x_val)\n",
        "    val_loss = mse_loss(val_prediction, y_val)\n",
        "\n",
        "    training_loss.append(loss.item())\n",
        "    validation_loss.append(val_loss.item())\n",
        "\n",
        "    if val_loss.item() < min_val_loss:\n",
        "        best_model = copy.deepcopy(model)\n",
        "        min_val_loss = val_loss.item()\n",
        "\n",
        "    if t % 50 == 0:\n",
        "        print(f'epoch {t}: train - {round(loss.item(), 4)}, '\n",
        "              f'val: - {round(val_loss.item(), 4)}')\n"
      ],
      "id": "936aa4e3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Y aquí llegamos al punto más difícil. Debe pasar el estado oculto al\n",
        "modelo RNN cuando lo evalua. La forma más sencilla de calentar el estado\n",
        "oculto es ejecutar el modelo en los datos de validación una vez y pasar\n",
        "un estado oculto cálido a través de cada iteración y por último\n",
        "evaluamos el modelo que construimos en el conjunto de datos de prueba.\n"
      ],
      "id": "84c5e385"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "best_model.eval()\n",
        "_, h_list = best_model(x_val)\n",
        "\n",
        "h = (h_list[-1, :]).unsqueeze(-2)\n",
        "\n",
        "\n",
        "predicted = []\n",
        "for test_seq in x_test.tolist():\n",
        "    x = torch.Tensor(data = [test_seq])\n",
        " \n",
        "    y, h = best_model(x, h.unsqueeze(-2))\n",
        "    unscaled = scaler.inverse_transform(np.array(y.item()).reshape(-1, 1))[0][0]\n",
        "    predicted.append(unscaled)\n",
        "\n",
        "real = scaler.inverse_transform(y_test.tolist())\n",
        "plt.title(\"Conjunto de datos prueba - RNN\")\n",
        "plt.plot(real, label = 'real')\n",
        "plt.plot(predicted, label = 'predicción')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "id": "94a660a8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "RNN muestra un gran rendimiento en el conjunto de datos de prueba. El\n",
        "modelo que hemos entrenado predice picos estacionales con mucha\n",
        "precisión.\n",
        "\n",
        "Y finalmente, examinamos el proceso de entrenamiento en sí.\n"
      ],
      "id": "53351b2f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plt.title('Desempeño RNN')\n",
        "plt.yscale('log')\n",
        "plt.plot(training_loss, label = 'Entrenamiento')\n",
        "plt.plot(validation_loss, label = 'validación')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "id": "fa2e9980",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "El proceso del entrenamiento es suave sin picos agudos e impredecibles.\n",
        "\n",
        "Ahora, podemos establecer con confianza la promesa y la efectividad de\n",
        "la aplicación de RNN a los problemas de pronósticos de la serie\n",
        "temporal.\n",
        "\n",
        "A pesar de todas las ventajas de RNN, tiene desventajas significativas:\n",
        "\n",
        "-   Debido a la complejidad computacional, sufren problemas de gradiente\n",
        "    de fuga. El proceso de entrenamiento se vuelve demasiado lento. El\n",
        "    problema del gradiente de fuga es un problema común a todas las RNN.\n",
        "\n",
        "-   El estado oculto se actualiza en cada iteración, lo que dificulta el\n",
        "    almacenamiento de información a largo plazo en RNN. Las\n",
        "    arquitecturas `GRU` y `LSTM` resuelven este problema. Tienen\n",
        "    enfoques similares sobre cómo almacenar información a largo plazo.\n",
        "\n",
        "### Gated recurrent unit network (GRU)\n",
        "\n",
        "La GRU es es una versión avanzada de la RNN clásica. El propósito\n",
        "principal de GRU es almacenar información a largo plazo. En breve\n",
        "exploraremos como GRU logra esto.\n",
        "\n",
        "La forma más fácil de almacenar información a largo plazo en un estado\n",
        "oculto es restringir las actualizaciones ocultas sobre cada iteración.\n",
        "Este enfoque evitará sobrescribir información importante a largo plazo.\n",
        "\n",
        "Puede encontrar la siguiente definición de GRU en internet:\n",
        "\n",
        "Se comienza calculando la puerta de actualización $z_t$ para el peso de\n",
        "tiempo $t$ usando la fórmula:\n",
        "\n",
        "$$\n",
        "\\begin{eqnarray*}\n",
        "z_{t} &=& \\sigma(W^{z}x_t + U^{z}h_{t-1}) \\hspace{1cm} \\mbox{Puerta de actualización}\\\\[0.2cm]\n",
        "\\end{eqnarray*}\n",
        "$$\n",
        "\n",
        "lo que sucede aquí es que cuando $x_t$ se conecta a la unidad de red, se\n",
        "multiplica por su propio peso $W^{z}$. Lo mismo ocurre con $h_{t-1}$,\n",
        "que contiene la información de las unidades $t-1$ anteriores y se\n",
        "múltiplica por su propio peso $U^{z}$. Ambos resultados se suman y se\n",
        "aplica una función de activación sigmoidea $(\\sigma)$ para acotar el\n",
        "resultado entre 0 y 1.\n",
        "\n",
        "![](fig_gru_1.png)\n",
        "\n",
        "La puerta de actualización ayuda al modelo a determinar cuánta\n",
        "información pasada (de pasos de tiempo anteriores) debe transmitirse al\n",
        "futuro. Esto es muy poderoso porque el modelo puede decidir copiar toda\n",
        "la la información del pasado y eliminar el riesgo de que desaparezca el\n",
        "problema de fuga del gradiente.\n",
        "\n",
        "Luego continuamos con Restablecer puerta:\n",
        "\n",
        "Básicamente, esta puerta se utiliza desde el modelo para decidir cuánta\n",
        "información pasada se debe olvidar. Para calcularlo utilizamos:\n",
        "\n",
        "$$\n",
        "r_t = \\sigma(W^{r}x_t + U^{r}h_{t-1})\\hspace{1cm} \\mbox{Restablecer puerta}\n",
        "$$\n",
        "\n",
        "Esta fórmula es la misma que la de la puerta de actualización. La\n",
        "diferencia viene en los pesos y el uso de la puerta, que veremos en un\n",
        "momento.\n",
        "\n",
        "![](fig_2_gru.png)\n",
        "\n",
        "Como antes, conectamos $h_{t-1} - \\mbox{linea azul}$ y\n",
        "$x_{t} - \\mbox{linea violeta}$, los multiplicamos con sus pesos\n",
        "correspondientes, sumamos los resultados y aplicamos la función\n",
        "sigmoidea.\n",
        "\n",
        "***Contenido de la memoria actual:***\n",
        "\n",
        "veamos como afectarán exactamente las puertaas al resultado final.\n",
        "Primero, comenzamos con el uso de la puerta de reinicio. Introducimos un\n",
        "nuevo contenido de memoria que utilizará la puerta de reinicio para\n",
        "almacenar la información del pasado. Se calcula de la siguiente manera:\n",
        "\n",
        "$$\n",
        "h_{t}^{\\prime} = tanh(Wx_{t} + r_{t}\\odot U h_{t-1})\n",
        "$$\n",
        "\n",
        "1.  Multiplique la entrada $x_t$ con un peso $W$ y $h_{t-1}$ con un peso\n",
        "    $U$.\n",
        "\n",
        "2.  Calcule el producto de Hadamard (por elementos) entre la puerta de\n",
        "    reinicio $r_t$ y $Uh_{t-1}$. Eso determinará qué eliminar de los\n",
        "    pasos de tiempo anterior. Digamos que tenemos un problema de\n",
        "    análisis de sentimientos para determinar la opinión de una persona\n",
        "    sobre un libro a partir de una reseña que escribió. El texto\n",
        "    comienza con *\"Este es un libro de fantasía que ilustra...\"* y\n",
        "    después de un par de párrafos termina con *\"No disfruté mucho el\n",
        "    libro porque creo que captura demasiados detalles\". Para determinar\n",
        "    el nivel general de satisfacción con el libro sólo necesitamos la\n",
        "    última parte de la reseña. En ese caso, a medida que la red neuronal\n",
        "    se acerque al final del texto, aprenderá a asignar un vector* $r_t$\n",
        "    cercano a 0, eliminando el pasado y centrándose solo en las últimas\n",
        "    oraciones.\n",
        "\n",
        "3.  Resuma los resultados de los pasos 1 y 2.\n",
        "\n",
        "4.  Aplicar la función de activación no lineal tanh.\n",
        "\n",
        "Puedes ver claramente los pasos aquí:\n",
        "\n",
        "![](fig_3_gru.png)\n",
        "\n",
        "Hacemos una multiplicación por elementos de\n",
        "$h_{t-1} - \\mbox{línea azul}$ y $r_t - \\mbox{línea naranja}$ y luego\n",
        "sumamos el resultado - linea rosa con la entrada $x_t -$ línea morada.\n",
        "Finalmente, tanh se usa para producir $h_{t}^{\\prime}:$ línea verde\n",
        "brillante.\n",
        "\n",
        "***Memoria final en el paso de tiempo actual***\n",
        "\n",
        "Como último paso, la red necesita calcular $h_{t}$, el vector que\n",
        "contiene información para la unidad actual y la transmite a la red. Para\n",
        "hacer eso, se necesita la puerta de actualización. Determina qué\n",
        "recopilar el contenido de la memoria actual $(h_t^{\\prime})$ y qué de\n",
        "los pasos anteriores $(h_{(t-1)})$. Eso se hace de la siguiente manera:\n",
        "\n",
        "$$\n",
        "h_t = z_t\\odot h_{t-1} + (1 - z_t)\\odot h_{t}^{\\prime}\n",
        "$$\n",
        "\n",
        "1.  Aplique la multiplicación por elementos a la puerta de actualización\n",
        "    $z_t$ y $h_{(t-1)}$.\n",
        "\n",
        "2.  Aplique la multiplicación por elementos a $(1- z_t)$ y\n",
        "    $h_{t}^{\\prime}$.\n",
        "\n",
        "3.  Sume los resultados de los pasos 1 y 2.\n",
        "\n",
        "Pongamos el ejemplo de la reseña del equilibrio. En esta ocasión, la\n",
        "información más relevante se situa al inicio del texto. El modelo puede\n",
        "aprender a establecer el vector $z_t$ cerca de 1 y conservar la mayor\n",
        "parte de la información anterior. Dado que $z_t$ estará cerca de 1 en\n",
        "este paso de tiempo, $(1-z_t)$ estará cerca de 0, lo que ignorará gran\n",
        "parte del contenido actual (en este caso, la última parte de la reseña\n",
        "que explica la trama del libro), lo cual es irrelevante para nuestra\n",
        "predicción.\n",
        "\n",
        "Aquí hay una ilustración que enfatiza la ecuación anterior:\n",
        "\n",
        "![](fig_4_gru.png)\n",
        "\n",
        "A continuación, puede ver cómo $z_t$ (línea verde) para calcular\n",
        "$1 - z_t$ que combinado con $h_{t}^{\\prime}$ (línea verde brillante),\n",
        "produce un resultado en la línea roja oscura. $z_t$ también se usa con\n",
        "$h_{t-1} - \\mbox{línea azul}$ en una multiplicación de elementos.\n",
        "Finalmente, $h_{t}:$ la línea azul es el resultado de la suma de las\n",
        "salidas correspondientes a las líneas rojas brillantes y oscuras.\n",
        "\n",
        "Ahora puede ver cómo las GRU pueden almacenar y filtrar la información\n",
        "utilizando sus puertas de actualización y reinicio. Eso elimina el\n",
        "problema del gradiente de fuga, ya que el modelo no elimina la nueva\n",
        "entrada cada vez, sino que mantiene la información relevante y la pasa a\n",
        "los siguientes pasos de la red. ***Si se les entrena cuidadosamente,\n",
        "pueden desempeñarse extremadamente bien incluso en escenarios\n",
        "complejos.***\n",
        "\n",
        "El modelo de predicción `GRU` es muy similar al `RNN`. Veamos su\n",
        "desempeño utilizando la misma data que el casa `RNN`.\n"
      ],
      "id": "28d12083"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "random.seed(1)\n",
        "torch.manual_seed(1)\n",
        "\n",
        "\n",
        "features = 240\n",
        "test_ts_len = 300\n",
        "gru_hidden_size = 24\n",
        "learning_rate = 0.02\n",
        "training_epochs = 500\n",
        "\n",
        "class GRU(nn.Module):\n",
        "\n",
        "    def __init__(self,\n",
        "                 hidden_size,\n",
        "                 in_size = 1,\n",
        "                 out_size = 1):\n",
        "        super(GRU, self).__init__()\n",
        "        self.gru = nn.GRU(\n",
        "            input_size = in_size,\n",
        "            hidden_size = hidden_size,\n",
        "            batch_first = True)\n",
        "        self.fc = nn.Linear(hidden_size, out_size)\n",
        "\n",
        "    def forward(self, x, h = None):\n",
        "        out, _ = self.gru(x, h)\n",
        "        last_hidden_states = out[:, -1]\n",
        "        out = self.fc(last_hidden_states)\n",
        "        return out, last_hidden_states\n",
        "\n",
        "# Inicializando el modelo GRU\n",
        "model = GRU(hidden_size = gru_hidden_size)\n",
        "model.train()\n",
        "\n",
        "# Entrenamiento\n",
        "optimizer = torch.optim.Adam(params = model.parameters(), lr = learning_rate)\n",
        "mse_loss = torch.nn.MSELoss()\n",
        "\n",
        "best_model = None\n",
        "min_val_loss = sys.maxsize\n",
        "\n",
        "training_loss = []\n",
        "validation_loss = []\n",
        "\n",
        "\n",
        "for t in range(training_epochs):\n",
        "\n",
        "    prediction, _ = model(x_train)\n",
        "    loss = mse_loss(prediction, y_train)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    val_prediction, _ = model(x_val)\n",
        "    val_loss = mse_loss(val_prediction, y_val)\n",
        "\n",
        "    training_loss.append(loss.item())\n",
        "    validation_loss.append(val_loss.item())\n",
        "\n",
        "    if val_loss.item() < min_val_loss:\n",
        "        best_model = copy.deepcopy(model)\n",
        "        min_val_loss = val_loss.item()\n",
        "\n",
        "    if t % 50 == 0:\n",
        "        print(f'epoch {t}: train - {round(loss.item(), 4)}, '\n",
        "              f'val: - {round(val_loss.item(), 4)}')\n",
        "\n",
        "best_model.eval()\n",
        "_, h_list = best_model(x_val)\n",
        "h = (h_list[-1, :]).unsqueeze(-2)\n",
        "\n",
        "predicted = []\n",
        "for test_seq in x_test.tolist():\n",
        "    x = torch.Tensor(data = [test_seq])\n",
        "    y, h = best_model(x, h.unsqueeze(-2))\n",
        "    unscaled = scaler.inverse_transform(np.array(y.item()).reshape(-1, 1))[0][0]\n",
        "    predicted.append(unscaled)\n"
      ],
      "id": "ff3a33e1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "real = scaler.inverse_transform(y_test.tolist())\n",
        "plt.title(\"Conjunto de datos prueba - GRU\")\n",
        "plt.plot(real, label = 'real')\n",
        "plt.plot(predicted, label = 'predicción')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "id": "75fe8cdc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vemos que el modelo `GRU` imita el comportamiento original de la serie\n",
        "temporal con bastante precisión.\n"
      ],
      "id": "7a88a0a6"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plt.title('Desempeño GRU')\n",
        "plt.yscale('log')\n",
        "plt.plot(training_loss, label = 'Entrenamiengto')\n",
        "plt.plot(validation_loss, label = 'validación')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "id": "3a0b0b9c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Las pérdidas de entrenamiento y validación tienen descenso asintótico\n",
        "con un brecha natural constante entre ellas. Podemos concluir que el\n",
        "modelo realmente aprende el comportamiento de la serie temporal.\n",
        "\n",
        "### Long short-term memory network (LSTM)\n",
        "\n",
        "La red `LSTM` se ha desarrollado para superar el problema de fuga de\n",
        "gradiente en `RNN` al mejorar el flujo de gradiente de la red. Debe\n",
        "mencionarse que la arquitectura apareció mucho antes que la GRU. La\n",
        "arquitectura LSTM se desarrolló en 1997, y el GRU se propueso en 2014.\n",
        "El diseño GRU es más simple y más comprensible que LSTM. Es por eso que\n",
        "comenzamos nuestro estudio examinando primero GRU.\n",
        "\n",
        "Como su nombre lo índica, LSTM aborda los mismos problemas de memoria a\n",
        "corto y largo plazo que GRU. A nivel global, el flujo computacional del\n",
        "LSTM se ve de la siguiente manera:\n",
        "\n",
        "![](Figure%204.16.png)\n",
        "\n",
        "LSTM funciona sobre los principios similares que GRU pero tiene más\n",
        "variables. RNN y GRU solo pasan un estado oculto $h_t$ a través de cada\n",
        "iteración. Pero LSTM pasa dos vectores:\n",
        "\n",
        "-   $h_t$ estado oculto (memoria a corto plazo)\n",
        "\n",
        "-   $c_t$ estado de celda (memoria a largo plazo)\n",
        "\n",
        "Las salidas de `LSTM Cell` se calculan a través de las fórmulas:\n",
        "\n",
        "$$\n",
        "\\begin{eqnarray*}\n",
        "i_t &=& \\sigma(W_{ii}x_t + b_{ii} + W_{hi}h_{t-1} + b_{hi})\\\\[0.2cm]\n",
        "f_t &=& \\sigma(W_{ii}x_{t} + b_{if} + W_{hf}h_{t-1} + b_{hf})\\\\[0.2cm]\n",
        "g_t &=& tanh(W_{ig}x_t + b_{ig} + W_{hg}h_{t-1} + b_{hn})\\\\[0.2cm]\n",
        "o_t &=& \\sigma(W_{io}x_t + b_{io} + W_{ho}h_{t-1} + b_{ho})\\\\[0.2cm]\n",
        "c_t &=& f_t \\circ c_{t-1} + i_t\\circ g_t\\\\[0.2cm]\n",
        "h_t &=& o_t \\circ tanh(c_t)\n",
        "\\end{eqnarray*}\n",
        "$$\n",
        "\n",
        "donde:\n",
        "\n",
        "-   $\\sigma$ es la función sigmoidea\n",
        "\n",
        "-   $\\circ$ es el producto de Hadamard\n",
        "\n",
        "En cuanto a las variables:\n",
        "\n",
        "-   $i_t~(puerta de entrada)$ es la variable que se utiliza para\n",
        "    actualizar el estado $c_t$. El estado previamente oculto $h_t$ y la\n",
        "    secuencia $x_t$ se dan como entradas a una función sigmoidea\n",
        "    $(\\sigma)$. Si la salida está cerca de 1, entonces la información es\n",
        "    más importante.\n",
        "\n",
        "-   $f_t ~ (puerta~de~olvido)$ es la variable que decide que información\n",
        "    debe olvidarse en el estado $c_t$. El estado $h_t$ de estado\n",
        "    previamente oculto y la secuencia $x_t$ se dan como entradas a una\n",
        "    función sigmoidea. Si la salida $f_t$ está cerca de cero, la\n",
        "    información se puede olvidar, mientras que si la salida está cerca\n",
        "    de 1, la información debe almacenarse o recordarse.\n",
        "\n",
        "-   $g_t$ representa información importante potencialmente nueva para el\n",
        "    estado $c_t$.\n",
        "\n",
        "-   $c_t ~ (estado~celda)$ es una suma de:\n",
        "\n",
        "    -   estado de celda anterior $c_{t-1}$ con información olvidada\n",
        "        $f_t$.\n",
        "\n",
        "    -   nueva información de $g_t$ seleccionada por $i_t$\n",
        "\n",
        "-   $o_t ~ (puerta~de~salida)$ es la variable para actualizar el estado\n",
        "    oculto $h_t$.\n",
        "\n",
        "-   $h_t ~(estado~oculto)$ es el siguiente estado oculto que se calcula\n",
        "    eligiendo la información importante del estado de celda o celular\n",
        "    $c_t$.\n",
        "\n",
        "A continuación te muestro el gráfico computacional de la celda LSTM:\n",
        "\n",
        "![](Figure%204.17%20.png)\n",
        "\n",
        "LSTM tiene los siguientes parámetros, que se ajustan durante el\n",
        "entrenamiento:\n",
        "\n",
        "-   $W_{ii}, W_{hi}, W_{if}, W_{hf}, W_{ig}, W_{hg}, W_{io}, W_{ho}$\n",
        "    estos son los pesos.\n",
        "\n",
        "-   $b_{ii}, b_{hi}, b_{if}, b_{hf}, b_{ig}, b_{hg}, b_{io}, b_{ho}$\n",
        "    estos son sesgos.\n",
        "\n",
        "Ahora examinemos la implementación de Pytorch del modelo de predicción\n",
        "LSTM:\n"
      ],
      "id": "6b524dd4"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class LSTM(nn.Module):\n",
        "\n",
        "    def __init__(self,\n",
        "                 hidden_size,\n",
        "                 in_size = 1,\n",
        "                 out_size = 1):\n",
        "        super(LSTM, self).__init__()\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size = in_size,\n",
        "            hidden_size = hidden_size,\n",
        "            batch_first = True)\n",
        "        self.fc = nn.Linear(hidden_size, out_size)\n",
        "\n",
        "    def forward(self, x, h = None):\n",
        "        out, h = self.lstm(x, h)\n",
        "        last_hidden_states = out[:, -1]\n",
        "        out = self.fc(last_hidden_states)\n",
        "        return out, h"
      ],
      "id": "6ee82335",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Como vemos, la implementación del modelo `LSTM` es bastante similar a\n",
        "las implementaciones de `RNN` y `GRU`.\n",
        "\n",
        "Probaremos el modelo LSTM con el siguiente conjunto de datos de la serie\n",
        "tiempo de consumo de energía por hora).\n"
      ],
      "id": "3902ce66"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "df = pd.read_csv('NI_hourly.csv')\n",
        "ts = df['NI_MW'].astype(int).values.reshape(-1, 1)[-3000:]\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.title('NI Hourly')\n",
        "plt.plot(ts[:500])\n",
        "plt.show()"
      ],
      "id": "fd0ea3ba",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Veamos el modelo en acción:\n"
      ],
      "id": "5dc496c2"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import copy\n",
        "import random\n",
        "import sys\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "random.seed(1)\n",
        "torch.manual_seed(1)\n",
        "\n",
        "\n",
        "features = 240\n",
        "test_ts_len = 300\n",
        "lstm_hidden_size = 24\n",
        "learning_rate = 0.02\n",
        "training_epochs = 100\n",
        "\n",
        "# Preparar el conjunto de datos para el entrenamiento \n",
        "scaler = MinMaxScaler()\n",
        "scaled_ts = scaler.fit_transform(ts)\n",
        "x_train, x_val, x_test, y_train, y_val, y_test =\\\n",
        "    get_training_datasets(scaled_ts, features, test_ts_len)\n",
        "\n",
        "# Inicializando el modelo \n",
        "model = LSTM(hidden_size = lstm_hidden_size)\n",
        "model.train()\n",
        "\n",
        "# Entrenamiento \n",
        "optimizer = torch.optim.Adam(params = model.parameters(), lr = learning_rate)\n",
        "mse_loss = torch.nn.MSELoss()\n",
        "\n",
        "best_model = None\n",
        "min_val_loss = sys.maxsize\n",
        "\n",
        "training_loss = []\n",
        "validation_loss = []\n",
        "\n",
        "\n",
        "for t in range(training_epochs):\n",
        "\n",
        "    prediction, _ = model(x_train)\n",
        "    loss = mse_loss(prediction, y_train)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    val_prediction, _ = model(x_val)\n",
        "    val_loss = mse_loss(val_prediction, y_val)\n",
        "\n",
        "    training_loss.append(loss.item())\n",
        "    validation_loss.append(val_loss.item())\n",
        "\n",
        "    if val_loss.item() < min_val_loss:\n",
        "        best_model = copy.deepcopy(model)\n",
        "        min_val_loss = val_loss.item()\n",
        "\n",
        "    if t % 10 == 0:\n",
        "        print(f'epoch {t}: train - {round(loss.item(), 4)}, '\n",
        "              f'val: - {round(val_loss.item(), 4)}')"
      ],
      "id": "41555165",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Para una evaluación del modelo LSTM, necesitamos pasar un estado celular\n",
        "y estado oculto.\n"
      ],
      "id": "3ab89834"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "best_model.eval()\n",
        "with torch.no_grad():\n",
        "    _, h_list = best_model(x_val)\n",
        "\n",
        "    h = tuple([(h[-1, -1, :]).unsqueeze(-2).unsqueeze(-2)\n",
        "               for h in h_list])\n",
        "\n",
        "    predicted = []\n",
        "    for test_seq in x_test.tolist():\n",
        "        x = torch.Tensor(data = [test_seq])\n",
        "\n",
        "        y, h = best_model(x, h)\n",
        "        unscaled = scaler.inverse_transform(\n",
        "            np.array(y.item()).reshape(-1, 1))[0][0]\n",
        "        predicted.append(unscaled)\n",
        "        \n",
        "real = scaler.inverse_transform(y_test.tolist())\n",
        "plt.title(\"Conjunto de prueba - LSTM\")\n",
        "plt.plot(real, label = 'real')\n",
        "plt.plot(predicted, label = 'predicción')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "id": "a1dd3648",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "LSTM captura muy bien el comportamiento de las series temporales para\n",
        "hacer predicciones precisas.\n"
      ],
      "id": "65855b99"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plt.title('Desempeño LSTM')\n",
        "plt.yscale('log')\n",
        "plt.plot(training_loss, label = 'Entrenamiento')\n",
        "plt.plot(validation_loss, label = 'validación')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "id": "e7be298e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Mirando, concluimos que detuvimos el proceso de entrenamiento demasiado\n",
        "temprano. Obtenemos modelos más precisos si establecemos más epocas\n",
        "(epoch) para el entrenamiento.\n",
        "\n",
        "### CONCLUSIONES\n",
        "\n",
        "Pudimos ver que las redes neuronales recurrentes muestran excelentes\n",
        "resultados y son adecuadas para problemas de pronósticos de series de\n",
        "tiempo.\n",
        "\n",
        "Las Redes Neuronales Recurrentes son la técnica muy popular de\n",
        "aprendizaje profundo (Deep Learning) para el pronóstico de series de\n",
        "tiempo, ya que permiten producir predicciones confiables en series de\n",
        "tiempo en diversos problemas. El principal problema con RNN es que sufre\n",
        "el problema de fuga de gradiente cuando se aplica a secuencia largas, y\n",
        "no tiene una herramienta de memoria a largo plazo. Se desarrollaron LSTM\n",
        "y GRU para evitar el problema de gradiente de RNN con el uso de puertas\n",
        "que regulan el flujo de información e implementan el almacenamiento de\n",
        "memoria a largo plazo. El uso de LSTM y GRU ofrece resultados notables,\n",
        "pero LSTM y GRU no siempre funcionan mejor que RNN.\n",
        "\n",
        "-   `RNN` tiene un estado oculto que puede tratarse como una memoria\n",
        "    interna de la secuencia de entrada.\n",
        "\n",
        "-   `RNN` vuelve a calcular el estado oculto después de procesar cada\n",
        "    nuevo valor de entrada de forma recurrente.\n",
        "\n",
        "-   `RNN` sufre un problema de fuga de gradiente.\n",
        "\n",
        "-   `RNN` actualiza un estado oculto en cada iteración. Por tanto, no\n",
        "    tiene memoria a largo plazo.\n",
        "\n",
        "-   `GRU` implementa la puerta de reinicio, que rechaza algunas\n",
        "    actualizaciones en un estado oculto.\n",
        "\n",
        "-   `LSTM` pasa dos vectores a través de cada iteración: *estado oculto*\n",
        "    y *estado de celda.*\n",
        "\n",
        "### REFERENCIAS\n",
        "\n",
        "-   Time Series Forecasting Using Deep Learning - Ivan Gridin\n",
        "\n",
        "-   [Understanding GRU\n",
        "    Networks](https://towardsdatascience.com/understanding-gru-networks-2ef37df6c9be)\n",
        "\n",
        "### "
      ],
      "id": "870904d3"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "/Users/juanisaulamejia/opt/anaconda3/share/jupyter/kernels/python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}