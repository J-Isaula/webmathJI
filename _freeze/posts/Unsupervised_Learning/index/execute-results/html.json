{
  "hash": "61c6ddd4b77a832de61e821d17cf3aee",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Aprendizaje No Supervisado\"\nsubtitle: \"Python\"\nauthor: \"Juan Isaula\"\ndate: \"2025-09-07\"\ncategories: [Python]\nimage: \"fondo.png\"\n---\n\n\nSupongamos que tiene una colección de clientes con diversas características, como *edad, ubicación e historial financiero*, y deseas descubrir patrones y clasificarlos en grupos. O quizás tengas un conjunto de textos, como páginas de Wikipedia, y quieras segmentarlos en categorías en función de su contenido. Este es el mundo del aprendizaje no supervizado, llamado así porque no estás guiando, o supervisando, el descubrimiento de patrones mediante alguna tarea de predicción, sino descubriendo la estructura oculta a partir de datos no etiquetados. El aprendizaje no supervizado engloba diversas técnicas de aprendizaje automático, desde la agrupación hasta la reducción de dimensiones y la factorización de matrices. En este artículo, aprenderás los fundamentos de **aprendizaje no supervizado** e implementarás los algoritmos esenciales utilizando `scikit-learn` y `SciPy`. Aprenderás a agrupar, transformar, visualizar y extraer información de conjuntos de datos no etiquetados.\n\n# Agrupación para la exploración de conjuntos de datos\n\nEl objetivo de esta sección es aprender a descubrir los grupos subyacentes (o clústeres) en un conjunto de datos. En esta sección aprendera a agrupar empresas utilizando sus cotizaciones bursátiles,y distinguir diferentes especies agrupando sus medidas.\n\n## Aprendizaje no supervizado \n\nEl aprendizaje no supervizado es una clase de técnica de aprendizaje automático para descrubrir patrones en los datos. Por ejemplo:\n\n-   Encontrar los grupos naturales de clientes en función de sus historiales de compras o buscar:\n\n-   Patrones y correlaciones entre estas compras, y utilizar estos patrones para expresar los datos en forma comprimida.\n\nEstos son ejemplos de técnicas de aprendizaje no supervizadas llamadas *agrupación* y *reducción de dimensiones.*\n\n> El aprendizaje no supervizado se define en oposición al aprendizaje supervizado.\n\n-   Un ejemplo de ***aprendizaje supervisado*** es utilizar las medidas de los tumores para clasificarlos como benignos o cancerosos. En este caso, el descubrimiento de patrones es guiado o supervizado, de modo que los patrones son lo más utilies posible para predecir la etiqueta: benigno o canceroso.\n\n-   El ***aprendizaje no supervisado***, por el contrario, es un aprendizaje sin etiquetas. Es puro descubrimiento de patrones, sin la guía de una tarea de predicción.\n\n### Iris dataset \n\nEl conjunto de datos iris consta de mediciones de muchas plantas iris de tres especies diferentes:\n\n-   Setosa\n\n-   Versicolor\n\n-   Virginica\n\nHay cuatro medidas:\n\n1.  Largo de pétalo (Petal length)\n\n2.  Ancho de pétalo (Petal width)\n\n3.  Largo de sépalo (Sepal length)\n\n4.  Ancho de sépalo (sepal width)\n\nEstas son las características del conjunto de datos.\n\n#### Matrices, características y muestras \n\nConjuntos de datos como este (iris) se escribiran como matrices numerosas bidimensionales.\n\n-   Las columnas de la matriz corresponderán a las características.\n\n-   Las medidas de plantas individuales son las muestras del conjunto de datos, estas corresponden a filas de la matriz.\n\n#### Iris datases es 4-dimensional \n\nLas muestras del conjunto de datos iris tienen cuatro medidas y, por lo tanto, corresponden a puntos en un espacio de cuatro dimensiones. Es decir:\n\n-   Dimensiones = número de características o features.\n\nNo podemos visualizar cuatro dimensiones directamente, pero utilizando técnicas de aprendizaje no supervizado aún podemos obtener información.\n\n### K-Means Clustering \n\nAgruparemos estas muestras utilizando la agrupación de k-Means. K-Means encuentra un número específico de grupos en las muestras. Está implementado en la biblioteca de `scikit-learn` o `sklearn`.\n\nVeamos KMeans en acción con el conjunto de datos iris.\n\n::: {#15964fad .cell execution_count=1}\n``` {.python .cell-code}\nimport pandas as pd         \nfrom sklearn import datasets    # Librería utilizada para importar iris dataset\niris = datasets.load_iris()     # importamos el conjunto de datos iris\n\niris = pd.DataFrame(iris.data, columns = iris.feature_names) # Convertimos iris a dataframe\n```\n:::\n\n\nPara comenzar:\n\n1.   Importamos KMeans de scikit-learn.\n\n2.  Luego creamos un modelo KMeans, especificando la cantidad de clústeres que deseamos encontrar con `n_clusters` especificamos n_cluster = 3, ya que hay tres especies de iris.\n\n3.  Posteriormente, llamamos el método de ajuste del modelo `.fit()`, pasando la matriz del iris dataset. Esto ajusta el modelo a los datos, localizando y recordando las regiones donde ocurren los diferentes grupos.\n\n4.  Por último, podemos utilizar el método de predicción del modelo en este mismo conjunto de datos.\n\n::: {#7b938af7 .cell execution_count=2}\n``` {.python .cell-code}\nfrom sklearn.cluster import KMeans\n\nmodel = KMeans(n_clusters = 3, random_state = 42)\nmodel.fit(iris)\n```\n\n::: {.cell-output .cell-output-display execution_count=2}\n```{=html}\n<style>#sk-container-id-1 {\n  /* Definition of color scheme common for light and dark mode */\n  --sklearn-color-text: #000;\n  --sklearn-color-text-muted: #666;\n  --sklearn-color-line: gray;\n  /* Definition of color scheme for unfitted estimators */\n  --sklearn-color-unfitted-level-0: #fff5e6;\n  --sklearn-color-unfitted-level-1: #f6e4d2;\n  --sklearn-color-unfitted-level-2: #ffe0b3;\n  --sklearn-color-unfitted-level-3: chocolate;\n  /* Definition of color scheme for fitted estimators */\n  --sklearn-color-fitted-level-0: #f0f8ff;\n  --sklearn-color-fitted-level-1: #d4ebff;\n  --sklearn-color-fitted-level-2: #b3dbfd;\n  --sklearn-color-fitted-level-3: cornflowerblue;\n\n  /* Specific color for light theme */\n  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-icon: #696969;\n\n  @media (prefers-color-scheme: dark) {\n    /* Redefinition of color scheme for dark theme */\n    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-icon: #878787;\n  }\n}\n\n#sk-container-id-1 {\n  color: var(--sklearn-color-text);\n}\n\n#sk-container-id-1 pre {\n  padding: 0;\n}\n\n#sk-container-id-1 input.sk-hidden--visually {\n  border: 0;\n  clip: rect(1px 1px 1px 1px);\n  clip: rect(1px, 1px, 1px, 1px);\n  height: 1px;\n  margin: -1px;\n  overflow: hidden;\n  padding: 0;\n  position: absolute;\n  width: 1px;\n}\n\n#sk-container-id-1 div.sk-dashed-wrapped {\n  border: 1px dashed var(--sklearn-color-line);\n  margin: 0 0.4em 0.5em 0.4em;\n  box-sizing: border-box;\n  padding-bottom: 0.4em;\n  background-color: var(--sklearn-color-background);\n}\n\n#sk-container-id-1 div.sk-container {\n  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n     but bootstrap.min.css set `[hidden] { display: none !important; }`\n     so we also need the `!important` here to be able to override the\n     default hidden behavior on the sphinx rendered scikit-learn.org.\n     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n  display: inline-block !important;\n  position: relative;\n}\n\n#sk-container-id-1 div.sk-text-repr-fallback {\n  display: none;\n}\n\ndiv.sk-parallel-item,\ndiv.sk-serial,\ndiv.sk-item {\n  /* draw centered vertical line to link estimators */\n  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n  background-size: 2px 100%;\n  background-repeat: no-repeat;\n  background-position: center center;\n}\n\n/* Parallel-specific style estimator block */\n\n#sk-container-id-1 div.sk-parallel-item::after {\n  content: \"\";\n  width: 100%;\n  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n  flex-grow: 1;\n}\n\n#sk-container-id-1 div.sk-parallel {\n  display: flex;\n  align-items: stretch;\n  justify-content: center;\n  background-color: var(--sklearn-color-background);\n  position: relative;\n}\n\n#sk-container-id-1 div.sk-parallel-item {\n  display: flex;\n  flex-direction: column;\n}\n\n#sk-container-id-1 div.sk-parallel-item:first-child::after {\n  align-self: flex-end;\n  width: 50%;\n}\n\n#sk-container-id-1 div.sk-parallel-item:last-child::after {\n  align-self: flex-start;\n  width: 50%;\n}\n\n#sk-container-id-1 div.sk-parallel-item:only-child::after {\n  width: 0;\n}\n\n/* Serial-specific style estimator block */\n\n#sk-container-id-1 div.sk-serial {\n  display: flex;\n  flex-direction: column;\n  align-items: center;\n  background-color: var(--sklearn-color-background);\n  padding-right: 1em;\n  padding-left: 1em;\n}\n\n\n/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\nclickable and can be expanded/collapsed.\n- Pipeline and ColumnTransformer use this feature and define the default style\n- Estimators will overwrite some part of the style using the `sk-estimator` class\n*/\n\n/* Pipeline and ColumnTransformer style (default) */\n\n#sk-container-id-1 div.sk-toggleable {\n  /* Default theme specific background. It is overwritten whether we have a\n  specific estimator or a Pipeline/ColumnTransformer */\n  background-color: var(--sklearn-color-background);\n}\n\n/* Toggleable label */\n#sk-container-id-1 label.sk-toggleable__label {\n  cursor: pointer;\n  display: flex;\n  width: 100%;\n  margin-bottom: 0;\n  padding: 0.5em;\n  box-sizing: border-box;\n  text-align: center;\n  align-items: start;\n  justify-content: space-between;\n  gap: 0.5em;\n}\n\n#sk-container-id-1 label.sk-toggleable__label .caption {\n  font-size: 0.6rem;\n  font-weight: lighter;\n  color: var(--sklearn-color-text-muted);\n}\n\n#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n  /* Arrow on the left of the label */\n  content: \"▸\";\n  float: left;\n  margin-right: 0.25em;\n  color: var(--sklearn-color-icon);\n}\n\n#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n  color: var(--sklearn-color-text);\n}\n\n/* Toggleable content - dropdown */\n\n#sk-container-id-1 div.sk-toggleable__content {\n  max-height: 0;\n  max-width: 0;\n  overflow: hidden;\n  text-align: left;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-1 div.sk-toggleable__content.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-1 div.sk-toggleable__content pre {\n  margin: 0.2em;\n  border-radius: 0.25em;\n  color: var(--sklearn-color-text);\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n  /* unfitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n  /* Expand drop-down */\n  max-height: 200px;\n  max-width: 100%;\n  overflow: auto;\n}\n\n#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n  content: \"▾\";\n}\n\n/* Pipeline/ColumnTransformer-specific style */\n\n#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator-specific style */\n\n/* Colorize estimator box */\n#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n#sk-container-id-1 div.sk-label label {\n  /* The background is the default theme color */\n  color: var(--sklearn-color-text-on-default-background);\n}\n\n/* On hover, darken the color of the background */\n#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n/* Label box, darken color on hover, fitted */\n#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator label */\n\n#sk-container-id-1 div.sk-label label {\n  font-family: monospace;\n  font-weight: bold;\n  display: inline-block;\n  line-height: 1.2em;\n}\n\n#sk-container-id-1 div.sk-label-container {\n  text-align: center;\n}\n\n/* Estimator-specific */\n#sk-container-id-1 div.sk-estimator {\n  font-family: monospace;\n  border: 1px dotted var(--sklearn-color-border-box);\n  border-radius: 0.25em;\n  box-sizing: border-box;\n  margin-bottom: 0.5em;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-1 div.sk-estimator.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n/* on hover */\n#sk-container-id-1 div.sk-estimator:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-1 div.sk-estimator.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Specification for estimator info (e.g. \"i\" and \"?\") */\n\n/* Common style for \"i\" and \"?\" */\n\n.sk-estimator-doc-link,\na:link.sk-estimator-doc-link,\na:visited.sk-estimator-doc-link {\n  float: right;\n  font-size: smaller;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1em;\n  height: 1em;\n  width: 1em;\n  text-decoration: none !important;\n  margin-left: 0.5em;\n  text-align: center;\n  /* unfitted */\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n  color: var(--sklearn-color-unfitted-level-1);\n}\n\n.sk-estimator-doc-link.fitted,\na:link.sk-estimator-doc-link.fitted,\na:visited.sk-estimator-doc-link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\ndiv.sk-estimator:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\ndiv.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n/* Span, style for the box shown on hovering the info icon */\n.sk-estimator-doc-link span {\n  display: none;\n  z-index: 9999;\n  position: relative;\n  font-weight: normal;\n  right: .2ex;\n  padding: .5ex;\n  margin: .5ex;\n  width: min-content;\n  min-width: 20ex;\n  max-width: 50ex;\n  color: var(--sklearn-color-text);\n  box-shadow: 2pt 2pt 4pt #999;\n  /* unfitted */\n  background: var(--sklearn-color-unfitted-level-0);\n  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n}\n\n.sk-estimator-doc-link.fitted span {\n  /* fitted */\n  background: var(--sklearn-color-fitted-level-0);\n  border: var(--sklearn-color-fitted-level-3);\n}\n\n.sk-estimator-doc-link:hover span {\n  display: block;\n}\n\n/* \"?\"-specific style due to the `<a>` HTML tag */\n\n#sk-container-id-1 a.estimator_doc_link {\n  float: right;\n  font-size: 1rem;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1rem;\n  height: 1rem;\n  width: 1rem;\n  text-decoration: none;\n  /* unfitted */\n  color: var(--sklearn-color-unfitted-level-1);\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n}\n\n#sk-container-id-1 a.estimator_doc_link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\n#sk-container-id-1 a.estimator_doc_link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n}\n</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KMeans(n_clusters=3, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>KMeans</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.cluster.KMeans.html\">?<span>Documentation for KMeans</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>KMeans(n_clusters=3, random_state=42)</pre></div> </div></div></div></div>\n```\n:::\n:::\n\n\n::: {#35544bf7 .cell execution_count=3}\n``` {.python .cell-code}\nlabels = model.predict(iris)\nspecies_ = labels\nprint(labels)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 0 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 0 0 0 0 2 0 0 0 0\n 0 0 2 2 0 0 0 0 2 0 2 0 2 0 0 2 2 0 0 0 0 0 2 0 0 0 0 2 0 0 0 2 0 0 0 2 0\n 0 2]\n```\n:::\n:::\n\n\nEsto nos devuelve una etiqueta de grupo para cada muestra, que indica a qué grupo pertenece una muestra.\n\n#### Etiquetas de clúster para nuevas muestras \n\nSi alguien viene con un algún dataset iris nuevo, kMeans puede determinar a qué grupos pertenecen sin tener que empezar de nuevo.\n\nKMeans hace esto recordando la media (o promedio) de las muestras en cada grupo. Estos se llaman **centroides** se asignan nuevas muestras al grupo cuyo centroide esté más cercano.\n\nVoy a tomar 3 registros aleatorios del dataset iris y asumiremos que estas son muestras nuevas.\n\n::: {#4540d628 .cell execution_count=4}\n``` {.python .cell-code}\nnew_samples = iris.sample(n = 3, random_state = 42)\nprint(new_samples)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n73                 6.1               2.8                4.7               1.2\n18                 5.7               3.8                1.7               0.3\n118                7.7               2.6                6.9               2.3\n```\n:::\n:::\n\n\nPara asignar las nuevas muestras a los grupos existentes, pasaremos el conjunto de nueva muestra al método de predicción del modelo kmeans.\n\n::: {#b3da6edf .cell execution_count=5}\n``` {.python .cell-code}\nnew_labels = model.predict(new_samples)\nprint(new_labels)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[2 1 0]\n```\n:::\n:::\n\n\nComo puede observar, esto devuelve las etiquetas de grupo para los datos nuevos o muestra de datos nueva.\n\n> En la siguiente sección aprenderá cómo evaluar la calidad de su agrupación.\n\n#### Scatter Plots\n\nPor ahora, visualizaremos nuestra agrupación de las muestras de iris usando diagramas de dispersión. A continuación se muestra un diagrama de dispersión de la longitud del sépalo frente a la longitud del pétalo del dataset iris.\n\n![](img/fig1.png){fig-align=\"center\" width=\"300\"}\n\nCada punto representa una muestra de iris y está coloreada según el grupo de la muestra. Para crear un diagrama de dispersión como este, usaremos `PyPlot`.\n\n-   La longitud del sépalo está en la columna 0 de la matriz iris, mientras que la longitud de los pétalos está en la segunda columna.\n\n-   Y labels o etiquetas que encontramos previamente lo usamos para colorear por etiqueta de clúster como un paramétro en `.scatter()`.\n\n::: {#392c0adb .cell execution_count=6}\n``` {.python .cell-code}\nimport matplotlib.pyplot as plt \n\nxs = iris.iloc[:, 0]   # Longitud de los sépalos \nys = iris.iloc[:, 2]   # Longitud de los pétalos\n\nplt.scatter(xs, ys, c = labels)\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-7-output-1.png){width=558 height=411}\n:::\n:::\n\n\nAhora, calculemos las coordenadas de los centroides utilizando el atributo `.cluster_centers_` de `model`. y asignaremos la columna 0 de `centroids` a `centroids_x`, y la columna 2 de `centroids` a `centroids_y`. Posterior a ello, realizaremos un diagrama de dispersión de centroids_x y centroids_y, utilizando `marker = 'D'` (un rombo) como marcador especificando el parámetro marker. El tamaño de los marcadores en 50 utilizando `s = 50`.\n\n::: {#83601dd7 .cell execution_count=7}\n``` {.python .cell-code}\nxs = iris.iloc[:, 0]   # Longitud de los sépalos \nys = iris.iloc[:, 2]   # Longitud de los pétalos\n\nplt.scatter(xs, ys, c = labels, alpha = 0.5)\ncentroids = model.cluster_centers_\n\ncentroids_x = centroids[:,0]\ncentroids_y = centroids[:,2]\n\nplt.scatter(centroids_x, centroids_y, marker = 'D', s = 50)\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-8-output-1.png){width=558 height=411}\n:::\n:::\n\n\n## Evaluar una agrupación \n\nEn la sección anterior, utilizamos KMeans para agrupar el dataset de iris en tres grupos. Pero **¿cómo podemos evaluar la calidad de esta agrupación?**\n\nUn enfoque directo es comparar los grupos con las especies de iris. Primero aprenderá sobre esto, antes de considerar el problema de cómo medir la calidad de una agrupación de una manera que no requiera que nuestras muestras vengan preagrupadas en especies. Esta medida de calidad puede utilizarse más adelante para tomar una decisión informada sobre el número de conglomerados a buscar.\n\n### Iris: Clusters vs Especies\n\nEn primer lugar, comprobemos si los 3 grupos de muestras de iris tienen alguna correspondencia con la especie de iris.\n\nLa correspondencia se describe en esta tabla:\n\n![](img/fig2.png){fig-align=\"center\" width=\"400\"}\n\nExiste una columna para cada una de las tres especies de iris: setosa, versicolor y virginica, y una fila para cada una de las tres etiquetas de grupo: 0, 1 y 2.\n\nLa tabla muestra el número de muestras que tienen cada combinación posible de etiquetas de grupo/especie. Por ejemplo:\n\n-   Vemos que el grupo 0 se corresponde perfectamente con la especie setosa.\n\n-   Por otro lado, mientras que el cluster 1 contiene principalmente muestras de virginica en el grupo 2.\n\nTablass como esta, se denominan **tabulaciones cruzadas** o **Cross tabulation**\n\n### Cross Tabulation con Pandas\n\nPara construir uno, usareos la biblioteca `pandas.` Como podemos observar en el bloque de código siguiente, creamos un dataframe de dos columnas, donde la primera columna son las etiquetas del grupo y la segunda son las especies de iris, de modo que cada fila proporciona la etiqueta del grupo y la especie de una sola muestra.\n\n::: {#1f7fc404 .cell execution_count=8}\n``` {.python .cell-code}\niris_raw = datasets.load_iris() \niris = pd.DataFrame(iris_raw.data, columns = iris_raw.feature_names)\n# Agregamos columna de especie verdadera al dataframe iiris\nspecies = pd.Categorical.from_codes(iris_raw.target, iris_raw.target_names)\n\n# \n\ndf = pd.DataFrame({'labels':labels, 'species':species})\nprint(df)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     labels    species\n0         1     setosa\n1         1     setosa\n2         1     setosa\n3         1     setosa\n4         1     setosa\n..      ...        ...\n145       0  virginica\n146       2  virginica\n147       0  virginica\n148       0  virginica\n149       2  virginica\n\n[150 rows x 2 columns]\n```\n:::\n:::\n\n\nAhora usamos la función de tabla cruzuda de pandas para crear la tubulación cruzada, pasando las dos columnas del DataFrame.\n\n::: {#04c0d743 .cell execution_count=9}\n``` {.python .cell-code}\nct = pd.crosstab(df['labels'], df['species'])\nprint(ct)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nspecies  setosa  versicolor  virginica\nlabels                                \n0             0           3         36\n1            50           0          0\n2             0          47         14\n```\n:::\n:::\n\n\nTabulaciones cruzadas como estás proporcionan información valiosa sobre qué tipo de muestras se encuentran en qué grupo. Pero la mayoría de los conjuntos de datos, las muestras no están etiquetadas por especie.\n\n**¿Cómo se puede evaluar la calidad de un clustering en estos casos?**\n\n### Medición de la calidad de la agrupación \n\nUna buena agrupación tiene grupos compactos, lo que significa que las muestras de cada grupo están agrupadas, no dispersas.\n\nLa **inercia** puede medir la distribución de las muestras dentro de cada grupo. Intuitivamente, la inercia mide qué tan lejos están las muestras de sus centroides. Puede encontrar la definición precisa en la documentación de scikit-learn. Queremos grupos que no estén dispersos, por lo que los valores más bajos de inercia son mejores.\n\nLa inercia de un modelo KMeans se mide automaticamente cuando se llama al metodo de ajuste .fit y luego están disponibles como atributos de `inertia_`.\n\nDe hecho, KMeans pretende colocar los clusters de forma que se minimice la inercia.\n\n::: {#f4998667 .cell execution_count=10}\n``` {.python .cell-code}\nmodel = KMeans(n_clusters = 3, random_state = 42)\nmodel.fit(iris)\nprint(model.inertia_)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n78.8556658259773\n```\n:::\n:::\n\n\nA continuación se muestra un gráfico de los valores de inercia de las agrupaciones del conjunto de datos de iris con diferentes números de agrupaciones.\n\n![](img/fig3.png){fig-align=\"center\" width=\"400\"}\n\nNuestro modelo KMeans con 3 grupos tiene una inercia relativamente baja, lo cual es genial. Pero observe que la incercia continúa disminuyendo lentamente. Entonces, **¿cuál es la mejor cantidad de clústeres para elegir?** En última instacia se trata de una compensación.\n\nUna buena agrupación tiene agrupaciones estrechas (lo que significa inercia baja). Pero tampoco tiene demasiados grupos.\n\nUna buena regla general es elegir un codo en el gráfico de inercia, es decir, un punto donde la inercia comienza a disminuir más lentamente.\n\nPor ejemplo, según este criterio, 3 es un buen número de grupos para el conjunto de datos del iris.\n\n::: {#70a89445 .cell execution_count=11}\n``` {.python .cell-code}\nks = range(1, 11)\ninertias = []\n\nfor k in ks:\n    model = KMeans(n_clusters=k, random_state=42)\n    model.fit(iris)\n    inertias.append(model.inertia_)   # suma de distancias cuadradas intracluster\n\nplt.plot(ks, inertias, '-o')\nplt.xlabel('número de clusters')\nplt.ylabel('inertia')\nplt.xticks(ks)\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-12-output-1.png){width=593 height=429}\n:::\n:::\n\n\n## Transformación de Características para mejorar agrupaciones \n\nVeamos ahora otro conjunto de datos, el conjunto de datos de los vinos del Piamonte.\n\n-   Disponemos de 178 muestras de vino tinto de la región de Piamonte de Italia.\n\n-   Las entradas o features miden la composición química (como el contendio del alcohol) y propiedades visuales como la intensidad del color.\n\n-   Las muestras proceden de 3 variedades distintas de vino.\n\n::: {#43801fe5 .cell execution_count=12}\n``` {.python .cell-code}\nsamples = pd.read_csv(\"wine.csv\")\nvarieties = samples['class_name']\nsamples = samples.drop(\"class_name\", axis = 1)\nsamples\n```\n\n::: {.cell-output .cell-output-display execution_count=12}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>class_label</th>\n      <th>alcohol</th>\n      <th>malic_acid</th>\n      <th>ash</th>\n      <th>alcalinity_of_ash</th>\n      <th>magnesium</th>\n      <th>total_phenols</th>\n      <th>flavanoids</th>\n      <th>nonflavanoid_phenols</th>\n      <th>proanthocyanins</th>\n      <th>color_intensity</th>\n      <th>hue</th>\n      <th>od280</th>\n      <th>proline</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>14.23</td>\n      <td>1.71</td>\n      <td>2.43</td>\n      <td>15.6</td>\n      <td>127</td>\n      <td>2.80</td>\n      <td>3.06</td>\n      <td>0.28</td>\n      <td>2.29</td>\n      <td>5.64</td>\n      <td>1.04</td>\n      <td>3.92</td>\n      <td>1065</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>13.20</td>\n      <td>1.78</td>\n      <td>2.14</td>\n      <td>11.2</td>\n      <td>100</td>\n      <td>2.65</td>\n      <td>2.76</td>\n      <td>0.26</td>\n      <td>1.28</td>\n      <td>4.38</td>\n      <td>1.05</td>\n      <td>3.40</td>\n      <td>1050</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>13.16</td>\n      <td>2.36</td>\n      <td>2.67</td>\n      <td>18.6</td>\n      <td>101</td>\n      <td>2.80</td>\n      <td>3.24</td>\n      <td>0.30</td>\n      <td>2.81</td>\n      <td>5.68</td>\n      <td>1.03</td>\n      <td>3.17</td>\n      <td>1185</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>14.37</td>\n      <td>1.95</td>\n      <td>2.50</td>\n      <td>16.8</td>\n      <td>113</td>\n      <td>3.85</td>\n      <td>3.49</td>\n      <td>0.24</td>\n      <td>2.18</td>\n      <td>7.80</td>\n      <td>0.86</td>\n      <td>3.45</td>\n      <td>1480</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>13.24</td>\n      <td>2.59</td>\n      <td>2.87</td>\n      <td>21.0</td>\n      <td>118</td>\n      <td>2.80</td>\n      <td>2.69</td>\n      <td>0.39</td>\n      <td>1.82</td>\n      <td>4.32</td>\n      <td>1.04</td>\n      <td>2.93</td>\n      <td>735</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>173</th>\n      <td>3</td>\n      <td>13.71</td>\n      <td>5.65</td>\n      <td>2.45</td>\n      <td>20.5</td>\n      <td>95</td>\n      <td>1.68</td>\n      <td>0.61</td>\n      <td>0.52</td>\n      <td>1.06</td>\n      <td>7.70</td>\n      <td>0.64</td>\n      <td>1.74</td>\n      <td>740</td>\n    </tr>\n    <tr>\n      <th>174</th>\n      <td>3</td>\n      <td>13.40</td>\n      <td>3.91</td>\n      <td>2.48</td>\n      <td>23.0</td>\n      <td>102</td>\n      <td>1.80</td>\n      <td>0.75</td>\n      <td>0.43</td>\n      <td>1.41</td>\n      <td>7.30</td>\n      <td>0.70</td>\n      <td>1.56</td>\n      <td>750</td>\n    </tr>\n    <tr>\n      <th>175</th>\n      <td>3</td>\n      <td>13.27</td>\n      <td>4.28</td>\n      <td>2.26</td>\n      <td>20.0</td>\n      <td>120</td>\n      <td>1.59</td>\n      <td>0.69</td>\n      <td>0.43</td>\n      <td>1.35</td>\n      <td>10.20</td>\n      <td>0.59</td>\n      <td>1.56</td>\n      <td>835</td>\n    </tr>\n    <tr>\n      <th>176</th>\n      <td>3</td>\n      <td>13.17</td>\n      <td>2.59</td>\n      <td>2.37</td>\n      <td>20.0</td>\n      <td>120</td>\n      <td>1.65</td>\n      <td>0.68</td>\n      <td>0.53</td>\n      <td>1.46</td>\n      <td>9.30</td>\n      <td>0.60</td>\n      <td>1.62</td>\n      <td>840</td>\n    </tr>\n    <tr>\n      <th>177</th>\n      <td>3</td>\n      <td>14.13</td>\n      <td>4.10</td>\n      <td>2.74</td>\n      <td>24.5</td>\n      <td>96</td>\n      <td>2.05</td>\n      <td>0.76</td>\n      <td>0.56</td>\n      <td>1.35</td>\n      <td>9.20</td>\n      <td>0.61</td>\n      <td>1.60</td>\n      <td>560</td>\n    </tr>\n  </tbody>\n</table>\n<p>178 rows × 14 columns</p>\n</div>\n```\n:::\n:::\n\n\n### Clustering con Vinos \n\nTomaremos la matriz de muestra de los vinos y usaremos KMeans para encontrar 3 grupos\n\n::: {#743ff047 .cell execution_count=13}\n``` {.python .cell-code}\nmodel = KMeans(n_clusters = 3, random_state = 42)\nlabels = model.fit_predict(samples)\n```\n:::\n\n\n#### Cluster vs Varieties \n\nHay tres variedades de vinom así que usamos pandas para crear la tabla cruzada para comprobar las correspondencia entre la etiqueta del clúster y la variedad de vino.\n\n::: {#baaa1ef4 .cell execution_count=14}\n``` {.python .cell-code}\ndf = pd.DataFrame({'labels': labels, 'varieties':varieties})\nct = pd.crosstab(df['labels'], df['varieties'])\nprint(ct)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nvarieties  Barbera  Barolo  Grignolino\nlabels                                \n0               37       1          64\n1               11      31           7\n2                0      27           0\n```\n:::\n:::\n\n\nComo podemos ver, esta vez las cosas no han salido tan bien. Los clusters KMeans no se corresponden bien con las variedades de vino.\n\n#### Variación de Características\n\nEl problema es que las características del conjunto de datos del vino tiene variaciones muy diferentes.\n\n> La varianza de una característica mide la dispersión de sus valores\n\n![](img/fig4.png){fig-align=\"center\" width=\"400\"}\n\nPor ejemplo, la característica del ácido málico (`malic_acid`) tiene una mayor varianza que la característica `0d280`, y esto también se puede ver en su diagrama de dispersión.\n\nLas diferencias en algunas de las variaciones de características son enormes, por ejmplo, en el diagrama de dispersión de características `od280` y `prolina`.\n\n![](img/fig5.png){fig-align=\"center\" width=\"300\"}\n\n### StandarScaler\n\nEn la agrupación en clústeres de KMeans, la varianza de una característica corresponde a su influencia en el algoritmo de agrupación en clústeres. Es decir:\n\n-   <div>\n\n    > Varianza de Carasterística = Influencia de Característica\n\n    </div>\n\nPara darle una oportunidad a cada característica, los datos deben transformarce para que las características tengan la misma varianza. Esto se puede lograr con el `StandarScaler` de scikit-learn. Transforma cada característica para que tenga media 0 y varianza 1.\n\nLas características **estandarizadas** resultantes pueden ser muy informativas.\n\nSi utilizamos, por ejemplo, los valores estandarizados de `od280` y `proline`, las tres variedades de vino son mucho más distintas.\n\n![](img/fig6.png){fig-align=\"center\" width=\"800\"}\n\nVeamos StandarScaler en acción:\n\n::: {#a2b49f8c .cell execution_count=15}\n``` {.python .cell-code}\nfrom sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler() # Creamos el objeto StandarScaler \nscaler.fit(samples)\nStandardScaler(copy = True, with_mean = True, with_std = True)\nsamples_scaled = scaler.transform(samples)\n```\n:::\n\n\nEl método de transformación ahora se puede utilizar para estandarizar cualquier muestra, ya sean las mismas o completamente nuevas.\n\n#### Métodos similares\n\n> Las API de StandarScaler y KMeans son similares, pero hay una diferencia importante:\n>\n> -   StandardScaler transforma datos y por eso tiene un método de transformación.\n>\n> -   KMeans por el contrario, asigna etiquetas de clúster a las muestras y esto se hace utilizando el método de predicción.\n\n### StandardScaler luego KMeans\n\nVolvamos al problema del agrupamiento de los vinos. Necesitamos realizar dos pasos:\n\n1.  Estandarizar los datos utilizando StandardScaler y\n\n2.  Tomar los datos estandarizados y agruparlos utilizando KMeans\n\nEsto se hace fácilmente combinando los dos pasos mediante un pipeline de scikit-learn, luego, los datos fluyen de un paso al siguiente de forma automática.\n\n#### Pipelines combinando multiples pasos\n\n::: {#44f5f950 .cell execution_count=16}\n``` {.python .cell-code}\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.cluster import KMeans\nfrom sklearn.pipeline import make_pipeline\n\nscaler = StandardScaler()\nkmeans = KMeans(n_clusters = 3, random_state = 42)\n\n# Aplicamos los pasos que queremos combinar\npipeline = make_pipeline(scaler, kmeans)\npipeline.fit(samples)\n\n# Utilizamos el método de predicción para obtener las etiquetas del clúster\n\nlabels = pipeline.predict(samples)\n\n```\n:::\n\n\nAhora, realicemos la comprobación de la correspondencia entre las etiquetas de los cluster y las variedadesd de vino\n\n::: {#70d5a1e2 .cell execution_count=17}\n``` {.python .cell-code}\ndf = pd.DataFrame({'labels': labels, 'varieties':varieties})\nct = pd.crosstab(df['labels'], df['varieties'])\nprint(ct)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nvarieties  Barbera  Barolo  Grignolino\nlabels                                \n0                0       0          67\n1               48       0           1\n2                0      59           3\n```\n:::\n:::\n\n\n> Y como podemos observar, esto nos revela que al incorporar estandarización la nueva agrupación es fantástica. Sus tres clúster corresponden casi exactamente a las tres variedades de vino. Por tanto, esto es una gran mejora con respecto a la agrupación sin estandarización.\n\n**StandardScaler** es un ejemplo de un paso de *preprocesamiento*. Existen varios de estos disponibles en Scikit-Learn, por ejemplo, MaxAbsScaler y Normalizer.\n\n# **Visualización con agrupamiento Jerárquico y t-SNE**\n\nEn este capítulo, aprenderás dos técnicas de aprendizaje no suprvisado para la visualización de datos: la **agrupación jerárquica** y **t-SNE**.\n\n**La agrupación jerárquica** fusiona las muestras de datos en grupos cada vez más amplios, lo que da como resultado una visualización en forma de árbol de la jerarquía de grupos resultantes.\n\n**t-SNE** mapea las muestras de datos en un espacio bidimensional para que se pueda visualizar la proximidad antre ellas.\n\n## Visualizar Jerarquías \n\nUna gran parte del trabajo de cualquier cientifico de datos es la comunicación de los resultados o conocimiento a otras personas. Las visualizaciones son una excelente manera de compartir sus hallazgos especialmente con una audiencia no técnica. En este nuevo capítulo, aprenderá sobre dos métodos de aprendizaje no supervisado correspondientes a visualización:\n\n-   t-SNE\n\n-   Agrupamiento Jerárquico\n\n**t-SNE**, que lo veremos más adelante, crea un mapa 2D de cualquier conjunto de datos y transmite información útil sobre la proximidad de las muestras entre sí. Pero primero aprendamos sobre la agrupación jerárquica.\n\nYa has visto muchas agrupaciones jerárquicas en el mundo real. Por ejemplo, los seres vivos pueden organizarse en grupos pequeños y estrechos como los humanos, los simios, las serpientes y los lagartos, o en grupos más grandes y amplios, como los mamíferos y los reptiles, o incluso grupos más amplios, como los animales y las plantas. Como puede visualizar en la figura de abajo, estos grupos están contenidos unos dentro de otros y forman una jerarquía.\n\n![](img/fig7.png){fig-align=\"center\" width=\"450\"}\n\nDe manera análoga, la agrupación jerárquica organiza las muestras en una jerarquía de grupos.\n\nLa **agrupación jerárquica** puede organizar cualquier tipo de datos en una jerarquía, no sólo muestras de plantas y animales.\n\n### Dataset de scoring Eurovision\n\nConsideremos un nuevo tipo de conjunto de datos que describe cómo los países calificaron sus actuaciones en el Festival de la Canción de Eurovisión 2016. Los datos se organizan en una matriz rectangular, donde las filas de la matriz muestra cuántos puntos le dio un país a cada canción.\n\n![](img/fig8.png){fig-align=\"center\" width=\"400\"}\n\nLas *muestras* en este caso son los países. El resultado de aplicar la agrupación jerárquica al Festival de Eurovisión:\n\n![](img/fig9.png){fig-align=\"center\" width=\"500\"}\n\nLas puntuaciones se pueden visualizar como u diagrama en forma de árbol llamado ***dendrograma***. Esta única imagen revela mucha información sobre el comportamiento electoral de los países en Eurovisión. El dendrograma agrupa a los países en grupos cada vez más grandes, y muchos de ellos los grupos se reconocen inmediatamente como compuestos por países cercanos entre si geográficamente, o que tienen estrechos vínculos culturales o político, o que pertenecen a un solo grupo linguístico. De esta manera, la agrupación jerárquica puede generar excelentes visualizaciones. **¿Pero cómo funciona?**\n\nLa agrupación jerárquica se realiza en pasos:\n\n-   Al principio cada país es su propio clúster,por lo que hay tantos clústeres como países.\n\n-   En cada paso se fusionan los dos clústeres más cercanos. Esto disminuye el número de clústeres, y\n\n-   Al final, sólo queda un grupo, que contiene todos los países.\n\nEste proceso es en realidad un tipo particular de agrupamiento jerárquico llamdo **agrupamiento aglomerativo,** también existe el **agrupamiento divisivo**, que funciona a la inversa.\n\nAún no hemos definido qué significa que dos clústeres estén cerca, pero volveremos a abordar este tema más adelante.\n\n### Dendrograma de una Clusterización Jerárquica \n\nTodo el proceso de agrupamiento jerárquico está codificado en el dendrograma.\n\n![](img/fig9.png){fig-align=\"center\" width=\"500\"}\n\nEn la parte inferior, cada país se encuentra en un grupo propio. Luego el agrupamiento continúa desde abajo hacia arriba.\n\nLos grupos se representan como líneas verticales y una unión de líneas verticales indica una fusión de grupos.\n\nPara comprender mejor, hagamos un acercamiento:\n\n![](img/fig10.png){fig-align=\"center\" width=\"500\"}\n\nObservemos sólo una parte de este dendrograma,\n\n![](img/fig11.png){fig-align=\"center\" width=\"174\"}\n\nAl principio hay seis grupos , cada uno de los cuales contiene sólo un país. La primera fusión se produce aquí:\n\n![](img/fig12.png){fig-align=\"center\" width=\"174\"}\n\ndonde los grupos que contienen a Cyprus y Grecia se fusionan en un solo grupo. Posteriormente, este nuevo clúster se fusiona con el clúster que contiene Bulgaria:\n\n![](img/fig13.png){fig-align=\"center\" width=\"174\"}\n\nPoco después, los grupos que incluyen a Moldova y Rusia son fusionados,\n\n![](img/fig14.png){fig-align=\"center\" width=\"174\"}\n\nque más tarde a su vez se fusiona con el grupo que contiene Armenia.\n\n![](img/fig15.png){fig-align=\"center\" width=\"174\"}\n\nMás tarde aún, los dos grupos compuestos se fusionan, Este proceso continua hasta que sólo quede un grupo, y éste contenga todos los países.\n\n![](img/fig16.png){fig-align=\"center\" width=\"500\"}\n\n### Clusterización Jerárquica con SciPy\n\nEn el capítulo anterior, utilizamos la agrupación KMeans para agrupar empresas según los movimientos de sus cotizaciones bursátiles. Ahora, realizaremos la agrupación jerárquica de las empresas.\n\nlinkage() de SciPy realiza una agrupación jerárquica en una matriz de muestras.\n\n::: {#6a24a38d .cell execution_count=18}\n``` {.python .cell-code}\nimport matplotlib.pyplot as plt\nfrom scipy.cluster.hierarchy import linkage, dendrogram\nfrom sklearn.preprocessing import normalize\nimport numpy as np\n\nempresas = pd.read_csv(\"/Users/juanisaulamejia/Documents/webmathJI/posts/Unsupervised_Learning/empresas.csv\")\n\ncompanies = empresas.iloc[:, 0].tolist()\n\nempresas = empresas.select_dtypes(include=\"number\").copy()\n\narr = empresas.to_numpy()\nnormalized_movements = normalize(arr)\n\n# Calculate the linkage: mergings\nmergings = linkage(normalized_movements, method = 'complete')\n\n# Plot the dendrogram\ndendrogram(mergings, labels = companies,\nleaf_rotation = 90,\nleaf_font_size = 6)\nplt.show()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-19-output-1.png){width=571 height=550}\n:::\n:::\n\n\nComo podemos observar, podemos crear visualizaciones geniales como esta con el clustering jerárquico, pero se puede usar ara más que solo visualizaciones.\n\n## Etiquetas de clústeres en la agrupación jerárquica \n\nEn la sección anterior empleamos la agrupación jerárquica. Creamos una gran visualización de las empresas según sus movimientos de sus cotizaciones bursátiles. Pero la **agrupación jerárquica no es sólo una herramienta de visualización**.\n\nEn esta sección aprenderá cómo extraer los clústeres de las etapas intermedias de una agrupación jerárquica. Las etiquetas de clúster para estos agrupamientos intermedios se pueden utilizar posteriormente en otros cálculos, como tabulaciones cruzadas, al igual que las etiquetas de clúster de KMeans.\n\n### Agrupaciones intermedias y altura en el dendrograma\n\nUna etapa intermedia en la agrupación jerárquica se especifica eligiendo una altura en el dendrograma.\n\n![](img/fig17.png){fig-align=\"center\" width=\"200\"}\n\nPor ejemplo, elegir una altura de 15 define una agrupación en el que Bulgaria, Cyprus y Grecia están en un grupo, Rusia y Moldavia en otro, y Armenia en un grupo propio.\n\nPero **¿qué significa la altura?**\n\nEl eje `y` del dendrograma codifica la distancia entre los grupos fusionados. Por ejemplo, la distancia entre el grupo que contiene Cyprus y el número de países que contenían Grecia era de aproximadamente 6 cuando se fusionaron en un solo grupo. Cuando este nuevo cúmulo se fusiono con el cúmulo que contenía a Bulgaria, la distancia entre ellos era de 12. Por lo tanto, la altura que especifica una agrupación intermedia corresponde a una distancia. Esto especifica que la agrupación jerárquica debe detenerse a fusionar clústeres cuando todos los clústeres están al menos a esta distancia.\n\n### Distancia entre Clusters\n\nLa distancia entre dos grupos se mide utilizando un **método de enlace (método `linkage`).** En nuestro ejemplo, utilizamos un enlace **completo**, donde la distancia entre dos clusteres es el máximo de las distancias entre sus muestras. Esto se especificó a través del parámetro \"method\" o en python `linkage(samples, method = \"complete\")`. Existen muchos otros métodos de vinculación y los veremos en algunos ejercicios que realizaremos en Python con Scikit-Learn.\n\n> Los diferentes métodos de vinculación producen diferentes agrupaciones jerárquicas.\n\n### Extracción de etiquetas de clúster mediante `fcluster.` \n\nLa etiquetas de clúster para cualquier etapa intermedia se pueden extraer utilizando la función `fcluster`. Vamos a probarlo, especificando la altura de 15. Despues de realizar la agrupación jerárquica de los datos de empresas, importamos la función `fcluster`. Luego, pasamos el resultado de la función de vinculación a la función fcluster, especificando la altura como segundo argumento.\n\n::: {#19bcf8e5 .cell execution_count=19}\n``` {.python .cell-code}\nfrom scipy.cluster.hierarchy import linkage\nfrom scipy.cluster.hierarchy import fcluster\n\nmergings = linkage(arr, method = 'complete')\nlabels   = fcluster(mergings, 15, criterion = 'distance')\nprint(labels)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[35 29 33 23  9 18 25 18  6 26  1 18  3 21 18 18 18 36 32 18 14 18 19 31\n 18 11 20 27 10  7 34 15  4 18 18 30  8 18 10 18 11 28 16 17  5 18 18 18\n 24 16 18 18 18 22 12 20 13  2 18 18]\n```\n:::\n:::\n\n\nEsto nos devolvio una matriz numpy que contiene las etiquetas de clúster para todos los países.\n\n### Alineación de las etiquetes de los clústeres con los nombres de las empresas \n\nPara inspeccionar las etiquetas de los clústeres, usaremos un DataFrame para alinear las etiquetas con los nombres de los países.\n\n::: {#fc0f2f68 .cell execution_count=20}\n``` {.python .cell-code}\nimport pandas as pd \npairs = pd.DataFrame({'labels': labels, 'companies': companies}) \nprint(pairs.sort_values('labels'))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n    labels                           companies\n10       1                      ConocoPhillips\n57       2                               Exxon\n12       3                             Chevron\n32       4                                  3M\n44       5                        Schlumberger\n8        6                         Caterpillar\n29       7                     Lookheed Martin\n36       8                    Northrop Grumman\n4        9                              Boeing\n38      10                               Pepsi\n28      10                           Coca Cola\n25      11                   Johnson & Johnson\n40      11                      Procter Gamble\n54      12                            Walgreen\n56      13                            Wal-Mart\n20      14                          Home Depot\n31      15                           McDonalds\n42      16                   Royal Dutch Shell\n49      16                               Total\n43      17                                 SAP\n46      18                      Sanofi-Aventis\n39      18                              Pfizer\n47      18                            Symantec\n37      18                            Novartis\n50      18  Taiwan Semiconductor Manufacturing\n34      18                          Mitsubishi\n51      18                   Texas instruments\n33      18                           Microsoft\n52      18                            Unilever\n45      18                                Sony\n59      18                               Yahoo\n58      18                               Xerox\n5       18                     Bank of America\n7       18                               Canon\n11      18                               Cisco\n15      18                                Ford\n16      18                   General Electrics\n19      18                     GlaxoSmithKline\n14      18                                Dell\n21      18                               Honda\n24      18                               Intel\n22      19                                  HP\n55      20                         Wells Fargo\n26      20                      JPMorgan Chase\n13      21                   DuPont de Nemours\n53      22                       Valero Energy\n3       23                    American express\n48      24                              Toyota\n6       25            British American Tobacco\n9       26                   Colgate-Palmolive\n27      27                      Kimberly-Clark\n41      28                       Philip Morris\n1       29                                 AIG\n35      30                            Navistar\n23      31                                 IBM\n18      32                       Goldman Sachs\n2       33                              Amazon\n30      34                          MasterCard\n0       35                               Apple\n17      36                     Google/Alphabet\n```\n:::\n:::\n\n\nComo era de esperar, las etiquetas del clúster agrupan a Intel, Texas instruments en el mismo clúster. Pero tenga en cuenta que las etiquetas de clúster de scipy comienzan en 1, no en 0 como lo hacen en `scikit-learn.`\n\n### t-SNE para mapas bidimensionales \n\nEn esta sección, aprenderá un método de aprendizaje no supervisado para visualización llamado `t-SNE`.\n\n> t-SNE significa \"incrustación de vecinos estocásticos distribuidos en t\"\n\nTiene un nombre complicado, pero tiene un propósito muy simple. Mapea muestras de su espacio de alta dimensión a un espacio de 2D o 3D dimensiones para que puedan visualizarse. Si bien es inevitable cierta distorsión, t-SNE hace un gran trabajo de representar aproximadamente las distancias entre las muestras. Por este motivo, t-SNE es una ayuda visual invaluable para comprender un conjunto de datos.\n\n#### t-SNE en el dataset iris \n\nPara ver qué tipo de conocimientos son posibles con t-SNE, veamos cómo funciona en el conjunto de datos del iris. Las muestras de iris están en un espacio de cuatro dimensiones, donde cada dimensión corresponde a una de las cuatro medidas del iris, como la longitud y el ancho de los pétalos.\n\nAhora a t-SNE solo se le dieron las medidas de las muestras de iris. En particular, no se proporcionó ninguna información sobre las tres especies de iris. Pero si coloreamos las especies de manera diferente en el diagrama de dispersión vemos que t-SNE ha mantedio las especies separadas.\n\n![](img/fig18.png){fig-align=\"center\" width=\"500\"}\n\nSin embargo, este diagrama de dispersión nos da una nueva perspectiva. Aprendemos que hay dos especies de iris, versicolor y virginica, cuyas muestras están muy juntas en el espacio. Por lo tanto, podría suceder que el conjunto de datos del iris parezca tener dos grupos en lugar de tres. Esto es compatible con nuestros ejemplos anteriores usando KMeans, donde vimos que la agrupación con 2 grupos también tenía una inercia relativamente baja, lo que significa grupos apretados.\n\n#### t-SNE en Sklearn \n\nt-SNE está disponible en scikit-learn, pero funciona un poco de manera diferente a los componentes de ajuste/transformación que ya conoce.\n\nPara comenzar, importamos `TSNE` y creamos un objeto TNSE. Aplicamos el método `fit_transform` a las muestras y luego hacemos un diagrama de dispersión del resultado, colerando los puntos según la especie.\n\n::: {#7c05868d .cell execution_count=21}\n``` {.python .cell-code}\nfrom sklearn.manifold import TSNE\n\nmodel = TSNE(learning_rate = 100)\ntransformed = model.fit_transform(iris)\nxs = transformed[:, 0]\nys = transformed[:, 1]\nplt.scatter(xs, ys, c = species_)\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-22-output-1.png){width=578 height=411}\n:::\n:::\n\n\nHay dos puntos que merecen especial atención:\n\n-   El método `fit_transform` y la\n\n-   tasa de aprendizaje (`learning_rate`)\n\nt-SNE solo tiene un método `fit_transform()`. Como era de esperar, el método fit_transform ajusta el modelo y transforma los datos simultáneamente. Sin embargi, t-SNE no tiene métodos de ajuste o `fit()` y transformación o `transform()` separados. Esto significa que no se puede ampliar un mapa t-SNE para incluir nuevas muestras. En cambio, debes empezar de nuevo cada vez.\n\nLa segunda cosa a tener en cuenta es la `tasa de aprendizaje.` Está hace que el uso de t-SNE sea más complicado que otras técnicas. Es posible que deba probar diferentes tasas de aprendizaje para diferentes conjuntos de datos.\n\nEstá claro, sin embargo, cuando has hecho una mala elección, porque todas las muestras aparecen agrupadas en el diagrama de dispersión. Normalmente es suficiente probar algunos valores entre 50 y 200.\n\nUna última cosa a tener en cuenta es que los ejes de un gráfico t-SNE no tienen ningún significado interpretable. De hecho son diferentes cada vez que se aplica t-SNE, incluso con los mismos datos. Por ejemplo, aquí hay tres gráficos t-SNE de muestras de vino de Piamonte escaladas, generados con el mismo código.\n\n![](img/fig19.png){fig-align=\"center\" width=\"800\"}\n\nTenga en cuenta que si bien la orientación de la trama es diferente cada vez, los tres vinos, las variedades, representadas aquí mediante colores, tienen la misma posición entre si.\n\n### Mapa t-SNE del mercado bursátil\n\nt-SNE proporciona excelentes visualizaciones cuando se pueden etiquetar las muestras individuales. En el siguiente bloque de código, se aplica t-SNE a los datos del precio de las acciones de la empresa. Un gráfico de dispersión de las características t-SNE resultantes, etiquetadas con los nombres de las empresas, te ofrece un mapa del mercado de valores. Los movimientos de las cotizaciones bursátiles de cada empresa están disponibles en `normalized_movements` las cuales normalizamos anteriormente.\n\n::: {#41dde582 .cell execution_count=22}\n``` {.python .cell-code}\n# Import TSNE\nfrom sklearn.manifold import TSNE\n\nmodel = TSNE(learning_rate = 50)\n\ntsne_features = model.fit_transform(normalized_movements)\n\nxs = tsne_features[:, 0]\n\nys = tsne_features[:,1]\n\n# Scatter plot\nplt.scatter(xs, ys, alpha = 0.5)\n\nfor x, y, company in zip(xs, ys, companies):\n    plt.annotate(company, (x, y), fontsize=5, alpha=0.75)\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-23-output-1.png){width=569 height=411}\n:::\n:::\n\n\n# Descorrelación de Datos y Reducción de Dimensiones \n\nLa reducción de dimensiones resume un conjunto de datos utilizando sus patrones comunes. En esta sección, aprenderás la técnica más fundamental de reducción de dimensiones, el **análisis de componentes principales** (PCA, por sus siglas en inglés). El PCA se utiliza a menudo antes del aprendizaje supervisado para mejorar el rendimiento y la generalización del modelo. También puede ser útil para aprendizaje no supervisado. Por ejemplo, utilizaremos una variante PCA que te permitirá agrupar articulos de wikipedia según su contenido.\n\n## Visualización de la transformación PCA \n\nLa reducción de dimensiones encuentra patrones en los datos y utiliza estos patrones para reexpresarlos en una forma comprimida. Esto hace que el cálculo posterior con los datos sea mucho más sencillo, eficiente y, esto puede ser de gran importancia en un mundo de grandes conjuntos de datos.\n\nSin embargo, la función más importante de la reducción de dimensión es reducir un conjunto de datos a su ***\"esqueleto básico\"***, descartando características ruidosas que causan grandes problemas para las tareas de aprendizaje supervisado como regresión y clasificación.\n\n> En muchas aplicaciones del mundo real, es la reducción de dimensiones la que hace posible la predicción.\n\n### Análisis de componentes principales \n\nEsta es la técnica de reducción de dimensión más fundamental. Se llama *\"Análisis de componentes principales\"*, o *\"PCA\"* para abreviar. PCA realiza la reducción de dimensión en dos pasos, y el primero:\n\n1.  Llamada **\"descorrelación\"**, no cambia la dimensión de los datos en absoluto.\n\nEs justamente en este primer paso en el cual nos centraremos.\n\nEn este **primer paso**, PCA gira las muestras para que queden alineadas con los ejes de coordenadas. De hecho, hace más que eso: PCA también desplaza las muestras para que tengan media cero.\n\n![](img/fig20.png){fig-align=\"center\" width=\"600\"}\n\nEstos gráficos de dispersión muestran el efecto del PCA aplicado a dos características del conjunto de datos del vino. Tenga en cuenta que no se pierde información: esto es así sin importar cuántas características tenga su conjunto de datos. Veremos la visualización de esta transformación en ejercicios más adelante.\n\n### PCA en Scikit - Learn\n\nScikit-learn tiene una implementación de PCA y tiene dos métodos de ajuste y transformación como StandardScaler.\n\n-   `fit()` el método de ajuste aprende cómo desplazar y rotar las muestras, pero en realidad no las cambia.\n\n-   `transform()` el método de transformación, por otro lado, aplica la transformación que se aprendio. En particular, el método de transformación se puede aplicar a muestras nuevas e invisibles.\n\nVeamos PCA en acción en algunas características del conjunto de datos de vino, estas características son: `total_phenols` y `od280`.\n\n::: {#c3a88851 .cell execution_count=23}\n``` {.python .cell-code}\nsamples = pd.read_csv(\"wine.csv\")\nvarieties = samples['class_name']\nsamples = samples.drop(\"class_name\", axis = 1)\nsamples = samples[[\"total_phenols\", \"od280\"]]\nsamples\n```\n\n::: {.cell-output .cell-output-display execution_count=23}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>total_phenols</th>\n      <th>od280</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2.80</td>\n      <td>3.92</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2.65</td>\n      <td>3.40</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2.80</td>\n      <td>3.17</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3.85</td>\n      <td>3.45</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2.80</td>\n      <td>2.93</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>173</th>\n      <td>1.68</td>\n      <td>1.74</td>\n    </tr>\n    <tr>\n      <th>174</th>\n      <td>1.80</td>\n      <td>1.56</td>\n    </tr>\n    <tr>\n      <th>175</th>\n      <td>1.59</td>\n      <td>1.56</td>\n    </tr>\n    <tr>\n      <th>176</th>\n      <td>1.65</td>\n      <td>1.62</td>\n    </tr>\n    <tr>\n      <th>177</th>\n      <td>2.05</td>\n      <td>1.60</td>\n    </tr>\n  </tbody>\n</table>\n<p>178 rows × 2 columns</p>\n</div>\n```\n:::\n:::\n\n\nVeamos:\n\n1.  En primer lugar importamos el objeto PCA\n\n2.  Luego creamos el objeto PCA y los ajustamos a las muestras o samples.\n\n::: {#df64aa9a .cell execution_count=24}\n``` {.python .cell-code}\nfrom sklearn.decomposition import PCA\n\nmodel = PCA()\nmodel.fit(samples)\n```\n\n::: {.cell-output .cell-output-display execution_count=24}\n```{=html}\n<style>#sk-container-id-2 {\n  /* Definition of color scheme common for light and dark mode */\n  --sklearn-color-text: #000;\n  --sklearn-color-text-muted: #666;\n  --sklearn-color-line: gray;\n  /* Definition of color scheme for unfitted estimators */\n  --sklearn-color-unfitted-level-0: #fff5e6;\n  --sklearn-color-unfitted-level-1: #f6e4d2;\n  --sklearn-color-unfitted-level-2: #ffe0b3;\n  --sklearn-color-unfitted-level-3: chocolate;\n  /* Definition of color scheme for fitted estimators */\n  --sklearn-color-fitted-level-0: #f0f8ff;\n  --sklearn-color-fitted-level-1: #d4ebff;\n  --sklearn-color-fitted-level-2: #b3dbfd;\n  --sklearn-color-fitted-level-3: cornflowerblue;\n\n  /* Specific color for light theme */\n  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-icon: #696969;\n\n  @media (prefers-color-scheme: dark) {\n    /* Redefinition of color scheme for dark theme */\n    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-icon: #878787;\n  }\n}\n\n#sk-container-id-2 {\n  color: var(--sklearn-color-text);\n}\n\n#sk-container-id-2 pre {\n  padding: 0;\n}\n\n#sk-container-id-2 input.sk-hidden--visually {\n  border: 0;\n  clip: rect(1px 1px 1px 1px);\n  clip: rect(1px, 1px, 1px, 1px);\n  height: 1px;\n  margin: -1px;\n  overflow: hidden;\n  padding: 0;\n  position: absolute;\n  width: 1px;\n}\n\n#sk-container-id-2 div.sk-dashed-wrapped {\n  border: 1px dashed var(--sklearn-color-line);\n  margin: 0 0.4em 0.5em 0.4em;\n  box-sizing: border-box;\n  padding-bottom: 0.4em;\n  background-color: var(--sklearn-color-background);\n}\n\n#sk-container-id-2 div.sk-container {\n  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n     but bootstrap.min.css set `[hidden] { display: none !important; }`\n     so we also need the `!important` here to be able to override the\n     default hidden behavior on the sphinx rendered scikit-learn.org.\n     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n  display: inline-block !important;\n  position: relative;\n}\n\n#sk-container-id-2 div.sk-text-repr-fallback {\n  display: none;\n}\n\ndiv.sk-parallel-item,\ndiv.sk-serial,\ndiv.sk-item {\n  /* draw centered vertical line to link estimators */\n  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n  background-size: 2px 100%;\n  background-repeat: no-repeat;\n  background-position: center center;\n}\n\n/* Parallel-specific style estimator block */\n\n#sk-container-id-2 div.sk-parallel-item::after {\n  content: \"\";\n  width: 100%;\n  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n  flex-grow: 1;\n}\n\n#sk-container-id-2 div.sk-parallel {\n  display: flex;\n  align-items: stretch;\n  justify-content: center;\n  background-color: var(--sklearn-color-background);\n  position: relative;\n}\n\n#sk-container-id-2 div.sk-parallel-item {\n  display: flex;\n  flex-direction: column;\n}\n\n#sk-container-id-2 div.sk-parallel-item:first-child::after {\n  align-self: flex-end;\n  width: 50%;\n}\n\n#sk-container-id-2 div.sk-parallel-item:last-child::after {\n  align-self: flex-start;\n  width: 50%;\n}\n\n#sk-container-id-2 div.sk-parallel-item:only-child::after {\n  width: 0;\n}\n\n/* Serial-specific style estimator block */\n\n#sk-container-id-2 div.sk-serial {\n  display: flex;\n  flex-direction: column;\n  align-items: center;\n  background-color: var(--sklearn-color-background);\n  padding-right: 1em;\n  padding-left: 1em;\n}\n\n\n/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\nclickable and can be expanded/collapsed.\n- Pipeline and ColumnTransformer use this feature and define the default style\n- Estimators will overwrite some part of the style using the `sk-estimator` class\n*/\n\n/* Pipeline and ColumnTransformer style (default) */\n\n#sk-container-id-2 div.sk-toggleable {\n  /* Default theme specific background. It is overwritten whether we have a\n  specific estimator or a Pipeline/ColumnTransformer */\n  background-color: var(--sklearn-color-background);\n}\n\n/* Toggleable label */\n#sk-container-id-2 label.sk-toggleable__label {\n  cursor: pointer;\n  display: flex;\n  width: 100%;\n  margin-bottom: 0;\n  padding: 0.5em;\n  box-sizing: border-box;\n  text-align: center;\n  align-items: start;\n  justify-content: space-between;\n  gap: 0.5em;\n}\n\n#sk-container-id-2 label.sk-toggleable__label .caption {\n  font-size: 0.6rem;\n  font-weight: lighter;\n  color: var(--sklearn-color-text-muted);\n}\n\n#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n  /* Arrow on the left of the label */\n  content: \"▸\";\n  float: left;\n  margin-right: 0.25em;\n  color: var(--sklearn-color-icon);\n}\n\n#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n  color: var(--sklearn-color-text);\n}\n\n/* Toggleable content - dropdown */\n\n#sk-container-id-2 div.sk-toggleable__content {\n  max-height: 0;\n  max-width: 0;\n  overflow: hidden;\n  text-align: left;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-2 div.sk-toggleable__content.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-2 div.sk-toggleable__content pre {\n  margin: 0.2em;\n  border-radius: 0.25em;\n  color: var(--sklearn-color-text);\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n  /* unfitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n  /* Expand drop-down */\n  max-height: 200px;\n  max-width: 100%;\n  overflow: auto;\n}\n\n#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n  content: \"▾\";\n}\n\n/* Pipeline/ColumnTransformer-specific style */\n\n#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator-specific style */\n\n/* Colorize estimator box */\n#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n#sk-container-id-2 div.sk-label label {\n  /* The background is the default theme color */\n  color: var(--sklearn-color-text-on-default-background);\n}\n\n/* On hover, darken the color of the background */\n#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n/* Label box, darken color on hover, fitted */\n#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator label */\n\n#sk-container-id-2 div.sk-label label {\n  font-family: monospace;\n  font-weight: bold;\n  display: inline-block;\n  line-height: 1.2em;\n}\n\n#sk-container-id-2 div.sk-label-container {\n  text-align: center;\n}\n\n/* Estimator-specific */\n#sk-container-id-2 div.sk-estimator {\n  font-family: monospace;\n  border: 1px dotted var(--sklearn-color-border-box);\n  border-radius: 0.25em;\n  box-sizing: border-box;\n  margin-bottom: 0.5em;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-2 div.sk-estimator.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n/* on hover */\n#sk-container-id-2 div.sk-estimator:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-2 div.sk-estimator.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Specification for estimator info (e.g. \"i\" and \"?\") */\n\n/* Common style for \"i\" and \"?\" */\n\n.sk-estimator-doc-link,\na:link.sk-estimator-doc-link,\na:visited.sk-estimator-doc-link {\n  float: right;\n  font-size: smaller;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1em;\n  height: 1em;\n  width: 1em;\n  text-decoration: none !important;\n  margin-left: 0.5em;\n  text-align: center;\n  /* unfitted */\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n  color: var(--sklearn-color-unfitted-level-1);\n}\n\n.sk-estimator-doc-link.fitted,\na:link.sk-estimator-doc-link.fitted,\na:visited.sk-estimator-doc-link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\ndiv.sk-estimator:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\ndiv.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n/* Span, style for the box shown on hovering the info icon */\n.sk-estimator-doc-link span {\n  display: none;\n  z-index: 9999;\n  position: relative;\n  font-weight: normal;\n  right: .2ex;\n  padding: .5ex;\n  margin: .5ex;\n  width: min-content;\n  min-width: 20ex;\n  max-width: 50ex;\n  color: var(--sklearn-color-text);\n  box-shadow: 2pt 2pt 4pt #999;\n  /* unfitted */\n  background: var(--sklearn-color-unfitted-level-0);\n  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n}\n\n.sk-estimator-doc-link.fitted span {\n  /* fitted */\n  background: var(--sklearn-color-fitted-level-0);\n  border: var(--sklearn-color-fitted-level-3);\n}\n\n.sk-estimator-doc-link:hover span {\n  display: block;\n}\n\n/* \"?\"-specific style due to the `<a>` HTML tag */\n\n#sk-container-id-2 a.estimator_doc_link {\n  float: right;\n  font-size: 1rem;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1rem;\n  height: 1rem;\n  width: 1rem;\n  text-decoration: none;\n  /* unfitted */\n  color: var(--sklearn-color-unfitted-level-1);\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n}\n\n#sk-container-id-2 a.estimator_doc_link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\n#sk-container-id-2 a.estimator_doc_link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n}\n</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>PCA()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>PCA</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.decomposition.PCA.html\">?<span>Documentation for PCA</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>PCA()</pre></div> </div></div></div></div>\n```\n:::\n:::\n\n\nAhora utilizamos el objeto PCA ajustado para transformar las muestras. Estos nos devuelve una matriz de muestras transformadas.\n\n::: {#1490c771 .cell execution_count=25}\n``` {.python .cell-code}\ntransformed = model.transform(samples)\nprint(transformed)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[[ 1.32771994e+00 -4.51396070e-01]\n [ 8.32496068e-01 -2.33099664e-01]\n [ 7.52168680e-01  2.94789161e-02]\n [ 1.64026613e+00  6.55724013e-01]\n [ 5.67992278e-01  1.83358911e-01]\n [ 8.07948468e-01  5.95331030e-01]\n [ 8.74453372e-01 -4.63619912e-01]\n [ 9.38570037e-01 -3.86879744e-01]\n [ 5.06600144e-01  2.34652243e-01]\n [ 1.15919131e+00 -7.60321086e-02]\n [ 8.48343677e-01  1.44589167e-01]\n [ 9.88781053e-02 -2.06553762e-01]\n [ 4.16736898e-01  4.91135760e-02]\n [ 6.06861937e-01  5.41812743e-01]\n [ 9.42293719e-01  5.22178083e-01]\n [ 5.61680527e-01  2.53787328e-01]\n [ 3.53119809e-01  3.62885573e-01]\n [ 3.87902672e-01  5.29289156e-01]\n [ 8.04161418e-01  6.37588080e-01]\n [ 8.33858333e-01 -1.69082914e-01]\n [ 1.29479891e+00 -1.63270739e-01]\n [ 7.70704274e-01 -4.94216064e-01]\n [ 1.26729041e+00 -6.48495720e-01]\n [ 9.00000123e-01 -5.11026278e-01]\n [ 1.07786477e+00 -5.94477857e-01]\n [ 6.66192400e-01 -1.20214368e-01]\n [ 8.22597096e-01  3.57906674e-02]\n [ 1.88741351e-01 -2.10150947e-02]\n [ 1.02484606e+00 -2.87916168e-03]\n [ 9.78302386e-01 -3.54921327e-01]\n [ 5.27397239e-01  4.77895909e-01]\n [ 5.68092193e-01  2.61461344e-01]\n [ 2.78304852e-01 -6.97837260e-02]\n [ 7.17885392e-01  2.53587497e-01]\n [ 2.33423186e-01 -1.23501843e-01]\n [ 9.18272518e-01 -2.39611246e-01]\n [ 3.24648697e-01  1.26053574e-01]\n [ 2.12752481e-02  1.84058317e-01]\n [ 1.27349217e-01  3.02782371e-02]\n [ 1.15666661e+00 -4.78607421e-02]\n [ 1.13773136e+00  1.63424506e-01]\n [ 3.97302069e-01 -1.30113340e-01]\n [ 1.33998032e+00  1.24754677e-01]\n [ 5.19123732e-01  1.56929782e-02]\n [ 1.01853431e+00  6.75492544e-02]\n [ 9.07011280e-01 -3.47376638e-02]\n [ 1.24789212e+00  2.01694675e-01]\n [ 1.06730294e+00  1.57112755e-01]\n [ 3.97801644e-01  2.60398824e-01]\n [ 7.49743895e-01  1.35752715e-01]\n [ 5.01350913e-01  1.34790110e-01]\n [ 6.81240688e-01 -3.67345000e-01]\n [ 1.51369481e+00  8.00567726e-01]\n [ 6.96225608e-01  3.36839246e-01]\n [ 6.46957401e-01 -1.43236418e-01]\n [ 7.47319109e-01  2.42026515e-01]\n [ 1.11607157e+00  2.46676255e-01]\n [ 6.27159457e-01  3.94544245e-01]\n [ 9.06648166e-01  6.82269915e-01]\n [-8.09580232e-01  2.65784517e-01]\n [-8.79808818e-01  4.15677631e-01]\n [-9.60435951e-01  4.43948913e-01]\n [-2.41503162e-01 -5.24739364e-02]\n [ 9.70764831e-01  7.59010083e-01]\n [-5.52650543e-01 -6.61599591e-02]\n [-1.59114103e-01  2.95681263e-01]\n [ 8.75252693e-01  1.61199551e-01]\n [ 5.47658212e-01 -6.98789900e-01]\n [-3.72524391e-01  6.17327107e-01]\n [ 6.63201973e-02 -6.35436010e-01]\n [-1.37380688e+00 -4.09528957e-01]\n [ 8.40669660e-01  1.51000834e-01]\n [-1.36991289e-01 -4.26475632e-01]\n [ 1.32599456e+00  2.01594760e-01]\n [ 1.09334927e+00  5.00218553e-01]\n [-8.01243355e-01 -2.23327430e-01]\n [-3.22330126e-01 -1.80407521e-01]\n [-4.39102388e-01 -3.82556572e-01]\n [-4.84846743e-01 -1.09779274e-01]\n [ 7.40707612e-01  7.81476322e-02]\n [ 4.70155270e-01 -2.30075388e-01]\n [ 3.44446641e-01 -4.11727089e-01]\n [-1.06095392e-01 -2.95917432e-01]\n [-8.75358907e-01 -1.09279699e-01]\n [ 2.98402541e-01 -3.73257090e-01]\n [ 3.59794675e-01 -4.24550422e-01]\n [-6.00156824e-01 -1.69809143e-01]\n [ 2.18638097e-01 -6.71481223e-01]\n [-1.15131674e-01 -3.53522515e-01]\n [ 3.98164758e-01 -4.56608755e-01]\n [-7.07892804e-01 -3.14353111e-01]\n [-5.12455165e-01 -6.73106688e-01]\n [-1.01010382e+00 -3.48536483e-01]\n [ 6.27522571e-01 -3.22463334e-01]\n [ 7.32070991e-01  3.32952280e-01]\n [ 1.45421781e-01  1.45488403e-01]\n [-7.15566821e-01 -3.07941444e-01]\n [ 2.61894298e-01  1.13330156e-01]\n [ 9.06847996e-01  8.38474781e-01]\n [ 5.23310443e-01  2.85845660e-01]\n [ 2.25549339e-01 -2.73295042e-01]\n [-4.20366964e-01 -7.50046686e-01]\n [ 7.59443036e-01 -2.89342482e-01]\n [-3.84536736e-04  2.67310066e-01]\n [ 6.74429361e-01 -6.87428748e-01]\n [ 1.33824252e-01 -9.13362624e-01]\n [ 1.48270353e-02 -8.53033010e-01]\n [-7.33839215e-01 -5.79356476e-01]\n [ 3.54945104e-01 -2.12002824e-01]\n [ 7.82764832e-01 -7.42701827e-02]\n [ 7.19547403e-01  5.51911546e-01]\n [ 2.92590365e-01  8.76834900e-02]\n [-4.35215422e-01 -3.46711188e-01]\n [-1.12970087e-01  3.35313697e-01]\n [ 6.13636718e-01 -1.67520819e-01]\n [ 3.03951517e-01 -3.90876590e-02]\n [ 3.49196297e-01 -7.02377121e-01]\n [ 7.80810103e-02 -4.49797428e-01]\n [-8.03768056e-01 -1.95156063e-01]\n [ 1.47147161e-01 -5.07502426e-01]\n [ 9.85113713e-01 -3.48375789e-02]\n [ 1.39486088e+00 -1.23151043e-02]\n [ 3.29098608e-01 -3.98903756e-01]\n [ 5.83040566e-01 -6.37717200e-02]\n [ 1.15131747e+00 -2.25825308e-01]\n [ 7.08349535e-01 -1.94529750e-01]\n [ 4.60456128e-01  1.95019809e-01]\n [-2.37616196e-01 -1.66285532e-02]\n [ 8.10053713e-02 -1.65559063e-01]\n [-1.57088978e-01 -1.23002268e-01]\n [-1.51765144e+00  2.44924053e-01]\n [-1.55253422e+00  4.18037417e-04]\n [-1.69475332e+00 -7.62222149e-02]\n [-1.39582978e+00  3.90730371e-01]\n [-1.03465142e+00  4.79894211e-01]\n [-1.22457663e+00  1.43399910e-01]\n [-1.61635114e+00  1.57985169e-01]\n [-1.03116411e+00  2.03329863e-01]\n [-1.04040022e+00 -1.04800857e-02]\n [-3.38341019e-01  3.15116093e-01]\n [-7.15666736e-01 -3.86043877e-01]\n [-6.82645799e-01 -5.96066775e-01]\n [-9.01105488e-01 -2.18078198e-01]\n [-6.20254514e-01  1.33664222e-01]\n [-1.05614792e+00 -3.10066484e-01]\n [-1.22477646e+00 -1.28049560e-02]\n [-1.82677370e+00 -1.87445500e-01]\n [-9.58410826e-01  2.52653823e-02]\n [-9.95118899e-01  3.55647763e-01]\n [-1.55107204e+00  1.42537220e-01]\n [-1.58050576e+00  1.54098203e-01]\n [-1.39875414e+00  1.06492006e-01]\n [-1.04455039e+00  7.48784543e-01]\n [-1.16288475e+00  3.26413876e-01]\n [-1.33736201e+00  5.51986747e-02]\n [-1.22437680e+00  2.99604775e-01]\n [-1.06312253e+00  2.43062212e-01]\n [-9.29939714e-01  2.62097381e-01]\n [-1.76387346e-01  8.05290560e-01]\n [-4.42752977e-01  7.67220221e-01]\n [-7.88583306e-01  6.65233048e-01]\n [-9.05755229e-01  1.50674266e-01]\n [-7.98618740e-01 -1.73396363e-01]\n [-1.24158667e+00 -1.42100806e-01]\n [-1.32095145e+00 -1.27915207e-01]\n [-1.31211500e+00 -2.26514990e-01]\n [-1.18863133e+00  2.17615377e-01]\n [-1.18388167e+00 -7.30346548e-02]\n [-1.10062992e+00 -5.13748700e-02]\n [-7.32840064e-01  2.01667852e-01]\n [-1.26995787e+00 -3.00830372e-01]\n [-1.33367487e+00 -6.51608079e-02]\n [-1.08634441e+00  1.06092346e-01]\n [-1.06332236e+00  8.68573465e-02]\n [-1.12451466e+00  2.94355544e-01]\n [-1.25915966e+00  1.33201192e-01]\n [-1.17464556e+00  1.40775294e-01]\n [-9.33526935e-01  4.60559297e-01]]\n```\n:::\n:::\n\n\nEsta nueva matriz tiene el mismo número de filas y columnas que la matriz de muestra original. En particular, hay una fila para cada muestra transformada. Las columnas de la nueva matriz corresponden a *\"características de PCA\"*, tales como las características originales que correspondían a columnas de la matriz original.\n\n### LAs características de PCA no están correlacionadas\n\nA menudo ocurre que las características de un conjunto de datos están correlacionadas. Lo mismo ocurre con muchas de las características del conjunto de datos del vino, por ejemplo. Sin embargo, del PCA, debido a la rotación que realiza, *\"descorrelaciona\"* los datos, en el sentido de que las columnas de la matriz transformada no están correlacionadas linealmente.\n\nComo sabemos la correlación lineal se puede medir con la `correlación de Pearson.` Toma valores entre -1 y 1, donde los valores mayores indican una correlación más fuerte y 0 indica que no hay correlación lineal. A continuación se muestran algunos ejemplos de características con distintos grados de correlación.\n\n![](img/fig21.png){fig-align=\"center\" width=\"600\"}\n\n### Componentes Principales\n\nFinalmente, al PCA se le denomina *\"análisis de componentes principales\"* porque aprende los *\"componentes principales\"* de los datos. Estas son las direcciones en las que las muestran varían más, representadas aquí en rojo.\n\n![](img/fig22.png){fig-align=\"center\" width=\"300\"}\n\nSon los componentes principales que PCA alinea con los ejes de coordenadas. Una vez ajustado un modelo PCA, los componentes proncipales están disponibles como atributos de componentes.\n\n::: {#e9e81aab .cell execution_count=26}\n``` {.python .cell-code}\nprint(model.components_)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[[ 0.64116665  0.76740167]\n [ 0.76740167 -0.64116665]]\n```\n:::\n:::\n\n\nEsta es una matriz numpy con una fila para cada componente principal. \\\n\n## Dimensión Intrínseca\n\nConsideremos un conjunto de datos con 2 características: **latitud** y **longitud**.\n\n![](img/fig23.png){fig-align=\"center\" width=\"300\"}\n\nEstas dos características podrían rastrear el vuelo de un avión, por ejemplo. Este conjunto de datos es bidimensional, pero resulta que se puede analizar observando el desplazamiento a lo largo de la trayectoria de vuelo.\n\n![](img/fig24.png){fig-align=\"center\" width=\"300\"}\n\nEste conjunto de datos es intrínsicamente unidimensional.\n\n### Dimensión Intrínsica\n\nLa dimensión intrínsica de un conjunto de datos es el número de características necesarias para aproximarlo. La dimensión intrínsica informa la reducción de la dimensión, porque nos dice cuánto se puede comprimir un conjunto de datos.\n\nObtendremos una comprensión sólida de la dimensión intrínsica y seremos capaz de utilizar PCA para aidentificarlo en conjuntos de datos del mundo real que tienen miles de características.\n\nPara ilustrar mejor la dimensión intrínseca, consideremos un conjunto de datos de ejemplo que contiene solo algunas de las muestras del conjunto de datos iris. En concreto, tomaremos tres medidas del iris.\n\n-   sepal length (largo del sépalo)\n\n-   sepal width (ancho del sépalo)\n\n-   petal width (ancho del pétalo)\n\n::: {#ca6b8cda .cell execution_count=27}\n``` {.python .cell-code}\niris_sample = iris[['sepal length (cm)', 'sepal width (cm)','petal width (cm)']]\niris_sample\n```\n\n::: {.cell-output .cell-output-display execution_count=27}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sepal length (cm)</th>\n      <th>sepal width (cm)</th>\n      <th>petal width (cm)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5.1</td>\n      <td>3.5</td>\n      <td>0.2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4.9</td>\n      <td>3.0</td>\n      <td>0.2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4.7</td>\n      <td>3.2</td>\n      <td>0.2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4.6</td>\n      <td>3.1</td>\n      <td>0.2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5.0</td>\n      <td>3.6</td>\n      <td>0.2</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>145</th>\n      <td>6.7</td>\n      <td>3.0</td>\n      <td>2.3</td>\n    </tr>\n    <tr>\n      <th>146</th>\n      <td>6.3</td>\n      <td>2.5</td>\n      <td>1.9</td>\n    </tr>\n    <tr>\n      <th>147</th>\n      <td>6.5</td>\n      <td>3.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>148</th>\n      <td>6.2</td>\n      <td>3.4</td>\n      <td>2.3</td>\n    </tr>\n    <tr>\n      <th>149</th>\n      <td>5.9</td>\n      <td>3.0</td>\n      <td>1.8</td>\n    </tr>\n  </tbody>\n</table>\n<p>150 rows × 3 columns</p>\n</div>\n```\n:::\n:::\n\n\nCada muestra se representa como un punto en el espacio tridimensional. Sin embargo, si hacemos un gráfico de dispersión 3D de las muestras, vemos que todas están muy cerca de una lámila plana bidimensional.\n\n![](img/fig25.png){fig-align=\"center\" width=\"300\"}\n\nEsto significa que los datos se pueden aproximar utilizando sólo dos coordenadas, sin perder mucha información. Entonces, este conjunto de datos tiene una dimensión intrínseca de 2. PEro los gráficos de dispersión solo son posibles si hay 3 características o menos.\n\n### PCA identifica la dimensión intrínseca \n\n**Cómo se puede identificar la dimensión intrínseca, si hay muchas características?**\n\nAquí es donde el PCA resulta muy útil. La dimensión intrínseca se puede identificar contando las características de PCA que tienen alta varianza. Para ver cómo, veamos qué sucece cuando se aplica PCA al conjunto de datos de muestra versicolor.\n\n![](img/fig26.png){fig-align=\"center\" width=\"400\"}\n\nPCA gira y desplaza las muestras para alinearlas con los ejes de coordenadas. Esto expresa las muestras utilizando tres características PCA.\n\n### Las carasterísticas de PCA se ordenan por varianza descendente\n\nLas características de PCA están en un orden especial.\n\n![](img/fig27.png){fig-align=\"center\" width=\"500\"}\n\nAquí se muestra un gráfico de barras que muestra la varianza de cada una de las características de PCA. Como se puede ver, cada característica de PCA tiene menos variación que la primera. Esto concuerda con el diagrama de dispersión de las características de PCA, donde las muestras no varían mucho en la dirección vertical. En las otras dos direcciones, sin embargo, la variación es evidente.\n\n### Varianza y Dimensión Intrínseca \n\n-   La dimensión intrínseca es el número de características de PCA que tiene una varianza significativa.\n\n    ![](img/fig28.png){width=\"200\"}\n\nEn nuestro ejemplo, solo las dos primeras características de PCA tienen una varianza significativa. Por lo tanto, este conjunto de datos tiene una dimensión intrínseca de 2, lo que concuerda con lo que observamos al inspeccionar el diagrama de dispersión.\n\n### Plotting de varianza de PCA \n\nVeamos como gráficar las varianzas de las características del PCA en la práctica.\n\n::: {#be22fc96 .cell execution_count=28}\n``` {.python .cell-code}\npca = PCA()\npca.fit(iris_sample)\n```\n\n::: {.cell-output .cell-output-display execution_count=28}\n```{=html}\n<style>#sk-container-id-3 {\n  /* Definition of color scheme common for light and dark mode */\n  --sklearn-color-text: #000;\n  --sklearn-color-text-muted: #666;\n  --sklearn-color-line: gray;\n  /* Definition of color scheme for unfitted estimators */\n  --sklearn-color-unfitted-level-0: #fff5e6;\n  --sklearn-color-unfitted-level-1: #f6e4d2;\n  --sklearn-color-unfitted-level-2: #ffe0b3;\n  --sklearn-color-unfitted-level-3: chocolate;\n  /* Definition of color scheme for fitted estimators */\n  --sklearn-color-fitted-level-0: #f0f8ff;\n  --sklearn-color-fitted-level-1: #d4ebff;\n  --sklearn-color-fitted-level-2: #b3dbfd;\n  --sklearn-color-fitted-level-3: cornflowerblue;\n\n  /* Specific color for light theme */\n  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-icon: #696969;\n\n  @media (prefers-color-scheme: dark) {\n    /* Redefinition of color scheme for dark theme */\n    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-icon: #878787;\n  }\n}\n\n#sk-container-id-3 {\n  color: var(--sklearn-color-text);\n}\n\n#sk-container-id-3 pre {\n  padding: 0;\n}\n\n#sk-container-id-3 input.sk-hidden--visually {\n  border: 0;\n  clip: rect(1px 1px 1px 1px);\n  clip: rect(1px, 1px, 1px, 1px);\n  height: 1px;\n  margin: -1px;\n  overflow: hidden;\n  padding: 0;\n  position: absolute;\n  width: 1px;\n}\n\n#sk-container-id-3 div.sk-dashed-wrapped {\n  border: 1px dashed var(--sklearn-color-line);\n  margin: 0 0.4em 0.5em 0.4em;\n  box-sizing: border-box;\n  padding-bottom: 0.4em;\n  background-color: var(--sklearn-color-background);\n}\n\n#sk-container-id-3 div.sk-container {\n  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n     but bootstrap.min.css set `[hidden] { display: none !important; }`\n     so we also need the `!important` here to be able to override the\n     default hidden behavior on the sphinx rendered scikit-learn.org.\n     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n  display: inline-block !important;\n  position: relative;\n}\n\n#sk-container-id-3 div.sk-text-repr-fallback {\n  display: none;\n}\n\ndiv.sk-parallel-item,\ndiv.sk-serial,\ndiv.sk-item {\n  /* draw centered vertical line to link estimators */\n  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n  background-size: 2px 100%;\n  background-repeat: no-repeat;\n  background-position: center center;\n}\n\n/* Parallel-specific style estimator block */\n\n#sk-container-id-3 div.sk-parallel-item::after {\n  content: \"\";\n  width: 100%;\n  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n  flex-grow: 1;\n}\n\n#sk-container-id-3 div.sk-parallel {\n  display: flex;\n  align-items: stretch;\n  justify-content: center;\n  background-color: var(--sklearn-color-background);\n  position: relative;\n}\n\n#sk-container-id-3 div.sk-parallel-item {\n  display: flex;\n  flex-direction: column;\n}\n\n#sk-container-id-3 div.sk-parallel-item:first-child::after {\n  align-self: flex-end;\n  width: 50%;\n}\n\n#sk-container-id-3 div.sk-parallel-item:last-child::after {\n  align-self: flex-start;\n  width: 50%;\n}\n\n#sk-container-id-3 div.sk-parallel-item:only-child::after {\n  width: 0;\n}\n\n/* Serial-specific style estimator block */\n\n#sk-container-id-3 div.sk-serial {\n  display: flex;\n  flex-direction: column;\n  align-items: center;\n  background-color: var(--sklearn-color-background);\n  padding-right: 1em;\n  padding-left: 1em;\n}\n\n\n/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\nclickable and can be expanded/collapsed.\n- Pipeline and ColumnTransformer use this feature and define the default style\n- Estimators will overwrite some part of the style using the `sk-estimator` class\n*/\n\n/* Pipeline and ColumnTransformer style (default) */\n\n#sk-container-id-3 div.sk-toggleable {\n  /* Default theme specific background. It is overwritten whether we have a\n  specific estimator or a Pipeline/ColumnTransformer */\n  background-color: var(--sklearn-color-background);\n}\n\n/* Toggleable label */\n#sk-container-id-3 label.sk-toggleable__label {\n  cursor: pointer;\n  display: flex;\n  width: 100%;\n  margin-bottom: 0;\n  padding: 0.5em;\n  box-sizing: border-box;\n  text-align: center;\n  align-items: start;\n  justify-content: space-between;\n  gap: 0.5em;\n}\n\n#sk-container-id-3 label.sk-toggleable__label .caption {\n  font-size: 0.6rem;\n  font-weight: lighter;\n  color: var(--sklearn-color-text-muted);\n}\n\n#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n  /* Arrow on the left of the label */\n  content: \"▸\";\n  float: left;\n  margin-right: 0.25em;\n  color: var(--sklearn-color-icon);\n}\n\n#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n  color: var(--sklearn-color-text);\n}\n\n/* Toggleable content - dropdown */\n\n#sk-container-id-3 div.sk-toggleable__content {\n  max-height: 0;\n  max-width: 0;\n  overflow: hidden;\n  text-align: left;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-3 div.sk-toggleable__content.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-3 div.sk-toggleable__content pre {\n  margin: 0.2em;\n  border-radius: 0.25em;\n  color: var(--sklearn-color-text);\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n  /* unfitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n  /* Expand drop-down */\n  max-height: 200px;\n  max-width: 100%;\n  overflow: auto;\n}\n\n#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n  content: \"▾\";\n}\n\n/* Pipeline/ColumnTransformer-specific style */\n\n#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator-specific style */\n\n/* Colorize estimator box */\n#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n#sk-container-id-3 div.sk-label label {\n  /* The background is the default theme color */\n  color: var(--sklearn-color-text-on-default-background);\n}\n\n/* On hover, darken the color of the background */\n#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n/* Label box, darken color on hover, fitted */\n#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator label */\n\n#sk-container-id-3 div.sk-label label {\n  font-family: monospace;\n  font-weight: bold;\n  display: inline-block;\n  line-height: 1.2em;\n}\n\n#sk-container-id-3 div.sk-label-container {\n  text-align: center;\n}\n\n/* Estimator-specific */\n#sk-container-id-3 div.sk-estimator {\n  font-family: monospace;\n  border: 1px dotted var(--sklearn-color-border-box);\n  border-radius: 0.25em;\n  box-sizing: border-box;\n  margin-bottom: 0.5em;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-3 div.sk-estimator.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n/* on hover */\n#sk-container-id-3 div.sk-estimator:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-3 div.sk-estimator.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Specification for estimator info (e.g. \"i\" and \"?\") */\n\n/* Common style for \"i\" and \"?\" */\n\n.sk-estimator-doc-link,\na:link.sk-estimator-doc-link,\na:visited.sk-estimator-doc-link {\n  float: right;\n  font-size: smaller;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1em;\n  height: 1em;\n  width: 1em;\n  text-decoration: none !important;\n  margin-left: 0.5em;\n  text-align: center;\n  /* unfitted */\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n  color: var(--sklearn-color-unfitted-level-1);\n}\n\n.sk-estimator-doc-link.fitted,\na:link.sk-estimator-doc-link.fitted,\na:visited.sk-estimator-doc-link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\ndiv.sk-estimator:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\ndiv.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n/* Span, style for the box shown on hovering the info icon */\n.sk-estimator-doc-link span {\n  display: none;\n  z-index: 9999;\n  position: relative;\n  font-weight: normal;\n  right: .2ex;\n  padding: .5ex;\n  margin: .5ex;\n  width: min-content;\n  min-width: 20ex;\n  max-width: 50ex;\n  color: var(--sklearn-color-text);\n  box-shadow: 2pt 2pt 4pt #999;\n  /* unfitted */\n  background: var(--sklearn-color-unfitted-level-0);\n  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n}\n\n.sk-estimator-doc-link.fitted span {\n  /* fitted */\n  background: var(--sklearn-color-fitted-level-0);\n  border: var(--sklearn-color-fitted-level-3);\n}\n\n.sk-estimator-doc-link:hover span {\n  display: block;\n}\n\n/* \"?\"-specific style due to the `<a>` HTML tag */\n\n#sk-container-id-3 a.estimator_doc_link {\n  float: right;\n  font-size: 1rem;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1rem;\n  height: 1rem;\n  width: 1rem;\n  text-decoration: none;\n  /* unfitted */\n  color: var(--sklearn-color-unfitted-level-1);\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n}\n\n#sk-container-id-3 a.estimator_doc_link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\n#sk-container-id-3 a.estimator_doc_link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n}\n</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>PCA()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>PCA</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.decomposition.PCA.html\">?<span>Documentation for PCA</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>PCA()</pre></div> </div></div></div></div>\n```\n:::\n:::\n\n\nAhora creeamos un rango que enumere las características de PCA\n\n::: {#1f366798 .cell execution_count=29}\n``` {.python .cell-code}\nfeatures = range(pca.n_components_)\n```\n:::\n\n\nHacemos un diagrama de barras de la varianza; las varianzas están disponibles como el atributo `explained_variance` del modelo PCA.\n\n::: {#77c9b011 .cell execution_count=30}\n``` {.python .cell-code}\nplt.bar(features, pca.explained_variance_)\nplt.xticks(features)\nplt.ylabel('variance')\nplt.xlabel('PCA feature')\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-31-output-1.png){width=589 height=429}\n:::\n:::\n\n\nLa dimensión intrínseca es una idea útil que ayuda a orientar la reducción de dimensión. Sin embargo, no siempre es inequívoco. Aquí se muestra u gráfico de las variaciones de las características de PCA para el conjunto de datos del vino.\n\n![](img/fig29.png){fig-align=\"center\" width=\"400\"}\n\nPodriamos argumentar a favor de una dimensión intrínseca de 2, de 3 o incluso más, dependiendo del umbral que elijamos.\n\nEn la siguiente sección, aprenderá a utilizar la dimensión intrínseca para la reducción de dimensión.\n\n## Reducción de dimensiones con PCA\n\nLa reducción de dimensión representa los mismos datos utilizando menos funciones y es vital para construir pipeline de aprendizaje automático utilizando datos del mundo real. Finalmente aquí, aprenderá cómo realizar la reducción de dimensión utilizando PCA. Ya hemos visto que las características del PCA están en orden decreciente de varianza.\n\n![](img/fig30.png){fig-align=\"center\" width=\"200\"}\n\nPCA realiza un reducción de dimensión descartando las características de PCA con menor varianza, lo que asume que es ruido y conserva las características PCA de mayor varianza, que supone que son informativas.\n\n> Para utilizar PCA para la reducción de dimensión, debe especificar cuántas características de PCA desea conservar.\n\nPor ejemplo, especificar `PCA(n_components=2)` al crear un modelo PCA le indica que conserve solo las primeras dos características PCA. Una buena opción es la dimensión intrínseca del conjunto de datos, si la conoce. Consideremos inmediatamente un ejemplo:\n\nEl conjunto de datos del iris tiene 4 características que representan las 4 mediciones\n\n::: {#8eb6c55c .cell execution_count=31}\n``` {.python .cell-code}\niris\n```\n\n::: {.cell-output .cell-output-display execution_count=31}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sepal length (cm)</th>\n      <th>sepal width (cm)</th>\n      <th>petal length (cm)</th>\n      <th>petal width (cm)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5.1</td>\n      <td>3.5</td>\n      <td>1.4</td>\n      <td>0.2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4.9</td>\n      <td>3.0</td>\n      <td>1.4</td>\n      <td>0.2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4.7</td>\n      <td>3.2</td>\n      <td>1.3</td>\n      <td>0.2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4.6</td>\n      <td>3.1</td>\n      <td>1.5</td>\n      <td>0.2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5.0</td>\n      <td>3.6</td>\n      <td>1.4</td>\n      <td>0.2</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>145</th>\n      <td>6.7</td>\n      <td>3.0</td>\n      <td>5.2</td>\n      <td>2.3</td>\n    </tr>\n    <tr>\n      <th>146</th>\n      <td>6.3</td>\n      <td>2.5</td>\n      <td>5.0</td>\n      <td>1.9</td>\n    </tr>\n    <tr>\n      <th>147</th>\n      <td>6.5</td>\n      <td>3.0</td>\n      <td>5.2</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>148</th>\n      <td>6.2</td>\n      <td>3.4</td>\n      <td>5.4</td>\n      <td>2.3</td>\n    </tr>\n    <tr>\n      <th>149</th>\n      <td>5.9</td>\n      <td>3.0</td>\n      <td>5.1</td>\n      <td>1.8</td>\n    </tr>\n  </tbody>\n</table>\n<p>150 rows × 4 columns</p>\n</div>\n```\n:::\n:::\n\n\nUtilicemos un PCA para reducir la dimensión del conjunto de datos del iris a solo 2.\n\n::: {#51e4f71a .cell execution_count=32}\n``` {.python .cell-code}\npca = PCA(n_components=2)\npca.fit(iris)\ntransformed = pca.transform(iris)\nprint(transformed.shape)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n(150, 2)\n```\n:::\n:::\n\n\nAl imprimir la forma de las muestras transformadas, vemos que solo hay dos características, como se esperaba.\n\nAquí se muestra un diagrama de dispersión de las características de PCA, donde los colores representan las tres especies de iris.\n\n::: {#0218132c .cell execution_count=33}\n``` {.python .cell-code}\nxs = transformed[:,0]\nys = transformed[:,1]\nplt.scatter(xs, ys,c = species_)\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-34-output-1.png){width=582 height=415}\n:::\n:::\n\n\nNotablemente, a pesar de haberse reducido la dimensión de 4 a 2, aún es posible distinguir las especies. Recuerde que PCA ni siquiera sabía que existían especies distintas. PCA simplemente tomó las 2 características de PCA con mayor variación.\n\nComo podemos ver estas dos características son muy informativas.\n\n> El PCA descarta las características de baja varianza y supone que las características de mayor varianza son informativas.\n\nComo sucede con todos los supuestos, existen casos donde esto no se cumple. Sin embargo, como vimos con el conjunto de datos del iris, en la práctica suele suceder esto. En algunos casos, es necesario utilizar una implementación alternativa de PCA.\n\n### Matrices de frecuencia de palabras\n\nLas matrices de frecuencia de palabras son un gran ejemplo de una implementación alternativa de PCA.\n\n![](img/fig31.png){fig-align=\"center\" width=\"400\"}\n\nEn una matriz de frecuencia de palabras, cada fila corresponde a un documento y cada columna corresponde a una palabra de un vocabulario fijo. Las entradas de la matriz miden la frecuencia con la que aparece cada palabra en cada documento. Sólo algunas de las palabras del vocabulario aparecen en cualquier documento, por lo que la mayoría de las entradas de la matriz de frecuencia de palabras son cero.\n\nSe dice que las matrices de palabras como esta son *\"dispersas\"* y, a menudo, representado utilizando un tipo especial de matriz llamada `\"csr_matrix\".`\n\n-   `csr_matrix` ahorra espacio al recordar solo las entradas distintas de cero de la matriz.\n\n### TruncatedSVD & csr_matrix\n\nEl PCA de Scikit-Learn no admite csr_matrix y necesitará utilizar TruncatedSVD en su lugar.\n\nTruncatedSVD realiza la misma transformación que PCA, pero acepta matrices csr_matrix como entrada.\n\n``` Python\nfrom sklearn.decomposition import TruncatedSVD\nmodel = TruncatedSVD(n_components = 3)\nmodel.fit(documents)\ntransformed = model.transform(documents)\n```\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}