[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Juan Isaula",
    "section": "",
    "text": "Hola!\nSoy un profesional apasionado por transformar datos en soluciones estratégicas que impulsen el crecimiento y la innovación en el sector financiero. Actualmente, como Subgerente de Ciencia de Datos en Grupo Financiero Ficohsa, lidero proyectos de analitica avanzada y modelado predictivo, la gestión del riesgo y la toma de decisiones basadas en evidencia.\nMi sólida formación en Matemáticas y Estadística me permite abordar los desafíos complejos del entorno financiero con rigor técnico y visión analítica. Trabajo continuamente en el desarrollo de metodologías y herramientas innovadoras que integren el análisis de datos al corazón de la estrategia corporativa.\nEstoy comprometido con la excelencia, la innovación y la mejora continua, buscando siempre generar un impacto positivo en las organizaciones con la que colaboro."
  },
  {
    "objectID": "cursos_impartidos/index.html",
    "href": "cursos_impartidos/index.html",
    "title": "Cursos Impartidos en UNAH",
    "section": "",
    "text": "Saludos! Bienvenido a esta sección de mi website. Aquí podrá encontrar información sobre algnos cursos que he impartido.\n\n2023\n\n\nEstadística Aplicada - Maestría UNAH\n\nEste apartado está dedicado a los estudiantes de la maestría en Formulación, Gestión y Evaluación de Proyectos de la UNAH. Donde podrán encontrar el contenido sobre el taller de fundamentos estadísticos utilizando el Software de R. Mismo que tuve la oportunidad de impartirles.\n\nFundamentos estadísticos utilizando el Software de R\nLibro sobre fundamentos estadísticos con R - Juan Isaula\n\nBases de datos utilizadas\n\nco2.csv\nAAPL.csv\n\n\n\n\nMicroeconomía II - UNAH\n\n\nPrograma del curso\n\n\nModulo I - Teoria del Consumidor\n\n\nkaggle - Comandos Generales Python\nMaterial de repaso - Matemáticas de la optimización\nAula virtual Classroom\n\n\nModulo II - Teoria del Productor\n\n\nElasticidad Sustitución, Función de costos y matriz sustitución\n\n\nVideos\n\n\nComandos Generales Python\n\n\nModulo III - Estructuras de Mercado\n\n\nEjercicios equilibro a corto plazo - Competencia Perfecta\nCompetencia Perfecta: Largo y Corto Plazo\nPresentaciones sobre Monopolios\n\n\nAsignaciones\n\n\nTarea I\nTarea 3 - Teoría del Productor\nTarea Final - Estructuras de Mercado utilizando Python\n\n\nBibliografía Recomendada\n\n\nAdvanced Microeconomic Theory, Geoffrey A. Jehle Philip J.Reny\nTeoría Microeconómica (Principios básicos y ampliaciones-Walter Nikolso)\nMicroeconomia II - UNAH - Juan Isaula"
  },
  {
    "objectID": "Sobre_mi/index.html",
    "href": "Sobre_mi/index.html",
    "title": "Historias",
    "section": "",
    "text": "En esta sección de mi website conoceras un poco de las diferentes actividades que realizó o he realizado en algunos de mis días.\nCompartiendo con compañeros de la Maestría en Economía Matemática, México.\n\nCelebrando el cumpleaños de mi amigo Elmer, felicidades crack.\n\nLinda Experiencia, impartiendo el curso sobre fundamentos estadísticos utilizando el software de R a estudiantes de la maestría en Gestión de Proyectos de la UNAH.\n\n\n\n\n\nParticipación en conversatorio estudiantes egresados de la Lic. Matemáticas UNAH 2023\n\nNoche de Cine - 8/07/2023\n\nEquipo de Trabajo - IHSS\n\nFestejando Graduación (Lic. Matemáticas) de Amigos"
  },
  {
    "objectID": "Sobre_mi/sobre_mi.html",
    "href": "Sobre_mi/sobre_mi.html",
    "title": "Historias",
    "section": "",
    "text": "En esta sección de mi website conoceras un poco de las diferentes actividades que realizó o he realizado en algunos de mis días.\nCompartiendo con compañeros de la Maestría en Economía Matemática, México.\n\nCelebrando el cumpleaños de mi amigo Elmer, felicidades crack.\n\nLinda Experiencia, impartiendo el curso sobre fundamentos estadísticos utilizando el software de R a estudiantes de la maestría en Gestión de Proyectos de la UNAH.\n\n\n\n\n\nParticipación en conversatorio estudiantes egresados de la Lic. Matemáticas UNAH 2023\n\nNoche de Cine - 8/07/2023\n\nEquipo de Trabajo - IHSS\n\nFestejando Graduación (Lic. Matemáticas) de Amigos"
  },
  {
    "objectID": "papers/index.html",
    "href": "papers/index.html",
    "title": "Juan Isaula",
    "section": "",
    "text": "Artículos\n\n\n\n\nArtículos\n\nBienvenidos! En esta sección encontrará una selección de artículos que he escrito a lo largo de mi trayectoria profesional.\n\n\n\n\nImpacto Aranceles de EE.UU sobre el desempeño de las Tarjetas de Crédito y Préstamos en Honduras\nModelando Riesgo Crediticio con Python\nFundamentos Estadísticos con R\nMatemáticas de la Optimización - Microeconomía\nTest de Jarque-Bera con Python\nRedes Neuronales LSTM vs GRU\nPronósticos de Inflación Honduras utilizando Redes Neuronales\nCredit Scoring"
  },
  {
    "objectID": "Dasboard/index.html",
    "href": "Dasboard/index.html",
    "title": "App/Dashboards",
    "section": "",
    "text": "En esta sección encontrará algunas herramientas (App) que he desarrollado en lenguajes de programación R y Python, elaborados para distintas instituciones del país (Honduras) .\n\nGeoRGe\nAplicación creada R, utilizando principalmente los paquetes shiny | shinydashboard | DT | tidyverse | shinyWidgets | fresh. En la actualizad es utilizada en el Instituto Hondureño de Seguridad Social (IHSS). [Ver aplicación aquí]\nIA-JIM\nAplicación diseñada para facilitar el cálculo de gran parte de los indicadores actuariales primarios y secundarios del IHSS, en el marco del Régimen del Seguro de Previsión Social (RSPS). [Ver aplicación aquí]"
  },
  {
    "objectID": "posts/Neural Network/index.html",
    "href": "posts/Neural Network/index.html",
    "title": "Arquitectura de Redes Neuronales",
    "section": "",
    "text": "Las arquitecturas de redes neuronales se refieren a los diseños estructurales y organizativos de redes neuronales artificiales (RNA). Estas arquitecturas determinan cómo se organiza la red, incluida la cantidad de capas, la cantidad de neuronas en cada capa, las conexiones entre neuoronas y las funciones de activación utilizadas. Se forman diferentes arquitecturas de redes neuronales alterando estos componentes estructurales para adaptarse a tareas o desafíos específicos. Si desea conocer los tipos de arquitectura de redes neuronales que debe conocer, este artículo es para usted. En este artículo, le explicaré los tipos de arquitecturas de redes neuronales en Machine Learning y cuándo elegirlas."
  },
  {
    "objectID": "posts/Neural Network/index.html#fundamentos-previos-a-la-comprensión-de-redes-neuronales",
    "href": "posts/Neural Network/index.html#fundamentos-previos-a-la-comprensión-de-redes-neuronales",
    "title": "Arquitectura de Redes Neuronales",
    "section": "Fundamentos previos a la comprensión de Redes Neuronales",
    "text": "Fundamentos previos a la comprensión de Redes Neuronales\n\nFunción de Activación\nUna función de activación es una función que se agrega a una red neuronal para ayudar a la red a aprender dependencias no lineales complejas. Una función de activación típica debe ser diferenciable y continua en todas partes. A continuación proporcionaré algunos ejemplos de funciones de activación utilizando la biblioteca PyTorch.\n\nFunción ReLU\nReLU o la función ReLU realiza una operación simple: \\(y = \\max (0, x)\\). Aquí te proporcionó un ejemplo de uso de la función ReLU utilizando PyTorch.\n\nimport torch\nimport torch.nn as nn\nimport matplotlib.pyplot as plt\n\nx = torch.linspace(-10, 10,steps=100)\n\nrelu = torch.nn.ReLU()\n\ny = relu(x)\nplt.title(\"ReLU\")\nplt.plot(x.tolist(), y.tolist())\nplt.show()\n\n\n\n\n\n\n\n\n\n\nFunción Sigmoidea\nEs una de las funciones de activación no lineal más comunes. La función sigmoidea se representa matemáticamente como:\n\\[\n\\sigma(x) = \\frac{1}{1 + e^x}\n\\]\nAl igual que ReLU, la función \\(\\sigma\\) se puede construir simplemente usando PyTorch.\n\nimport torch\nimport torch.nn as nn\nimport matplotlib.pyplot as plt\n\nx = torch.linspace(-10, 10,steps=100)\n\nsigmoid = torch.nn.Sigmoid()\n\ny = sigmoid(x)\nplt.title(\"Sigmoidea\")\nplt.plot(x.tolist(), y.tolist())\nplt.show()\n\n\n\n\n\n\n\n\n\n\nFunción Tanh\nLa función tangente hiperbólica es similar a la función sigmoidea, pero devuelve valores en el rango \\((-1,1)\\). El beneficio de Tanh sobre \\(\\sigma\\) es que las entradas negativas se asignarán estrictamente a negativa, y las entradas positivas se asignarán estrictamente a positivas:\n\\[\n\\tanh(x) = \\frac{e^x - e^{-x}}{e^x + e^{-x}}\n\\]\n\nimport torch\nimport matplotlib.pyplot as plt\n\nx=torch.linspace(-10,10, steps = 100)\ntanh = torch.nn.Tanh()\ny = tanh(x)\n\nplt.title('Tanh')\nplt.plot(x.tolist(),y.tolist())\nplt.show()\n\n\n\n\n\n\n\n\nLas funciones de activación no lineales, como la \\(\\sigma\\) y \\(\\tanh\\) sufren de un gran problema computacional llamado problema de fuga de gradiente.\nLa fuga de gradiente hace que sea muy difícil entrenar y ajustar los parámetros de las capas iniciales en la red. Este problema empeora a medida que aumenta el número de capas en la red.\nLa fuga de gradiente es la causa principal que hace que las activaciones sigmoideas o Tanh no sean adecuadas para los modelos de Deep Learning (aprendizaje profundo). La función de activación ReLU no sufre de gradiente de fuga porque la derivada siempre es 1 para entradas positivas. Así que siempre considere usar ReLU como la función de activación en los primeros borradores del diseño de su modelo.\n\nLa creación de una arquitectura de red neuronal que se adapte más a un problema en particular es un arte. Existe una dirección de estudio separada en el aprendizaje profundo llamado Búsqueda de arquitectura neural, que automatiza la ingeniería de arquitectura de red: https://lilianweng.github.io/lil-log/2020/08/06/neural-architecture-search.html. Pero incluso estos motores de búsqueda no pueden competir con las habilidades heurísticas humanas en el diseño todavía. Existen algunas técnicas que aumentan la probabilidad de mejorar el rendimiento de la red neuronal. Por supuesto, estas técnicas no garantizan la mejora en todos los casos. A veces incluso pueden empeorar el rendimiento de la red neuronal. Pero es probable que desarrolle una arquitectura de modelo robusta siguiendo estos enfoques.\n\n\n\nFunciones de Pérdida y Optimización\n\nFunciones de Pérdida\nLa función de pérdida calculará un error de red en cada iteración, mientras que la función de optimización determina “cómo y en qué dirección cambiar los parámetros de peso”.\nHay una cantidad diversa de funciones de pérdida, cada una de ellas está destinada a una tarea en particular. Para el análisis de series de tiempo, hay tres funciones de pérdida principales:\n\nPérdida absoluta (L1): La pérdida absoluta es la métrica más simple de la distancia entre dos vectores:\n\\[\nabsolute loss = \\frac{\\sum |y_{actual} - y_{predicción}|}{n}\n\\]\nEn PyTorch, la función de pérdida absoluta se implementa de la siguiente manera:\n\na = torch.tensor([1,2]).float()\nb = torch.tensor([1, 5]).float()\nabs_loss = torch.nn.L1Loss()\nabs_error = abs_loss(a,b)\nprint(f'abs: {abs_error.item()}')\n\nabs: 1.5\n\n\nError cuadrático medio (MSE) (L2): Es la función de pérdida más utilizada para los problemas de predicción de series de tiempo:\n\\[\nmean\\_squared\\_error =  \\frac{\\sum(y_{actual} - y_{predicted})^2}{n}\n\\]\nPérdida suave (L1): es algo intermedio entre las funciones de pérdida absoluta y MSE. La pérdida absoluto (L1) es menos sensible a los valores atípicos que MSE:\n\\[\nsmooth\\_loss(y^{\\prime},y) = \\frac{1}{n}\\sum z_i\n\\]\ndonde \\(y\\) es valor real, \\(y\\) se predice, \\(z_i\\) se define como:\n\\[ z =\n\\begin{equation}\n\\begin{matrix}\n  \\frac{0.5(y_{i}^{\\prime} - y_i)^2}{\\beta}, & |y_{i}^{\\prime} - y_i| &lt; \\beta\\\\  \n|y_{i}^{\\prime} - y_i| - 0.5\\beta, & otro\\_caso\n  \\end{matrix}\n\\end{equation}\n\\]\n\nLa función de pérdida de L1 suave tiene un parámetro \\(\\beta\\), es igual a 1 por defecto.\n\n\nOptimizador\nEl objetivo principal de un optimizador es cambiar los parámetros de pesos del modelo para minimizar la función de pérdida. La selección de un optimizador adecuado depende completamente de la arquitectura de la red neuronal y los datos sobre los que ocurre el entrenamiento.\n\nAdagrad: es un algoritmo de optimización basado en gradiente que adapta la tasa de aprendizaje a los parámetros. Realiza actualizaciones más pequeñas para los parámetros asociados con características frecuentes y actualizaciones más grandes para parámetros asociados con características raras.\nAdadelta es la versión avanzada del algoritmo de Adagrad. Adadelta busca minimizar su tasa de aprendizaje agresiva y monotónica que disminuye. En lugar de acumular todos los gradientes pasados.\nAdam es otro método de optimización que calcula las tasas de aprendizaje adaptativo para cada parámetro. Además de guardar un promedio exponencialmente en descomposición de gradientes cuadrados anteriores como Adadelta, Adam también mantiene un promedio exponencialmente de disminución de gradientes anteriores."
  },
  {
    "objectID": "posts/Neural Network/index.html#tipos-de-redes-neuronales",
    "href": "posts/Neural Network/index.html#tipos-de-redes-neuronales",
    "title": "Arquitectura de Redes Neuronales",
    "section": "Tipos de Redes Neuronales",
    "text": "Tipos de Redes Neuronales\nComenzaremos explorando algunas de las arquitecturas de redes neuronales más eficientes para el pronóstico de series de tiempo. Nos centraremos en la implementación de redes neuronales recurrentes (RNN), unidad recurrentes cerradas (GRU), redes de memoria a largo plazo (LSTM). Comprender los principios básicos de las RNN será una buena base para su aplicación directa y dominar otras arquitecturas similares. Trataremos de cubrir la lógica y el núcleo de cada arquitectura, su aplicación práctica y pros y contras.\nDiscutiremos los siguientes temas:\n\nRecurrent neural network (RNN)\nGated recurrent unit network (GRU)\nLong short-term memory network (LSTM)\n\n\nRecurrent Neural Network (RNN)\nRNN (Red Neuronal Recurrente Estándar) tiene un concepto de un estado oculto. Un estado oculto puede tratarse como memoria interna. El estado oculto no intenta recordar todos los valores pasados de la secuencia sino solo su efecto. Debido a la memoria interna, las RNN pueden recordar cosas importantes sobre su entrada, lo que les permite ser muy preciosos para predecir valores futuros.\nEstudiemos la teoría de RNN de una manera más formal. En RNN, la secuencia de entrada se representa a traves de un bucle. Cuando toma una decisión, considera la entrada actual y también lo que ha aprendido de las entradas que recibio anteriormente. Veamos el gráfico computacional de RNN para comprender esta lógica:\n\n\n\nGráfico Computacional de RNN\n\n\ndonde,\n\n\\(x_1, x_2, . . . , x_n\\) son la secuencia de entrada.\n\\(h_i\\) es el estado oculto. \\(h_i\\) es un vector de longitud \\(h\\).\nRNN Cell representa la capa de red neuronal que calcula la siguiente función: \\(h_t = \\tanh(W_{ih}x_t + b_{ih} + W_{hh}h_{(t-1)} + b_{hh})\\)\n\nPodemos ver a detalle la RNN Cell:\n\n\n\nGráfico computacional de RNN Cell\n\n\nLa RNN Cell combina información sobre el valor actual de la secuencia \\(x_i\\) y el estado previamente oculto \\(h_{i-1}\\). La RNN Cell, devuelve un estado oculto actualizado \\(h_i\\) después de aplicar la función de activación.\nLa RNN tiene los siguientes parámetros, que se ajustan durante el entrenamiento:\n\n\\(W_{ih}\\) pesos ocultos de entrada\n\\(b_{ih}\\) sesgos oculto de entrada\n\\(W_{hh}\\) pesos ocultos - ocultos\n\\(B_{hh}\\) sesgos oculto - oculto\n\nNota: Un error común ocurre cuando los subíndices en los parámetros RNN \\((W_{ih}, b_{ih}, W_{hh}, b_{hh})\\) se interpretan como una dimensión de índice o tensor. No, son solo la abreviatura de entrada-oculto \\((h_í)\\) y oculto-oculto \\((h)\\). El mismo principio aplica a los parámetros de otros modelos: GRU y LSTM.\nEn ocasiones, los cientificos de datos utilizan la siguiente representación de las RNN:\n\n\n\nVisualización alternativa de RNN\n\n\nEl gráfico que se muestra puede dar lugar a algunos malentendidos, y estoy tratando de evitar esto. Pero si este tipo de gráfico se adapta a tu intuición, entonces úsalo sin ninguna duda.\n\nAhora estamos listos para examinar una implementación de RNN utilizando PyTorch\n\nimport torch.nn as nn\n\nclass RNN(nn.Module):\n\n    def __init__(self,\n                 hidden_size,\n                 in_size = 1,\n                 out_size = 1):\n        super(RNN, self).__init__()\n        self.rnn = nn.RNN(\n            input_size = in_size,\n            hidden_size = hidden_size,\n            batch_first = True)\n        self.fc = nn.Linear(hidden_size, out_size)\n\n    def forward(self, x, h = None):\n        out, _ = self.rnn(x, h)\n        last_hidden_states = out[:, -1]\n        out = self.fc(last_hidden_states)\n        return out, last_hidden_states\n\nNote que nuestro modelo devuelve dos salidas: predicción y estado oculto. Es crucial reutilizar los estados ocultos durante la evaluación RNN. Utilizaremos conjuntos de datos de consumo de energía por hora ( https://www.kaggle.com/robikscube/Hourly-energy-Consumed) para la implementación de RNN.\n\nimport pandas as pd\nimport torch\n\ndf = pd.read_csv('AEP_hourly.csv')\nts = df['AEP_MW'].astype(int).values.reshape(-1, 1)[-3000:]\n\nimport matplotlib.pyplot as plt\n\nplt.title('AEP Hourly')\nplt.plot(ts[:500])\nplt.show()\n\n\n\n\n\n\n\n\nPodemos ver en que esta es una serie de tiempo realmente complicada. Tiene varios factores de estacionalidad con picos apenas predecibles.\nA continuación, voy a mostrarte como se desempeña RNN en la serie de tiempo AEP Hourly:\n\nimport copy\nimport random\nimport sys\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch\nfrom sklearn.preprocessing import MinMaxScaler\n\nrandom.seed(1)\ntorch.manual_seed(1)\n\n# Parametros globales\n\n\nfeatures = 240\n# Longitud del conjunto de datos de prueba\ntest_ts_len = 300\n# tamaño del estado oculto\nrnn_hidden_size = 24\n# tasa de aprendizaje de optimizador\nlearning_rate = 0.02\n\ntraining_epochs = 500\n\ndef sliding_window(ts, features):\n    X = []\n    Y = []\n\n    for i in range(features + 1, len(ts) + 1):\n        X.append(ts[i - (features + 1):i - 1])\n        Y.append([ts[i - 1]])\n\n    return X, Y\n\ndef get_training_datasets(ts, features, test_len):\n    X, Y = sliding_window(ts, features)\n\n    X_train, Y_train, X_test, Y_test = X[0:-test_len],\\\n                                       Y[0:-test_len],\\\n                                       X[-test_len:],\\\n                                       Y[-test_len:]\n\n    train_len = round(len(ts) * 0.7)\n\n    X_train, X_val, Y_train, Y_val = X_train[0:train_len],\\\n                                     X_train[train_len:],\\\n                                     Y_train[0:train_len],\\\n                                     Y_train[train_len:]\n\n    x_train = torch.tensor(data = X_train).float()\n    y_train = torch.tensor(data = Y_train).float()\n\n    x_val = torch.tensor(data = X_val).float()\n    y_val = torch.tensor(data = Y_val).float()\n\n    x_test = torch.tensor(data = X_test).float()\n    y_test = torch.tensor(data = Y_test).float()\n\n    return x_train, x_val, x_test,\\\n           y_train.squeeze(1), y_val.squeeze(1), y_test.squeeze(1)\n           \n\n# Preparando datos para entrenamiento\nscaler = MinMaxScaler()\nscaled_ts = scaler.fit_transform(ts)\nx_train, x_val, x_test, y_train, y_val, y_test =\\\n    get_training_datasets(scaled_ts, features, test_ts_len)\n    \n\n# Inicialización del modelo \nmodel = RNN(hidden_size = rnn_hidden_size)\nmodel.train()\n\n/var/folders/sg/qphrr1zj1qn5sjtfpqllwx6m0000gn/T/ipykernel_66519/1156180628.py:50: UserWarning:\n\nCreating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:257.)\n\n\n\nRNN(\n  (rnn): RNN(1, 24, batch_first=True)\n  (fc): Linear(in_features=24, out_features=1, bias=True)\n)\n\n\n\n# Entrenamiento\noptimizer = torch.optim.Adam(params = model.parameters(), lr = learning_rate)\nmse_loss = torch.nn.MSELoss()\n\nbest_model = None\nmin_val_loss = sys.maxsize\n\ntraining_loss = []\nvalidation_loss = []\n\nfor t in range(training_epochs):\n\n    prediction, _ = model(x_train)\n    loss = mse_loss(prediction, y_train)\n\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n\n    val_prediction, _ = model(x_val)\n    val_loss = mse_loss(val_prediction, y_val)\n\n    training_loss.append(loss.item())\n    validation_loss.append(val_loss.item())\n\n    if val_loss.item() &lt; min_val_loss:\n        best_model = copy.deepcopy(model)\n        min_val_loss = val_loss.item()\n\n    if t % 50 == 0:\n        print(f'epoch {t}: train - {round(loss.item(), 4)}, '\n              f'val: - {round(val_loss.item(), 4)}')\n\nepoch 0: train - 0.377, val: - 0.0866\nepoch 50: train - 0.0061, val: - 0.0133\nepoch 100: train - 0.0021, val: - 0.0044\nepoch 150: train - 0.0018, val: - 0.0034\nepoch 200: train - 0.0015, val: - 0.003\nepoch 250: train - 0.0014, val: - 0.0027\nepoch 300: train - 0.0013, val: - 0.0026\nepoch 350: train - 0.0012, val: - 0.0025\nepoch 400: train - 0.0012, val: - 0.0024\nepoch 450: train - 0.0012, val: - 0.0024\n\n\nY aquí llegamos al punto más difícil. Debe pasar el estado oculto al modelo RNN cuando lo evalua. La forma más sencilla de calentar el estado oculto es ejecutar el modelo en los datos de validación una vez y pasar un estado oculto cálido a través de cada iteración y por último evaluamos el modelo que construimos en el conjunto de datos de prueba.\n\nbest_model.eval()\n_, h_list = best_model(x_val)\n\nh = (h_list[-1, :]).unsqueeze(-2)\n\n\npredicted = []\nfor test_seq in x_test.tolist():\n    x = torch.Tensor(data = [test_seq])\n \n    y, h = best_model(x, h.unsqueeze(-2))\n    unscaled = scaler.inverse_transform(np.array(y.item()).reshape(-1, 1))[0][0]\n    predicted.append(unscaled)\n\nreal = scaler.inverse_transform(y_test.tolist())\nplt.title(\"Conjunto de datos prueba - RNN\")\nplt.plot(real, label = 'real')\nplt.plot(predicted, label = 'predicción')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nRNN muestra un gran rendimiento en el conjunto de datos de prueba. El modelo que hemos entrenado predice picos estacionales con mucha precisión.\nY finalmente, examinamos el proceso de entrenamiento en sí.\n\nplt.title('Desempeño RNN')\nplt.yscale('log')\nplt.plot(training_loss, label = 'Entrenamiento')\nplt.plot(validation_loss, label = 'validación')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nEl proceso del entrenamiento es suave sin picos agudos e impredecibles.\nAhora, podemos establecer con confianza la promesa y la efectividad de la aplicación de RNN a los problemas de pronósticos de la serie temporal.\nA pesar de todas las ventajas de RNN, tiene desventajas significativas:\n\nDebido a la complejidad computacional, sufren problemas de gradiente de fuga. El proceso de entrenamiento se vuelve demasiado lento. El problema del gradiente de fuga es un problema común a todas las RNN.\nEl estado oculto se actualiza en cada iteración, lo que dificulta el almacenamiento de información a largo plazo en RNN. Las arquitecturas GRU y LSTM resuelven este problema. Tienen enfoques similares sobre cómo almacenar información a largo plazo.\n\n\n\nGated recurrent unit network (GRU)\nLa GRU es es una versión avanzada de la RNN clásica. El propósito principal de GRU es almacenar información a largo plazo. En breve exploraremos como GRU logra esto.\nLa forma más fácil de almacenar información a largo plazo en un estado oculto es restringir las actualizaciones ocultas sobre cada iteración. Este enfoque evitará sobrescribir información importante a largo plazo.\nPuede encontrar la siguiente definición de GRU en internet:\nSe comienza calculando la puerta de actualización \\(z_t\\) para el peso de tiempo \\(t\\) usando la fórmula:\n\\[\n\\begin{eqnarray*}\nz_{t} &=& \\sigma(W^{z}x_t + U^{z}h_{t-1}) \\hspace{1cm} \\mbox{Puerta de actualización}\\\\[0.2cm]\n\\end{eqnarray*}\n\\]\nlo que sucede aquí es que cuando \\(x_t\\) se conecta a la unidad de red, se multiplica por su propio peso \\(W^{z}\\). Lo mismo ocurre con \\(h_{t-1}\\), que contiene la información de las unidades \\(t-1\\) anteriores y se múltiplica por su propio peso \\(U^{z}\\). Ambos resultados se suman y se aplica una función de activación sigmoidea \\((\\sigma)\\) para acotar el resultado entre 0 y 1.\n\nLa puerta de actualización ayuda al modelo a determinar cuánta información pasada (de pasos de tiempo anteriores) debe transmitirse al futuro. Esto es muy poderoso porque el modelo puede decidir copiar toda la la información del pasado y eliminar el riesgo de que desaparezca el problema de fuga del gradiente.\nLuego continuamos con Restablecer puerta:\nBásicamente, esta puerta se utiliza desde el modelo para decidir cuánta información pasada se debe olvidar. Para calcularlo utilizamos:\n\\[\nr_t = \\sigma(W^{r}x_t + U^{r}h_{t-1})\\hspace{1cm} \\mbox{Restablecer puerta}\n\\]\nEsta fórmula es la misma que la de la puerta de actualización. La diferencia viene en los pesos y el uso de la puerta, que veremos en un momento.\n\nComo antes, conectamos \\(h_{t-1} - \\mbox{linea azul}\\) y \\(x_{t} - \\mbox{linea violeta}\\), los multiplicamos con sus pesos correspondientes, sumamos los resultados y aplicamos la función sigmoidea.\nContenido de la memoria actual:\nveamos como afectarán exactamente las puertaas al resultado final. Primero, comenzamos con el uso de la puerta de reinicio. Introducimos un nuevo contenido de memoria que utilizará la puerta de reinicio para almacenar la información del pasado. Se calcula de la siguiente manera:\n\\[\nh_{t}^{\\prime} = tanh(Wx_{t} + r_{t}\\odot U h_{t-1})\n\\]\n\nMultiplique la entrada \\(x_t\\) con un peso \\(W\\) y \\(h_{t-1}\\) con un peso \\(U\\).\nCalcule el producto de Hadamard (por elementos) entre la puerta de reinicio \\(r_t\\) y \\(Uh_{t-1}\\). Eso determinará qué eliminar de los pasos de tiempo anterior. Digamos que tenemos un problema de análisis de sentimientos para determinar la opinión de una persona sobre un libro a partir de una reseña que escribió. El texto comienza con “Este es un libro de fantasía que ilustra…” y después de un par de párrafos termina con “No disfruté mucho el libro porque creo que captura demasiados detalles”. Para determinar el nivel general de satisfacción con el libro sólo necesitamos la última parte de la reseña. En ese caso, a medida que la red neuronal se acerque al final del texto, aprenderá a asignar un vector \\(r_t\\) cercano a 0, eliminando el pasado y centrándose solo en las últimas oraciones.\nResuma los resultados de los pasos 1 y 2.\nAplicar la función de activación no lineal tanh.\n\nPuedes ver claramente los pasos aquí:\n\nHacemos una multiplicación por elementos de \\(h_{t-1} - \\mbox{línea azul}\\) y \\(r_t - \\mbox{línea naranja}\\) y luego sumamos el resultado - linea rosa con la entrada \\(x_t -\\) línea morada. Finalmente, tanh se usa para producir \\(h_{t}^{\\prime}:\\) línea verde brillante.\nMemoria final en el paso de tiempo actual\nComo último paso, la red necesita calcular \\(h_{t}\\), el vector que contiene información para la unidad actual y la transmite a la red. Para hacer eso, se necesita la puerta de actualización. Determina qué recopilar el contenido de la memoria actual \\((h_t^{\\prime})\\) y qué de los pasos anteriores \\((h_{(t-1)})\\). Eso se hace de la siguiente manera:\n\\[\nh_t = z_t\\odot h_{t-1} + (1 - z_t)\\odot h_{t}^{\\prime}\n\\]\n\nAplique la multiplicación por elementos a la puerta de actualización \\(z_t\\) y \\(h_{(t-1)}\\).\nAplique la multiplicación por elementos a \\((1- z_t)\\) y \\(h_{t}^{\\prime}\\).\nSume los resultados de los pasos 1 y 2.\n\nPongamos el ejemplo de la reseña del equilibrio. En esta ocasión, la información más relevante se situa al inicio del texto. El modelo puede aprender a establecer el vector \\(z_t\\) cerca de 1 y conservar la mayor parte de la información anterior. Dado que \\(z_t\\) estará cerca de 1 en este paso de tiempo, \\((1-z_t)\\) estará cerca de 0, lo que ignorará gran parte del contenido actual (en este caso, la última parte de la reseña que explica la trama del libro), lo cual es irrelevante para nuestra predicción.\nAquí hay una ilustración que enfatiza la ecuación anterior:\n\nA continuación, puede ver cómo \\(z_t\\) (línea verde) para calcular \\(1 - z_t\\) que combinado con \\(h_{t}^{\\prime}\\) (línea verde brillante), produce un resultado en la línea roja oscura. \\(z_t\\) también se usa con \\(h_{t-1} - \\mbox{línea azul}\\) en una multiplicación de elementos. Finalmente, \\(h_{t}:\\) la línea azul es el resultado de la suma de las salidas correspondientes a las líneas rojas brillantes y oscuras.\nAhora puede ver cómo las GRU pueden almacenar y filtrar la información utilizando sus puertas de actualización y reinicio. Eso elimina el problema del gradiente de fuga, ya que el modelo no elimina la nueva entrada cada vez, sino que mantiene la información relevante y la pasa a los siguientes pasos de la red. Si se les entrena cuidadosamente, pueden desempeñarse extremadamente bien incluso en escenarios complejos.\nEl modelo de predicción GRU es muy similar al RNN. Veamos su desempeño utilizando la misma data que el casa RNN.\n\nimport torch.nn as nn\n\nrandom.seed(1)\ntorch.manual_seed(1)\n\n\nfeatures = 240\ntest_ts_len = 300\ngru_hidden_size = 24\nlearning_rate = 0.02\ntraining_epochs = 500\n\nclass GRU(nn.Module):\n\n    def __init__(self,\n                 hidden_size,\n                 in_size = 1,\n                 out_size = 1):\n        super(GRU, self).__init__()\n        self.gru = nn.GRU(\n            input_size = in_size,\n            hidden_size = hidden_size,\n            batch_first = True)\n        self.fc = nn.Linear(hidden_size, out_size)\n\n    def forward(self, x, h = None):\n        out, _ = self.gru(x, h)\n        last_hidden_states = out[:, -1]\n        out = self.fc(last_hidden_states)\n        return out, last_hidden_states\n\n# Inicializando el modelo GRU\nmodel = GRU(hidden_size = gru_hidden_size)\nmodel.train()\n\n# Entrenamiento\noptimizer = torch.optim.Adam(params = model.parameters(), lr = learning_rate)\nmse_loss = torch.nn.MSELoss()\n\nbest_model = None\nmin_val_loss = sys.maxsize\n\ntraining_loss = []\nvalidation_loss = []\n\n\nfor t in range(training_epochs):\n\n    prediction, _ = model(x_train)\n    loss = mse_loss(prediction, y_train)\n\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n\n    val_prediction, _ = model(x_val)\n    val_loss = mse_loss(val_prediction, y_val)\n\n    training_loss.append(loss.item())\n    validation_loss.append(val_loss.item())\n\n    if val_loss.item() &lt; min_val_loss:\n        best_model = copy.deepcopy(model)\n        min_val_loss = val_loss.item()\n\n    if t % 50 == 0:\n        print(f'epoch {t}: train - {round(loss.item(), 4)}, '\n              f'val: - {round(val_loss.item(), 4)}')\n\nbest_model.eval()\n_, h_list = best_model(x_val)\nh = (h_list[-1, :]).unsqueeze(-2)\n\npredicted = []\nfor test_seq in x_test.tolist():\n    x = torch.Tensor(data = [test_seq])\n    y, h = best_model(x, h.unsqueeze(-2))\n    unscaled = scaler.inverse_transform(np.array(y.item()).reshape(-1, 1))[0][0]\n    predicted.append(unscaled)\n\nepoch 0: train - 0.0626, val: - 0.0326\nepoch 50: train - 0.0017, val: - 0.0026\nepoch 100: train - 0.0012, val: - 0.0024\nepoch 150: train - 0.0012, val: - 0.0023\nepoch 200: train - 0.0011, val: - 0.0022\nepoch 250: train - 0.0011, val: - 0.0022\nepoch 300: train - 0.0011, val: - 0.0023\nepoch 350: train - 0.0011, val: - 0.0023\nepoch 400: train - 0.0011, val: - 0.0022\nepoch 450: train - 0.0011, val: - 0.0022\n\n\n\nreal = scaler.inverse_transform(y_test.tolist())\nplt.title(\"Conjunto de datos prueba - GRU\")\nplt.plot(real, label = 'real')\nplt.plot(predicted, label = 'predicción')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nVemos que el modelo GRU imita el comportamiento original de la serie temporal con bastante precisión.\n\nplt.title('Desempeño GRU')\nplt.yscale('log')\nplt.plot(training_loss, label = 'Entrenamiengto')\nplt.plot(validation_loss, label = 'validación')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nLas pérdidas de entrenamiento y validación tienen descenso asintótico con un brecha natural constante entre ellas. Podemos concluir que el modelo realmente aprende el comportamiento de la serie temporal.\n\n\nLong short-term memory network (LSTM)\nLa red LSTM se ha desarrollado para superar el problema de fuga de gradiente en RNN al mejorar el flujo de gradiente de la red. Debe mencionarse que la arquitectura apareció mucho antes que la GRU. La arquitectura LSTM se desarrolló en 1997, y el GRU se propueso en 2014. El diseño GRU es más simple y más comprensible que LSTM. Es por eso que comenzamos nuestro estudio examinando primero GRU.\nComo su nombre lo índica, LSTM aborda los mismos problemas de memoria a corto y largo plazo que GRU. A nivel global, el flujo computacional del LSTM se ve de la siguiente manera:\n\nLSTM funciona sobre los principios similares que GRU pero tiene más variables. RNN y GRU solo pasan un estado oculto \\(h_t\\) a través de cada iteración. Pero LSTM pasa dos vectores:\n\n\\(h_t\\) estado oculto (memoria a corto plazo)\n\\(c_t\\) estado de celda (memoria a largo plazo)\n\nLas salidas de LSTM Cell se calculan a través de las fórmulas:\n\\[\n\\begin{eqnarray*}\ni_t &=& \\sigma(W_{ii}x_t + b_{ii} + W_{hi}h_{t-1} + b_{hi})\\\\[0.2cm]\nf_t &=& \\sigma(W_{ii}x_{t} + b_{if} + W_{hf}h_{t-1} + b_{hf})\\\\[0.2cm]\ng_t &=& tanh(W_{ig}x_t + b_{ig} + W_{hg}h_{t-1} + b_{hn})\\\\[0.2cm]\no_t &=& \\sigma(W_{io}x_t + b_{io} + W_{ho}h_{t-1} + b_{ho})\\\\[0.2cm]\nc_t &=& f_t \\circ c_{t-1} + i_t\\circ g_t\\\\[0.2cm]\nh_t &=& o_t \\circ tanh(c_t)\n\\end{eqnarray*}\n\\]\ndonde:\n\n\\(\\sigma\\) es la función sigmoidea\n\\(\\circ\\) es el producto de Hadamard\n\nEn cuanto a las variables:\n\n\\(i_t~(puerta de entrada)\\) es la variable que se utiliza para actualizar el estado \\(c_t\\). El estado previamente oculto \\(h_t\\) y la secuencia \\(x_t\\) se dan como entradas a una función sigmoidea \\((\\sigma)\\). Si la salida está cerca de 1, entonces la información es más importante.\n\\(f_t ~ (puerta~de~olvido)\\) es la variable que decide que información debe olvidarse en el estado \\(c_t\\). El estado \\(h_t\\) de estado previamente oculto y la secuencia \\(x_t\\) se dan como entradas a una función sigmoidea. Si la salida \\(f_t\\) está cerca de cero, la información se puede olvidar, mientras que si la salida está cerca de 1, la información debe almacenarse o recordarse.\n\\(g_t\\) representa información importante potencialmente nueva para el estado \\(c_t\\).\n\\(c_t ~ (estado~celda)\\) es una suma de:\n\nestado de celda anterior \\(c_{t-1}\\) con información olvidada \\(f_t\\).\nnueva información de \\(g_t\\) seleccionada por \\(i_t\\)\n\n\\(o_t ~ (puerta~de~salida)\\) es la variable para actualizar el estado oculto \\(h_t\\).\n\\(h_t ~(estado~oculto)\\) es el siguiente estado oculto que se calcula eligiendo la información importante del estado de celda o celular \\(c_t\\).\n\nA continuación te muestro el gráfico computacional de la celda LSTM:\n\nLSTM tiene los siguientes parámetros, que se ajustan durante el entrenamiento:\n\n\\(W_{ii}, W_{hi}, W_{if}, W_{hf}, W_{ig}, W_{hg}, W_{io}, W_{ho}\\) estos son los pesos.\n\\(b_{ii}, b_{hi}, b_{if}, b_{hf}, b_{ig}, b_{hg}, b_{io}, b_{ho}\\) estos son sesgos.\n\nAhora examinemos la implementación de Pytorch del modelo de predicción LSTM:\n\nimport torch.nn as nn\n\nclass LSTM(nn.Module):\n\n    def __init__(self,\n                 hidden_size,\n                 in_size = 1,\n                 out_size = 1):\n        super(LSTM, self).__init__()\n        self.lstm = nn.LSTM(\n            input_size = in_size,\n            hidden_size = hidden_size,\n            batch_first = True)\n        self.fc = nn.Linear(hidden_size, out_size)\n\n    def forward(self, x, h = None):\n        out, h = self.lstm(x, h)\n        last_hidden_states = out[:, -1]\n        out = self.fc(last_hidden_states)\n        return out, h\n\nComo vemos, la implementación del modelo LSTM es bastante similar a las implementaciones de RNN y GRU.\nProbaremos el modelo LSTM con el siguiente conjunto de datos de la serie tiempo de consumo de energía por hora).\n\nimport pandas as pd\nimport torch\n\ndf = pd.read_csv('NI_hourly.csv')\nts = df['NI_MW'].astype(int).values.reshape(-1, 1)[-3000:]\n\nimport matplotlib.pyplot as plt\n\nplt.title('NI Hourly')\nplt.plot(ts[:500])\nplt.show()\n\n\n\n\n\n\n\n\nVeamos el modelo en acción:\n\nimport copy\nimport random\nimport sys\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch\nfrom sklearn.preprocessing import MinMaxScaler\n\nrandom.seed(1)\ntorch.manual_seed(1)\n\n\nfeatures = 240\ntest_ts_len = 300\nlstm_hidden_size = 24\nlearning_rate = 0.02\ntraining_epochs = 100\n\n# Preparar el conjunto de datos para el entrenamiento \nscaler = MinMaxScaler()\nscaled_ts = scaler.fit_transform(ts)\nx_train, x_val, x_test, y_train, y_val, y_test =\\\n    get_training_datasets(scaled_ts, features, test_ts_len)\n\n# Inicializando el modelo \nmodel = LSTM(hidden_size = lstm_hidden_size)\nmodel.train()\n\n# Entrenamiento \noptimizer = torch.optim.Adam(params = model.parameters(), lr = learning_rate)\nmse_loss = torch.nn.MSELoss()\n\nbest_model = None\nmin_val_loss = sys.maxsize\n\ntraining_loss = []\nvalidation_loss = []\n\n\nfor t in range(training_epochs):\n\n    prediction, _ = model(x_train)\n    loss = mse_loss(prediction, y_train)\n\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n\n    val_prediction, _ = model(x_val)\n    val_loss = mse_loss(val_prediction, y_val)\n\n    training_loss.append(loss.item())\n    validation_loss.append(val_loss.item())\n\n    if val_loss.item() &lt; min_val_loss:\n        best_model = copy.deepcopy(model)\n        min_val_loss = val_loss.item()\n\n    if t % 10 == 0:\n        print(f'epoch {t}: train - {round(loss.item(), 4)}, '\n              f'val: - {round(val_loss.item(), 4)}')\n\nepoch 0: train - 0.0979, val: - 0.087\nepoch 10: train - 0.0253, val: - 0.0255\nepoch 20: train - 0.0131, val: - 0.0119\nepoch 30: train - 0.0056, val: - 0.0059\nepoch 40: train - 0.0032, val: - 0.0043\nepoch 50: train - 0.0026, val: - 0.0029\nepoch 60: train - 0.002, val: - 0.0025\nepoch 70: train - 0.0018, val: - 0.0023\nepoch 80: train - 0.0016, val: - 0.0021\nepoch 90: train - 0.0014, val: - 0.0019\n\n\nPara una evaluación del modelo LSTM, necesitamos pasar un estado celular y estado oculto.\n\nbest_model.eval()\nwith torch.no_grad():\n    _, h_list = best_model(x_val)\n\n    h = tuple([(h[-1, -1, :]).unsqueeze(-2).unsqueeze(-2)\n               for h in h_list])\n\n    predicted = []\n    for test_seq in x_test.tolist():\n        x = torch.Tensor(data = [test_seq])\n\n        y, h = best_model(x, h)\n        unscaled = scaler.inverse_transform(\n            np.array(y.item()).reshape(-1, 1))[0][0]\n        predicted.append(unscaled)\n        \nreal = scaler.inverse_transform(y_test.tolist())\nplt.title(\"Conjunto de prueba - LSTM\")\nplt.plot(real, label = 'real')\nplt.plot(predicted, label = 'predicción')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nLSTM captura muy bien el comportamiento de las series temporales para hacer predicciones precisas.\n\nplt.title('Desempeño LSTM')\nplt.yscale('log')\nplt.plot(training_loss, label = 'Entrenamiento')\nplt.plot(validation_loss, label = 'validación')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nMirando, concluimos que detuvimos el proceso de entrenamiento demasiado temprano. Obtenemos modelos más precisos si establecemos más epocas (epoch) para el entrenamiento.\n\n\nCONCLUSIONES\nPudimos ver que las redes neuronales recurrentes muestran excelentes resultados y son adecuadas para problemas de pronósticos de series de tiempo.\nLas Redes Neuronales Recurrentes son la técnica muy popular de aprendizaje profundo (Deep Learning) para el pronóstico de series de tiempo, ya que permiten producir predicciones confiables en series de tiempo en diversos problemas. El principal problema con RNN es que sufre el problema de fuga de gradiente cuando se aplica a secuencia largas, y no tiene una herramienta de memoria a largo plazo. Se desarrollaron LSTM y GRU para evitar el problema de gradiente de RNN con el uso de puertas que regulan el flujo de información e implementan el almacenamiento de memoria a largo plazo. El uso de LSTM y GRU ofrece resultados notables, pero LSTM y GRU no siempre funcionan mejor que RNN.\n\nRNN tiene un estado oculto que puede tratarse como una memoria interna de la secuencia de entrada.\nRNN vuelve a calcular el estado oculto después de procesar cada nuevo valor de entrada de forma recurrente.\nRNN sufre un problema de fuga de gradiente.\nRNN actualiza un estado oculto en cada iteración. Por tanto, no tiene memoria a largo plazo.\nGRU implementa la puerta de reinicio, que rechaza algunas actualizaciones en un estado oculto.\nLSTM pasa dos vectores a través de cada iteración: estado oculto y estado de celda.\n\n\n\nREFERENCIAS\n\nTime Series Forecasting Using Deep Learning - Ivan Gridin\nUnderstanding GRU Networks"
  },
  {
    "objectID": "posts/estructuras_mercado/index.html",
    "href": "posts/estructuras_mercado/index.html",
    "title": "Estructuras de Mercado con Python",
    "section": "",
    "text": "Este post tiene como objetivo dar a conocer la importancia del software de Python en el ambito microeconomico, particularmente en este caso hablamos de las diferentes estructuras de mercado; competencia perfecta, monopolio y oligopolio."
  },
  {
    "objectID": "posts/estructuras_mercado/index.html#condiciones-necesaria-para-la-competencia-perfecta",
    "href": "posts/estructuras_mercado/index.html#condiciones-necesaria-para-la-competencia-perfecta",
    "title": "Estructuras de Mercado con Python",
    "section": "Condiciones necesaria para la competencia perfecta",
    "text": "Condiciones necesaria para la competencia perfecta\n\nMuchos productores, ninguno de los cuales tiene una gran cuota de mercado.\nUna industria puede ser perfectamente competitiva sólo si los consumidores consideran como equivalentes a los productos de todos los productores (producto homogéneo)"
  },
  {
    "objectID": "posts/estructuras_mercado/index.html#libre-entrada-y-salida",
    "href": "posts/estructuras_mercado/index.html#libre-entrada-y-salida",
    "title": "Estructuras de Mercado con Python",
    "section": "Libre entrada y salida",
    "text": "Libre entrada y salida\nExiste libre entrada y salida en una industria cuando nuevos productores pueden entrar facilmente en esa industria a los que ya estan en ella pueden abondonarla sin coste alguno.\n\nRegla de Producción Optima\nLa regla de producción optima dice que el beneficio se maximiza cuando se produce la cantidad de output para la cual el ingreso marginal de la última unidad de output producida es igual a su coste marginal.\n\\[\nIMg = CMg\n\\]\n\n\nFunción de Benenficios\nLa función de beneficios \\((\\pi)\\) representa las diferencias entre los costos totales, \\(C(Q)\\) e ingresos totales,\\(R(Q)\\) , de las empresas\n\\[\n\\pi = R(Q) - C(Q)\n\\]\n\n\nTomador de Precios\nPrecio igual al costo marginal\n\\[\n\\begin{eqnarray*}\nCMg = IMg = P\n\\end{eqnarray*}\n\\]\nPor tanto, se dice que el beneficio de una empresa precio-aceptante se maximiza produciendo la cantidad de output para la cual el costo marginal de la última unidad producida es igual al precio de mercado, tal como se aprecia en el siguiente gráfico\n\n\n\nCantidad de producto que maximiza el beneficio de una empresa precio-aceptante"
  },
  {
    "objectID": "posts/estructuras_mercado/index.html#costes-y-producción-en-el-corto-plazo",
    "href": "posts/estructuras_mercado/index.html#costes-y-producción-en-el-corto-plazo",
    "title": "Estructuras de Mercado con Python",
    "section": "Costes y Producción en el Corto Plazo",
    "text": "Costes y Producción en el Corto Plazo\nEn el corto plazo tenemos las siguientes condiciones de producción de empresas competitivas\n\n\n\n\n\n\n\nCondiciones\nResultados\n\n\n\n\nP &gt; CVMe mínimo\nLa empresa produce en el corto plazo. Si P &lt; CTMe mínimo, la empresa cubre sus costos variables y parte de sus costes fijos pero no todos. Si P &gt; CTMe mínimo, la empresa cubre todos sus costes variables y sus costes fijos.\n\n\nP = CVMe mínimo\nLa empresa es indiferente entre producir en el corto plazo o no producir. Cubre exactamente sus costes variables.\n\n\nP &lt; CVMe mínimo\nLa empresa cierra en el corto plazo. No cubre sus costes variables."
  },
  {
    "objectID": "posts/estructuras_mercado/index.html#ejemplo-1--corto-plazo",
    "href": "posts/estructuras_mercado/index.html#ejemplo-1--corto-plazo",
    "title": "Estructuras de Mercado con Python",
    "section": "Ejemplo # 1- Corto Plazo",
    "text": "Ejemplo # 1- Corto Plazo\nPrimero resolveremos el siguiente ejercicio de manera manual y posteriormente lo resolveremos en Python.\nSuponga que la empresa tiene una curva de costos de corto plazo dada por\n\\[\nC(Q) = 100 + 20Q + Q^2\n\\]\n\n¿Cuál es la ecuación para el costo variable Medio?\n¿Cuál es el valor mínimo para el costo variable promedio?\n¿Cuál es la curva de oferta de corto plazo?\n\nSolución\n\nDada la función de costo \\(C(Q) = 100 + 20Q + Q^2\\) es claro que el costo variable, CV, esta dado por \\[CV = 20Q + Q^2\\] por tanto su costo variable promedio es \\[CVMe = \\frac{CV}{Q} = 20 + Q\\]\nAhora bien, su costo marginal sabemos que unicamente requiere aplicar la regla de diferenciación, ya que \\[CMg = \\frac{\\partial C(Q)}{\\partial Q} = 20 + 2Q\\]\nSi queremos encontrar el costo variable promedio mínimo, \\[CVMe_{\\min}\\], se obtiene como \\[CMg = CVMe \\longrightarrow Q = \\fbox{0}\\]\nEntonces la función de oferta es: \\[\\begin{eqnarray*}CMg &=& p\\\\[0.2cm] 20 + 2Q &=& P\\\\[0.2cm] Q(P) &=& \\frac{P}{2} - 10 \\end{eqnarray*}\\]\n\nPor tanto, también podemos obtener el precio de equilibrio, ya que \\[0 = \\frac{P}{2} - 10 \\longrightarrow P = \\fbox{20}\\]\nAhora, encontremos estos resultados en Python:\n\n# Paquete previo \nfrom sympy import *\nQ = symbols(\"Q\")\n\n\n# función de costo de corto plazo \nCT = 100 + 20*Q + Q**2\n# costo variale promedio \nCV = 20 + Q \n# Encontrar el costo variable minimo \n# Primero: costo marginal\n\nCM = diff(CT,Q)\n\n\n# igualar costo marginal y costo variable promedio \nsolve(Eq(CM,CV))\n\n[0]\n\n\n\ncantidad = solve(Eq(CM,CV))\ncantidad[0]\n\n\\(\\displaystyle 0\\)\n\n\n\nP = CV.subs({Q:cantidad[0]})\nP\n\n\\(\\displaystyle 20\\)\n\n\n\nplot(CT, CT/Q, CV, CM, (Q,0,100), xlim = (0, 100), ylim = (0,100), xlabel = \"Q\", ylabel = \"P\")\n\n\n\n\n\n\n\n\nPuedes notar lo rápido y fácil que resulta realizar estos procedimientos con Python y la utilidad que puede brindarte en caso de que trabajes con volumnes de datos.\n\nEjemplo # 2 - Corto Plazo\nAhora suponga que la empresa tiene una curva costos en el corto plazo de la siguiente forma:\n\\[\nC(Q) = 1 + 10Q + Q^2\n\\]\nSi la empresa opera en un mercado perfectamente competitivo, donde \\(P = 12\\), ¿Cuál será los beneficios de la empresa en el corto plazo?\nSolución\nSabemos que la función de beneficios esta dada por\n\\[\n\\pi = R - C\n\\]\nentonces,\n\\[\n\\frac{\\partial \\pi}{\\partial Q} = IMg - CMg = 0\n\\]\nasí pues,\n\\[\nCMg = 10 + 2Q \\hspace{1cm}y\\hspace{1cm} IMg = P\n\\]\npor tanto,\n\\[\n\\begin{eqnarray*}\nCMg &=& IMg\\\\[0.2cm]\n10 + 2Q &=& P\\\\[0.2cm]\nQ &=& \\frac{P}{2} - 5\\\\[0.2cm]\nQ &=& \\frac{12}{2} - 5, \\hspace{2cm}\\mbox{ya que P = 12}\\\\[0.2cm]\nQ &=& \\fbox{1}\n\\end{eqnarray*}\n\\]\nentonces,\n\\[\n\\pi = 12 - (1 + 10 +1) = \\fbox{0}\n\\]\nAhora veamos esta solución en Python:\n\n# Función de costos a corto plazo \nQ = symbols(\"Q\")\nCT = Q**2 + 10*Q + 1\nP = 12\nR = P*Q\n# costo marginal\nCM = diff(CT,Q)\nCM\nIM = diff(R,Q)\nIM\ncantidad = solve(Eq(IM,CM))\nprint(\"El valor de la producción que garantiza un equilibrio será:\", cantidad[0])\n\nEl valor de la producción que garantiza un equilibrio será: 1\n\n\nEste resultado lo que nos dice es que la empresa oferta una unidad de producción \\(Q = 1\\).\n\n# Beneficio = IT - CT\ncosto = CT.subs({Q:cantidad[0]})\ncosto\n\n\\(\\displaystyle 12\\)\n\n\n\ningreso = R.subs({Q:cantidad[0]})\ningreso \n\n\\(\\displaystyle 12\\)\n\n\n\nBeneficios = R - CT\npi = Beneficios.subs({Q:cantidad[0]})\npi\n\n\\(\\displaystyle 0\\)\n\n\n\nplot(CT,CM,CT/Q,(Q,0,60), xlim=(0,5), ylim=(0,30), xlabel='Q', ylabel='CT,CM')\n\n\n\n\n\n\n\n\nRecuerde que todo este análisis se realizo para un mercado en competencia perfecta a corto plazo.\nPronto actualizare para el mercado en competencia perfecta a largo plazo, monopolio, e introducirnos un poco a la teoria de juegos."
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Juan Isaula",
    "section": "",
    "text": "Deep Learning\n\n\nPyTorch\n\n\n\nPython\n\n\nPyTorch\n\n\n\n\n\n\n\n\n\nJul 1, 2025\n\n\nJuan Isaula\n\n\n\n\n\n\n\n\n\n\n\n\nArquitectura de Redes Neuronales\n\n\n\n\n\n\nRNN\n\n\nGRU\n\n\nLSTM\n\n\nPyTorch\n\n\n\n\n\n\n\n\n\nJan 24, 2024\n\n\nJuan Isaula\n\n\n\n\n\n\n\n\n\n\n\n\nCredit Scoring and Segmentation using Python\n\n\nMachine Learning\n\n\n\nFICO\n\n\nCredit Scores\n\n\nPython\n\n\nsklearn\n\n\n\n\n\n\n\n\n\nSep 13, 2023\n\n\nJuan Isaula\n\n\n\n\n\n\n\n\n\n\n\n\nEstructuras de Mercado con Python\n\n\nCompetencia Perfecta, Monopolio y Oligopolio\n\n\n\nCMg\n\n\nCVP\n\n\nCTP\n\n\nPython\n\n\n\n\n\n\n\n\n\nApr 13, 2023\n\n\nJuan Isaula\n\n\n\n\n\n\n\n\n\n\n\n\nMicroeconomía Intermedia con R\n\n\nUtilidad y sus Curvas de Indiferencia\n\n\n\nEconomía\n\n\nMicroeconomía\n\n\nR\n\n\nRStudio\n\n\n\n\n\n\n\n\n\nJan 9, 2023\n\n\nJuan Isaula\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/microeconomia_R/index.html",
    "href": "posts/microeconomia_R/index.html",
    "title": "Microeconomía Intermedia con R",
    "section": "",
    "text": "Una forma de iniciar el análisis de los individuos es plantear un conjunto básico de postulados, o axiomas, que describen el comportamiento racional del mismo. Supondremos que dadas tres canastas de consumo cualesquiera \\((x_1,x_2)\\), \\((y_1,y_2)\\) y \\((z_1,z_2)\\). El consumidor puede ordenarlas según su atractivo. Es decir, puede decidir que una de ellas es estrictamente mejor que la otra o bien que le son indiferentes.\nUtilizaremos la notación:\n\n\\(\\succ\\) Para indicar que una canasta se prefiere estrictamente a otra, es decir, \\((x_1,x_2) \\succ (y_1,y_2)\\).\n\\(\\sim\\) Para indicar que al consumidor le resulta indiferente elegir una u otra de las dos canastas de bienes y lo representamos matemáticamente como \\((x_1,x_2)\\sim (y_1,y_2)\\).\n\\(\\succeq\\) Para indicar si el individuo prefiere una de las dos canastas o es indiferente entre ellas, decimos que prefiere debilmente la canasta \\((x_1,x_2)\\) a la \\((y_1,y_2)\\) y escribimos \\((x_1,x_2)\\succeq (y_1,y_2)\\).\n\n\n\nCon base en lo anterior, ya estamos preparados para conocer los tres axiomas de la teoría del consumidor. Decimos que las preferencias son:\n\nCompletas: suponemos que es posible comprar dos canastas cualesquiera, es decir, dada cualquier canasta \\(\\textbf{X}\\) y cualquier canasrta \\(\\textbf{Y}\\), suponemos que \\((x_1,x_2)\\succeq (y_1,y_2)\\) o \\((y_1,y_2) \\succeq (x_1,x_2)\\) o las dos cosas, en cuyo caso el consumidor es indiferente entre las dos canastas.\nReflexivas: suponemos que cualquier canasta es al menos tan buena como ella misma: \\((x_1,x_2)\\succeq (y_1,y_2)\\).\nTransitiva: si \\((x_1,x_2)\\succeq (y_1,y_2)\\) y \\((y_1,y_2)\\succeq (z_1,z_2) \\Longrightarrow (x_1,x_2)\\succeq (z_1,z_2)\\). Es decir, si el consumidor piensa que la canasta \\(\\textbf{X}\\) es al menos tan buena como la \\(\\textbf{Y}\\) y que la \\(\\textbf{Y}\\) es al menos tan buena como la \\(\\textbf{Z}\\), piensa que la \\(\\textbf{X}\\) es al menos tan buena como la \\(\\textbf{Z}\\).\n\nConsidere que cuando nos referimos a las canastas \\(\\textbf{X}, \\textbf{Y}\\) o \\(\\textbf{Z}\\) estamos haciendo referencia a:\n\n\\(\\textbf{X} = (x_1,x_2)\\)\n\\(\\textbf{Y} = (y_1.y_2)\\)\n\\(\\textbf{Z} = (z_1,z_2)\\)\n\nSi las preferencias no fueran transitivas, podría muy bien haber un conjunto de canastas tal que ninguna de las elecciones fuera la mejor. Sin embargo, en el curso de microeconomía II estamos trabajando bajo el modelo tradicional, donde asumimos que el individuo es razonal, tomando en cuenta que siempre va a preferir mas que menos.\n\n\n\nEl primer axioma, la completitud, es dificilmente criticable, al menos en el caso de los tipos de elecciones que suelen analizar los economistas. Decir que pueden compararse dos canastas cualesquiera es decir simplemente que el consumidor es capaz de elegir entre dos canasas cualesquiera.\nEl segundo axioma, la reflexividad, plantea más problemas. Una canasta cualquiera es ciertamente tan buena como una canasta idéntica.\nEl tercer axioma, la transitividad, plantea más problemas. No esta claro que las preferencias deban tener necesariamente esta propiedad. El supuesto de que son transitivas no parece evidente desde un punto de vista puramente lógico, y, de hecho, no lo es. La transitividad es una hipótesis sobre la conducta de los individuos en sus elecciones y no una afirmación lógica. Sin embargo, no importa que sea o no un hecho lógico básico; lo que importa es que sea o no una descripción razonablemente exacta del comportamiento de los individuos.\n¿Qué pensarías de una persona que dijera que prefiere la canasta \\(\\textbf{X}\\) a la \\(\\textbf{Y}\\) y la \\(\\textbf{Y}\\) a la \\(\\textbf{Z}\\), pero que también dijera que prefiere la \\(\\textbf{Z}\\) a la \\(\\textbf{X}\\)? Desde luego, lo consideraríamos como prueba de una conducta particular. Y lo que es más importante, ¿Cómo se comportaría este consumidor si tuviera que elegir entre las tres canastas \\(\\textbf{X}, \\textbf{Y}\\) y \\(\\textbf{Z}\\)?"
  },
  {
    "objectID": "posts/microeconomia_R/index.html#axiomas-de-la-teoría-del-consumidor",
    "href": "posts/microeconomia_R/index.html#axiomas-de-la-teoría-del-consumidor",
    "title": "Microeconomía Intermedia con R",
    "section": "",
    "text": "Con base en lo anterior, ya estamos preparados para conocer los tres axiomas de la teoría del consumidor. Decimos que las preferencias son:\n\nCompletas: suponemos que es posible comprar dos canastas cualesquiera, es decir, dada cualquier canasta \\(\\textbf{X}\\) y cualquier canasrta \\(\\textbf{Y}\\), suponemos que \\((x_1,x_2)\\succeq (y_1,y_2)\\) o \\((y_1,y_2) \\succeq (x_1,x_2)\\) o las dos cosas, en cuyo caso el consumidor es indiferente entre las dos canastas.\nReflexivas: suponemos que cualquier canasta es al menos tan buena como ella misma: \\((x_1,x_2)\\succeq (y_1,y_2)\\).\nTransitiva: si \\((x_1,x_2)\\succeq (y_1,y_2)\\) y \\((y_1,y_2)\\succeq (z_1,z_2) \\Longrightarrow (x_1,x_2)\\succeq (z_1,z_2)\\). Es decir, si el consumidor piensa que la canasta \\(\\textbf{X}\\) es al menos tan buena como la \\(\\textbf{Y}\\) y que la \\(\\textbf{Y}\\) es al menos tan buena como la \\(\\textbf{Z}\\), piensa que la \\(\\textbf{X}\\) es al menos tan buena como la \\(\\textbf{Z}\\).\n\nConsidere que cuando nos referimos a las canastas \\(\\textbf{X}, \\textbf{Y}\\) o \\(\\textbf{Z}\\) estamos haciendo referencia a:\n\n\\(\\textbf{X} = (x_1,x_2)\\)\n\\(\\textbf{Y} = (y_1.y_2)\\)\n\\(\\textbf{Z} = (z_1,z_2)\\)\n\nSi las preferencias no fueran transitivas, podría muy bien haber un conjunto de canastas tal que ninguna de las elecciones fuera la mejor. Sin embargo, en el curso de microeconomía II estamos trabajando bajo el modelo tradicional, donde asumimos que el individuo es razonal, tomando en cuenta que siempre va a preferir mas que menos."
  },
  {
    "objectID": "posts/microeconomia_R/index.html#explicación-de-los-axiomas",
    "href": "posts/microeconomia_R/index.html#explicación-de-los-axiomas",
    "title": "Microeconomía Intermedia con R",
    "section": "",
    "text": "El primer axioma, la completitud, es dificilmente criticable, al menos en el caso de los tipos de elecciones que suelen analizar los economistas. Decir que pueden compararse dos canastas cualesquiera es decir simplemente que el consumidor es capaz de elegir entre dos canasas cualesquiera.\nEl segundo axioma, la reflexividad, plantea más problemas. Una canasta cualquiera es ciertamente tan buena como una canasta idéntica.\nEl tercer axioma, la transitividad, plantea más problemas. No esta claro que las preferencias deban tener necesariamente esta propiedad. El supuesto de que son transitivas no parece evidente desde un punto de vista puramente lógico, y, de hecho, no lo es. La transitividad es una hipótesis sobre la conducta de los individuos en sus elecciones y no una afirmación lógica. Sin embargo, no importa que sea o no un hecho lógico básico; lo que importa es que sea o no una descripción razonablemente exacta del comportamiento de los individuos.\n¿Qué pensarías de una persona que dijera que prefiere la canasta \\(\\textbf{X}\\) a la \\(\\textbf{Y}\\) y la \\(\\textbf{Y}\\) a la \\(\\textbf{Z}\\), pero que también dijera que prefiere la \\(\\textbf{Z}\\) a la \\(\\textbf{X}\\)? Desde luego, lo consideraríamos como prueba de una conducta particular. Y lo que es más importante, ¿Cómo se comportaría este consumidor si tuviera que elegir entre las tres canastas \\(\\textbf{X}, \\textbf{Y}\\) y \\(\\textbf{Z}\\)?"
  },
  {
    "objectID": "posts/microeconomia_R/index.html#curvas-de-indiferencia",
    "href": "posts/microeconomia_R/index.html#curvas-de-indiferencia",
    "title": "Microeconomía Intermedia con R",
    "section": "Curvas de Indiferencia",
    "text": "Curvas de Indiferencia\nCon base en la definición previa de utilidad, podemos concluir, una función de utilidad es la que explica la cantidad de utilidad que posee un consumidor dado su consumo de dos bienes diferentes. \\(x, y\\). Una curva de indiferencia es solo una rebanada infenitesimal de esa función que describe todas las diferentes combinaciones entre dos bienes que producen la misma cantidad de utilidad (es decir, a la que una persona sería indiferente).\nSupongamos que una persona clasifica las hamburguesas \\((y)\\) y las bebidas \\((x)\\) de acuerdo con la función de utilidad\n\\[\nU(x,y) = \\sqrt{xy}\n\\]\nEn el caso de esta función, obtenemos la curva de indiferencia identificando un conjunto de combinaciones de \\(x,y\\) en el cual la utilidad tiene el mismo valor. Suponga que arbitrariamente decimos que la utilidad tiene un valor de 10. Entonces, la ecuación de esta curva sera:\n\\[\nU(x,y) = 10 = \\sqrt{xy}\n\\]Note que si elevamos esta función al cuadrado se mantiene el mismo orden, por lo cual también podemos representar esta curva de indiferencia como\n\\[\n100 = xy\n\\]\nEs importante siempre despejar este tipo de ecuaciones para \\(y\\) la importancia esta en que será mucho más facil posteriormente encontrar su tasa marginal de sustitución ( en otra sección de esta publicación estudiaremos a detalle esto), entonces, al despejar obtenemos:\n\\[\ny = \\frac{100}{x}\n\\]\nPara trazar su curva de indiferencia, lo haremos en R , a continuación les muestro como hacerlo. Puedes realizar este ejercicio en tu PC tu mismo.\n\n# 1. Primero cargamos las librerias que utilizaremos, en caso que nos las tengas \n#    instaladas sugiero lo hagas usando install.package(\"libreria\") en su consola\n#    de Rstudio.\nlibrary(ggplot2)\nlibrary(ggthemes)\nlibrary(tidyverse)\nlibrary(plotly)\n\n# 2. Creamos la función de utilidad del ejemplo \nutilidad &lt;- function(x,y){\n  sqrt(x*y) \n}\n\n# 3. Creamos una matriz para hacer un bucle en la función de utilidad\nvalores_matriz &lt;- matrix(0,nrow = 200, ncol = 200)\n\n# 3.1 Llenamos la matriz con usando la función de utilidad \nfor(fila in 1:nrow(valores_matriz)){\n  for(columna in 1:ncol(valores_matriz)){\n    valores_matriz[fila,columna] &lt;- utilidad(fila,columna)\n  }\n}\n\n# 4. Función que nos permitira graficar las curvas de indiferencia \n\nC_indiferencia &lt;- function(entrada_utilidad){\n  y &lt;- c()\n  \n  for(i in 1:50){\n    y_coord &lt;- entrada_utilidad^2/i\n    y       &lt;- c(y,y_coord)\n  }\n  \n  data &lt;- data.frame(\n    x = 1:50,\n    y = y,\n    z = rep(entrada_utilidad,50)\n  )\n  \n  return(data)\n}\n\n\n# 4.1 Resultado de utilidades obtenidas \nlista_utilidades &lt;- lapply(10, C_indiferencia)\n\nfull_df &lt;- do.call(rbind, lista_utilidades)\n\nAhora si ya estamos preparados para graficar nuestras curvas de indiferencia para \\(10 = \\sqrt{xy}\\)\n\n# 5. Gráfico\n\nggplot() + \n  geom_point(data = full_df, aes(x = x, y = y, color = z)) + \n  geom_path(data = full_df, aes(x = x, y = y, color = z)) +\n  theme_minimal()+\n  ylim(0,100) + \n  labs(x = \"Bebidad\", y = \"Hamburguesas\") + \n  scale_color_continuous(name = \"Utilidad\")\n\n\n\n\n\n\n\n\nNote que la curva previa representa una utilidad = 10.\nA continuación te muestro un grafico animado de la curva de indiferencia previa. Para generar el gráfico presiona el boton PLAY.\n\n\n\n\n\n\nVeamos que sucede cuando tenemos diferentes niveles de utilidad, en base al resultado usted puede deducir su propio análisis.\n\nutilidad &lt;- function(x,y){\n  sqrt(x*y) \n}\n\nvalores_matriz &lt;- matrix(0,nrow = 200, ncol = 200)\n\nfor(fila in 1:nrow(valores_matriz)){\n  for(columna in 1:ncol(valores_matriz)){\n    valores_matriz[fila,columna] &lt;- utilidad(fila,columna)\n  }\n}\n\nC_indiferencia &lt;- function(entrada_utilidad){\n  y &lt;- c()\n  \n  for(i in 1:100){\n    y_coord &lt;- entrada_utilidad^2/i\n    y       &lt;- c(y,y_coord)\n  }\n  \n  data &lt;- data.frame(\n    x = 1:100,\n    y = y,\n    z = rep(entrada_utilidad,100)\n  )\n  \n  return(data)\n}\n\nlista_utilidades &lt;- lapply(seq(from =10, to = 60, by = 10), C_indiferencia)\n\nfull_df &lt;- do.call(rbind, lista_utilidades)\n\n\nggplot() +\n  geom_point(data = full_df, aes(x = x, y = y, color = z)) +\n  geom_path(data = full_df, aes(x = x, y = y, color = z)) +\n  theme_minimal() +\n  ylim(0,200) +\n  labs(x = \"Bebidas\", y = \"Hamburguesas\") +\n  scale_color_continuous(name = \"Utilidad\")\n\n\n\n\n\n\n\n\nAquí podemos señalar lo siguiente:\n\nA medida que aumenta la utilidad, las curvas se desplazan hacia la derecha y hacia la izquierda a medida que disminuye la utilidad.\nObserve que las curvas se inclinan hacia abajo, esto debe ser necesariamente el caso; a medida que uno aumenta su consumo de bebidas renuncia al otro bien que les era indiferente, hamburguesa.\nTodo lo que está debajo de la curva representa paquetes con menos utilidad. La teoría de la utilidad asume que un consumidor siempre buscará maximizar la utilidad.\nComprende que la pendiente no es lineal. En genera, cuanto más se tiene de algo, menos utilidad se obtendrá de otra unidad y, por el contrario, más se renunciaría a adquirir el otro bien. Esta pendiente tiene un nombre oficial: Tasa Marginal de Sustitución o TMS hablaremos de esto en una sección posterior.\n\nPero esas son solo algunas rebanadas que ya he señalado como infinitesimalmente pequeñas.\nPara concluir esta sección te dejo un gráfico animado de los diferentes niveles de utilidad, por favor presiona el boton PLAY para que logres verlo."
  },
  {
    "objectID": "posts/microeconomia_R/index.html#tasa-marginal-de-sustitución-tms",
    "href": "posts/microeconomia_R/index.html#tasa-marginal-de-sustitución-tms",
    "title": "Microeconomía Intermedia con R",
    "section": "Tasa Marginal de Sustitución (TMS)",
    "text": "Tasa Marginal de Sustitución (TMS)\nOtro concepto importante en la teoría del consumidor es la Tasa Marginal de Sustitución (TMS). Matemáticamente esto es la pendiente de la curva de indiferencia, sin embargo, en términos microecnómicos esta pendiente se refiere a la relación de cambio entre un bien \\(x\\) y el bien \\(y\\), es decir, cuanto del bien x se tiene que sacrificar (aumentar) para aumentar (disminuir) el consumo del bien y para aumentarse en el mismo nivel de utilidad.\nEn términos matemáticos la TMS se define como:\n\\[\nTMS = -\\left.\\begin{array}{c}\\frac{dy}{dx} \\end{array}\\right|_{U = U_1}\n\\]\ndonde la notación indica que la pendiente se debe calcular a lo largo de la cuva de indiferencia \\(U_1\\).\nUn ejercicio interesante para el lector, seria intentar probar la identidad de \\(TMS\\) que acabamos de definir.\n\nMúltiples Curvas de Indiferencia\nHay una curva de indiferencia que pasa por cada punto del plano \\(xy\\). Cada una de estas curvas muestra combinaciones de \\(x\\) y \\(y\\) que proporcionan al individuo determinado nivel de satisfación como se vio en graficos anteriores. Los movimientos en dirección noreste representan movimientos hacia niveles más altos de satisfación.\n\n\n\nEl cambio de la pendiente a lo largo de U1 muestra que la canasta de consumo disponible afecta los intercambios que esta persona realizará libremente\n\n\nDado que ya conocemos en que consiste la TMS, y a este punto asumo que el lector ya tiene idea de como realizar el computo manual de la TMS para una función de utilidad dada. Entonces, procederemos a realizar el computo de la TMS en R, para el computo se procederá a crear una función que resuelva el problema más rapidamente, ya que como usted se ha podido dar cuenta se necesita y usar calculo diferencial (derivadas).\nLa función que crearemos para realizar el computo de la TMS la llamaremos TMS, veamos como hacerlo en R.\n\nTMS &lt;- function(fun.utilidad, bien_x) {\n  U  &lt;- parse(text = fun.utilidad)\n  v1 &lt;- D(U, \"x\")                       # D() función que realiza la derivada de U\n  print(paste(\"TMS = \", \n              eval(v1, envir = list(x = bien_x)), \"considerando\", \n              bien_x, \"unidades del bien x\"))\n}\n\nDel bloque de código previo:\n\nTMS: función que calcula la tasa marginal de sustitución.\nfun.utilidad: función de la curva de indiferencia (y en función de x). Tiene que especificarse en caracteres.\nbien_x: unidades del bien x en donde se evaluara la TMS.\n\n\n\nEjemplo\nconsideremos la siguiente función de utilidad con su respectivo nivel de utilidad\n\\[\nU(x,y) = 10 = \\sqrt{xy}\n\\]\nSi calculamos la TMS de esta curva de indiferencia de manera manual tendremos:\n\\[\nTMS = -\\frac{\\frac{\\partial U}{\\partial x}}{\\frac{\\partial U}{\\partial y}} = -\\frac{100}{x^2}\n\\]\nComo se puede dar cuenta la TMS depende de “x”, lo que indica que tenemos que variar “x” positiva o negativamente , con el fin de obtener menos o más de “y” y mantenernos en la misma utilidad de 10.\nSi evaluamos la TMS cuando el bien “x” es igual a 5, entonces, la TMS sera de\n\\[\nTMS = -\\frac{100}{5^2} = -4\n\\]\nEsto implica, que si aumentamos el consumo del bien “x” en 1 tendremos que disminuir el consumo del bien y en 4. Veamos este ejemplo en R.\n\n# bien_x = 5\n# Utilizamos la función TMS que creamos previamente \n\nTMS(fun.utilidad = \"100/x\", 5)\n\n[1] \"TMS =  -4 considerando 5 unidades del bien x\"\n\n\nNote que el resultado es el deseado. Pero si queremos ver como varía la TMS para distintas cantidades del bien “x”, podemos hacer pequeñas variaciones a la función (TMS) que definimos en el primer bloque de código de esta sección.\n\nVar_TMS &lt;- function(fun.utilidad, bien_x){\n  U  &lt;- parse(text = fun.utilidad)\n  v1 &lt;- D(U, \"x\")\n  eval(v1, envir = list(x = bien_x))\n}\n\n\n# Veamos el comportamiento de la TMS cuando variamos el bien x\n\nw &lt;- c()\nfor (i in seq(60, 10, -10)){\n  t &lt;- Var_TMS(fun.utilidad = \"100/x\",i)\n  w &lt;- c(w,t)\n}\n\nw\n\n[1] -0.02777778 -0.04000000 -0.06250000 -0.11111111 -0.25000000 -1.00000000\n\n\nVeamos que a medida que el bien x pasa de ser abundante a ser un bien escazo cada vez le resulta al consumidor más relevante y si desea obtener una unidad adicional del bien x tendrá que renunciar a más cantidad del bien y. Es así que si el consumidor tiene solo un bien, cambiará este bien siempre y cuando reciba cien unidades del bien y.\nEn la siguiente sección de este post verá el tema de maximización de la utilidad dado una restricción presupuestaria. Es decir, desarrollamaremos el cálculo óptimo de los bienes, que maximizan la función de utilidad."
  },
  {
    "objectID": "posts/Credit_Scoring/index.html",
    "href": "posts/Credit_Scoring/index.html",
    "title": "Credit Scoring and Segmentation using Python",
    "section": "",
    "text": "La calificación crediticia y la segmentación se refieren al proceso de evaluar la solvencia de personas o empresas y dividirlos en distintos grupos según sus perfiles crediticios. Su objetivo es evaluar la probabilidad de que los prestatarios pagen sus deudas y ayuda a las instituciones financieras a tomar decisiones informadas sobre préstamos y gestión del riesgo crediticio. Si desea aprender a calcular puntajes crediticios y segmentar clientes en función de sus puntajes crediticios, este artículo es para usted. En este artículo, lo guiaré a través de la tarea de segementación y calificación crediticia usando Python."
  },
  {
    "objectID": "posts/Credit_Scoring/index.html#calificación-crediticia-y-segmentación-usando-python",
    "href": "posts/Credit_Scoring/index.html#calificación-crediticia-y-segmentación-usando-python",
    "title": "Credit Scoring and Segmentation using Python",
    "section": "Calificación crediticia y segmentación usando Python",
    "text": "Calificación crediticia y segmentación usando Python\nAhora comencemos con la tarea de segmentación y calificación crediticia importando las bibliotecas de Python necesarias y el conjunto de datos\n\nimport pandas as pd\nimport plotly.graph_objects as go\nimport plotly.express as px\nimport plotly.io as pio\npio.templates.default = \"plotly_white\"\n\ndata = pd.read_csv(\"credit_scoring.csv\")\ndata.head()\n\n\n\n\n\n\n\n\nAge\nGender\nMarital Status\nEducation Level\nEmployment Status\nCredit Utilization Ratio\nPayment History\nNumber of Credit Accounts\nLoan Amount\nInterest Rate\nLoan Term\nType of Loan\n\n\n\n\n0\n60\nMale\nMarried\nMaster\nEmployed\n0.22\n2685.0\n2\n4675000\n2.65\n48\nPersonal Loan\n\n\n1\n25\nMale\nMarried\nHigh School\nUnemployed\n0.20\n2371.0\n9\n3619000\n5.19\n60\nAuto Loan\n\n\n2\n30\nFemale\nSingle\nMaster\nEmployed\n0.22\n2771.0\n6\n957000\n2.76\n12\nAuto Loan\n\n\n3\n58\nFemale\nMarried\nPhD\nUnemployed\n0.12\n1371.0\n2\n4731000\n6.57\n60\nAuto Loan\n\n\n4\n32\nMale\nMarried\nBachelor\nSelf-Employed\n0.99\n828.0\n2\n3289000\n6.28\n36\nPersonal Loan\n\n\n\n\n\n\n\nA continuación se muestra la descripción de todas los campos de los datos:\n\nAge: representa la edad del individuo\nGender: identifica el género del individuo\nMarital Status: denota el estado civil del individuo\nEducation Level: representa en nivel más alto de educación alcanzado por el individuo.\nEmployment Status: indica el estado de empleo actual del individuo\nCredit Utilization: refleja la proporción de crédito utilizado por el individuo en comparación con su límite de crédito total disponible.\nInterest Rate: tasa de interés asociada con el préstamo.\nPayment History: representa el comportamiento de pago neto mensual de cada cliente, tomando en cuenta factores como pagos a tiempo, pagos atrasados, pagos atrasados e incumplimientos.\nNumber of Credit Accounts: representa el conteo de cuentas de crédito activas que posee la persona.\nLoan Amount: indica el valor monetario del préstamo.\nLoan Term: indica la duraciòn o plazo del préstamo.\nType of Loan: incluye categorías como “Préstamo personal”, “Préstamo para automovil” o potencialmente otro tipos de préstamos.\n\nAhora echemos un vistazo a las estadísticas de las columnas antes de seguir adelante:\n\ndata.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 1000 entries, 0 to 999\nData columns (total 12 columns):\n #   Column                     Non-Null Count  Dtype  \n---  ------                     --------------  -----  \n 0   Age                        1000 non-null   int64  \n 1   Gender                     1000 non-null   object \n 2   Marital Status             1000 non-null   object \n 3   Education Level            1000 non-null   object \n 4   Employment Status          1000 non-null   object \n 5   Credit Utilization Ratio   1000 non-null   float64\n 6   Payment History            1000 non-null   float64\n 7   Number of Credit Accounts  1000 non-null   int64  \n 8   Loan Amount                1000 non-null   int64  \n 9   Interest Rate              1000 non-null   float64\n 10  Loan Term                  1000 non-null   int64  \n 11  Type of Loan               1000 non-null   object \ndtypes: float64(3), int64(4), object(5)\nmemory usage: 93.9+ KB\n\n\nAhora echemos un vistazo a las estadísticas descriptivas de los datos:\n\ndata.describe()\n\n\n\n\n\n\n\n\nAge\nCredit Utilization Ratio\nPayment History\nNumber of Credit Accounts\nLoan Amount\nInterest Rate\nLoan Term\n\n\n\n\ncount\n1000.000000\n1000.000000\n1000.000000\n1000.000000\n1.000000e+03\n1000.000000\n1000.000000\n\n\nmean\n42.702000\n0.509950\n1452.814000\n5.580000\n2.471401e+06\n10.686600\n37.128000\n\n\nstd\n13.266771\n0.291057\n827.934146\n2.933634\n1.387047e+06\n5.479058\n17.436274\n\n\nmin\n20.000000\n0.000000\n0.000000\n1.000000\n1.080000e+05\n1.010000\n12.000000\n\n\n25%\n31.000000\n0.250000\n763.750000\n3.000000\n1.298000e+06\n6.022500\n24.000000\n\n\n50%\n42.000000\n0.530000\n1428.000000\n6.000000\n2.437500e+06\n10.705000\n36.000000\n\n\n75%\n54.000000\n0.750000\n2142.000000\n8.000000\n3.653250e+06\n15.440000\n48.000000\n\n\nmax\n65.000000\n1.000000\n2857.000000\n10.000000\n4.996000e+06\n19.990000\n60.000000\n\n\n\n\n\n\n\nAhora echemos un vistazo a la distribución del índice de utilización del crédito en los datos:\n\ncredit_utilization_fig = px.box(data, y='Credit Utilization Ratio',\n                                title='Distribución del índice de utilización del crédito')\ncredit_utilization_fig.show()\n\n                                                \n\n\nAhora echemos un vistazo a la distribución del monto del préstamo en los datos:\n\nloan_amount_fig = px.histogram(data, x='Loan Amount', \n                               nbins=20, \n                               title='Distribución del monto del préstamo')\nloan_amount_fig.show()\n\n                                                \n\n\nLuego, echemos un vistazo a la correlación en los datos:\n\nnumeric_df = data[['Credit Utilization Ratio', \n                   'Payment History', \n                   'Number of Credit Accounts', \n                   'Loan Amount', 'Interest Rate', \n                   'Loan Term']]\ncorrelation_fig = px.imshow(numeric_df.corr(), \n                            title='Mapa de calor de correlación')\ncorrelation_fig.show()"
  },
  {
    "objectID": "posts/Credit_Scoring/index.html#calcular-puntajes-de-crédito",
    "href": "posts/Credit_Scoring/index.html#calcular-puntajes-de-crédito",
    "title": "Credit Scoring and Segmentation using Python",
    "section": "Calcular puntajes de crédito",
    "text": "Calcular puntajes de crédito\nEl conjunto de datos no tiene ninguna característica que represente los puntajes crediticios de las personas. Para calcular las puntuaciones de crédito, debemos utilizar una técnica adecuada. Existen varias técnicas ampliamente utilizadas para calcular puntajes credeticios, cada una con su propio proceso de cálculo. Un ejemplo es el puntaje FICO, es un modelo de calificación crediticia comúnmente utilizado en la industria.\nA continuación se muestra cómo podemos implementar el método de puntuación FICO para calcular las puntuaciones de crédito.\n\n# Definir el mapeo para características categóricas\neducation_level_mapping = {'High School': 1, 'Bachelor': 2, 'Master': 3, 'PhD': 4}\nemployment_status_mapping = {'Unemployed': 0, 'Employed': 1, 'Self-Employed': 2}\n\n# Aplicar mapeo  a características categóricas\ndata['Education Level'] = data['Education Level'].map(education_level_mapping)\ndata['Employment Status'] = data['Employment Status'].map(employment_status_mapping)\n\n# Calcule puntajes de crédito utilizando la fórmula FICO completa\ncredit_scores = []\n\nfor index, row in data.iterrows():\n    payment_history = row['Payment History']\n    credit_utilization_ratio = row['Credit Utilization Ratio']\n    number_of_credit_accounts = row['Number of Credit Accounts']\n    education_level = row['Education Level']\n    employment_status = row['Employment Status']\n    \n    # Apliaue la fórmula FICO para calcular el puntaje crediticio\n    credit_score = (payment_history * 0.35) + (credit_utilization_ratio * 0.30) + (number_of_credit_accounts * 0.15) + (education_level * 0.10) + (employment_status * 0.10)\n    credit_scores.append(credit_score)\n\n# Agregue los puntajes de crédito como una nueva columna al DataFrame\ndata['Credit Score'] = credit_scores\n\ndata.head()\n\n\n\n\n\n\n\n\nAge\nGender\nMarital Status\nEducation Level\nEmployment Status\nCredit Utilization Ratio\nPayment History\nNumber of Credit Accounts\nLoan Amount\nInterest Rate\nLoan Term\nType of Loan\nCredit Score\n\n\n\n\n0\n60\nMale\nMarried\n3\n1\n0.22\n2685.0\n2\n4675000\n2.65\n48\nPersonal Loan\n940.516\n\n\n1\n25\nMale\nMarried\n1\n0\n0.20\n2371.0\n9\n3619000\n5.19\n60\nAuto Loan\n831.360\n\n\n2\n30\nFemale\nSingle\n3\n1\n0.22\n2771.0\n6\n957000\n2.76\n12\nAuto Loan\n971.216\n\n\n3\n58\nFemale\nMarried\n4\n0\n0.12\n1371.0\n2\n4731000\n6.57\n60\nAuto Loan\n480.586\n\n\n4\n32\nMale\nMarried\n2\n2\n0.99\n828.0\n2\n3289000\n6.28\n36\nPersonal Loan\n290.797\n\n\n\n\n\n\n\nA continuación se muestra cómo funciona el código anterior:\n\nEn primer lugar, define asignaciones para dos características categóricas: “Nivel de educación” y “Estado laboral”. La asignación de “Nivel de educación” asigna valores numéricos a diferentes niveles de educación, como “Escuela secundaria” asignada a 1, “Licenciatura” a 2, “Maestría” a 3 y “Doctorado” a 4. El “Estado de empleo” el mapeo asigna valores numéricos a diferentes estados laborales, como “desempleado” asignado a 0, “empleado” asigna 1 y “autónomo” a 2.\nA continuación, el código aplica las asignaciones definidas a las columnas correspondientes en el DataFrame. Transforma los valores de las columnas “Nivel de educación” y “Estado de empleo” de su forma categórica original a las representaciones numéricas asignadas.\nDespués de eso, el código inicia una iteración sobre cada fila del DataFrame para calcular las puntuaciones de crédito de cada individuo. Recupera los valores de características relevantes, como “Historial de pagos”, “índice de utilización de crédito”, “Número de cuentas de crédito”, “Nivel de educación” y “Estado de empleo”, de cada fila.\n\nDentro de la iteración, se aplica la fórmula FICO para calcular el puntaje de crediticio de cada individuo. La fórmula incorpora los valores ponderados de las características mencionadas anteriormente:\n\nPeso del 35% para “Historial de pagos (Payment History)”\nPeso del 30% para el “índice de utilización de crédito (Credit Utilization Ratio)”\nPeso del 15% para “Número de cuentas de crédito (Number of Credit Accounts)”\n10% de peso para “Nivel de educación (Education Level)”\ny 10% de ponderación para “Estatus laboral (Employment Status)”\n\nLuego, el puntaje crediticio calculado se almacena en una lista llamada \"credit_scores\"."
  },
  {
    "objectID": "posts/Credit_Scoring/index.html#segmentación-basada-en-puntakes-crediticios",
    "href": "posts/Credit_Scoring/index.html#segmentación-basada-en-puntakes-crediticios",
    "title": "Credit Scoring and Segmentation using Python",
    "section": "Segmentación basada en puntakes crediticios",
    "text": "Segmentación basada en puntakes crediticios\nAhora, usemos el algoritmo de agrupamiento KMeans para segmentar a los clientes según sus puntajes crediticios.\n\nimport warnings\nwarnings.filterwarnings('ignore')\nimport numpy as np\nfrom sklearn.cluster import KMeans\n\nX = data[['Credit Score']]\nX = np.nan_to_num(X)\nkmeans = KMeans(n_clusters=4, n_init=10, random_state=42)\nkmeans.fit(X)\ndata['Segment'] = kmeans.labels_\n\nAhora echemos un vistazo a los segmentos:\n\ndata.head()\n\n\n\n\n\n\n\n\nAge\nGender\nMarital Status\nEducation Level\nEmployment Status\nCredit Utilization Ratio\nPayment History\nNumber of Credit Accounts\nLoan Amount\nInterest Rate\nLoan Term\nType of Loan\nCredit Score\nSegment\n\n\n\n\n0\n60\nMale\nMarried\n3\n1\n0.22\n2685.0\n2\n4675000\n2.65\n48\nPersonal Loan\n940.516\n3\n\n\n1\n25\nMale\nMarried\n1\n0\n0.20\n2371.0\n9\n3619000\n5.19\n60\nAuto Loan\n831.360\n3\n\n\n2\n30\nFemale\nSingle\n3\n1\n0.22\n2771.0\n6\n957000\n2.76\n12\nAuto Loan\n971.216\n3\n\n\n3\n58\nFemale\nMarried\n4\n0\n0.12\n1371.0\n2\n4731000\n6.57\n60\nAuto Loan\n480.586\n0\n\n\n4\n32\nMale\nMarried\n2\n2\n0.99\n828.0\n2\n3289000\n6.28\n36\nPersonal Loan\n290.797\n0\n\n\n\n\n\n\n\n\n# Convertir la columna segmento al tipo de datos categoría\ndata['Segment'] = data['Segment'].astype('category')\n\n# Visualiza los segmentos usando Plotly\nfig = px.scatter(data, x=data.index, y='Credit Score', color='Segment',\n                 color_discrete_sequence=['green', 'blue', 'yellow', 'red'])\nfig.update_layout(\n    xaxis_title='Indice de clientes',\n    yaxis_title='Credit Score',\n    title='Customer Segmentation based on Credit Scores'\n)\nfig.show()\n\n                                                \n\n\nAhora nombremos los segmentos según los grupos anteriores y echemos un vistazo a los segmentos nuevamente:\n\ndata['Segment'] = data['Segment'].map({2: 'Muy baja', \n                                       0: 'Baja',\n                                       1: 'Buena',\n                                       3: \"Excelente\"})\n\n# Convertir la columna segmento al tipo de datos de categoria\ndata['Segment'] = data['Segment'].astype('category')\n\n# Visualiza los segmentos usando Plotly\nfig = px.scatter(data, x=data.index, y='Credit Score', color='Segment',\n                 color_discrete_sequence=['green', 'blue', 'yellow', 'red'])\nfig.update_layout(\n    xaxis_title='Customer Index',\n    yaxis_title='Credit Score',\n    title='Customer Segmentation based on Credit Scores'\n)\nfig.show()\n\n                                                \n\n\nAsí es como puede realizar la segmentación y la calificación crediticia utilizando Python."
  },
  {
    "objectID": "posts/DL_PyTorch/index.html",
    "href": "posts/DL_PyTorch/index.html",
    "title": "Deep Learning",
    "section": "",
    "text": "El Deep Learning está en todas partes, desde las cámaras de los smartphones hasta los asistentes de vos o los vehículos autónomos. En este curso, descubriras esta potente tecnología y aprenderás a aprovecharla con PyTorch, una de las bibliotecas de aprendizaje profundo más populares. Al finalizar tu recorrido por este documento, serás capaz de aprovechar PyTorch para resolver problemas de clasificación y regresión utilizando el aprendizaje profundo."
  },
  {
    "objectID": "posts/DL_PyTorch/index.html#qué-es-deep-learning",
    "href": "posts/DL_PyTorch/index.html#qué-es-deep-learning",
    "title": "Deep Learning",
    "section": "Qué es Deep Learning?",
    "text": "Qué es Deep Learning?\n\n\n\n\n\nDeep Learning (aprendizaje profundo) es un subconjunto del aprendizaje automático (machine learning). La estructura del modelo es una red de entradas (input), capas ocultas (hidden layers) y salidas (output), como se muestra en la siguiente imagen:\n\n\n\n\n\nComo apreciamos en la figura, una red puede tener una o muchas capas ocultas\n\n\n\n\n\nLa intuición original detrás del aprendizaje profundo era crear modelos inspirados en el cerebro humano, sobre todo por cómo aprende el cerebro humano: a través de células interconectadas llamadas neuronas. Es por esto que llamamos a los modelos de aprendizaje profundo Redes Neuronales.\n\n\n\n\n\nEstas estructuras de modelos en capas requieren muchos más datos en comparación con otros modelos de aprendizaje automático para derivar patrones. Generalmente hablamos de al menos cientos de miles de puntos de datos."
  },
  {
    "objectID": "posts/DL_PyTorch/index.html#pytorch-un-framework-del-deep-learning",
    "href": "posts/DL_PyTorch/index.html#pytorch-un-framework-del-deep-learning",
    "title": "Deep Learning",
    "section": "PyTorch: un framework del deep learning",
    "text": "PyTorch: un framework del deep learning\n\n\n\n\n\nSi bien existen varios framework y paquetes para implementar el aprendizaje profundo en cuanto a algoritmos, nos centraremos en PyTorch, uno de los frameworks más populares y mejor mantenidos. PyTorch fue desarrollado originalmente por Meta IA como parte del laboratorio de investigación de inteligencia artificial de Facebook antes de que pasara a depender de la fundación Linux.\nEstá diseñado para ser intuitivo y fácil de usar, compartiendo muchas similitudes con la biblioteca de Python NumPy.\n\nPyTorch Tensors\nPodemos importar el módulo PyTorch llamando a\n\nimport torch\n\n\nLa estructura de datos fundamental en PyTorch es un tensor, que es similar a una matriz.\nPuede soportar muchas operaciones matemáticas y constituye un componente básico para nuestras redes neuronales.\nSe pueden crear tensores a partir de listas de Python o matrices NumPy utilizando la clase torch.tensor() esta clase convierte los datos a un formato compatible para el aprendizaje profundo.\n\n\nmi_lista = [[1,2,3], [4,5,6]]\ntensor = torch.tensor(mi_lista)\nprint(tensor)\n\ntensor([[1, 2, 3],\n        [4, 5, 6]])\n\n\n\n\nAtributos de los Tensores\nPodemos llamar a tensor.shape para mostrar la forma de nuestro objeto recién creado.\n\nprint(tensor.shape)\n\ntorch.Size([2, 3])\n\n\nY tensor.dtype() para mostrar su tipo de datos, aquí un entero de 64 bits.\n\nprint(tensor.dtype)\n\ntorch.int64\n\n\nVerificar la forma y el tipo de datos garantiza que los tensores se alineen correctamente con nuestro modelo y tarea, y puede ayudarnos en caso de depuración.\n\nOperaciones con Tensores\nSe pueden sumar o restar tensores de PyTorch, siempre que sus formas sean compatibles.\n\na = torch.tensor([[1,1], [2,2]])\nb = torch.tensor([[2,2],[3,3]])\nc = torch.tensor([[2,2,2], [3,3,5]])\n\n\nprint(a + b)\n\ntensor([[3, 3],\n        [5, 5]])\n\n\nCuando las dimensiones no son compatibles, obtendremos un error.\nTambién podemos realizar la multiplicación por elemento, lo que implica multiplicar cada elemento correspondiente.\n\nprint(a*b)\n\ntensor([[2, 2],\n        [6, 6]])\n\n\nTambién esta incluida la multiplicación de matrices, que no es más que uno forma de combinar dos matrices para crear una nueva.\n\nprint(a @ b)\n\ntensor([[ 5,  5],\n        [10, 10]])\n\n\nDetras de escena, los modelos de aprendizaje profundo realizan innumerables operaciones como la suma y multiplicación para procesar datos y aprender patrones."
  }
]